{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on MDVR-KCL Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import auc\n",
    "#from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import seaborn as sns\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Acoustic Features alone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the data that was extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanF0Hz</th>\n",
       "      <th>stdevF0Hz</th>\n",
       "      <th>HNR</th>\n",
       "      <th>localJitter</th>\n",
       "      <th>localabsoluteJitter</th>\n",
       "      <th>rapJitter</th>\n",
       "      <th>ppq5Jitter</th>\n",
       "      <th>localShimmer</th>\n",
       "      <th>localdbShimmer</th>\n",
       "      <th>apq3Shimmer</th>\n",
       "      <th>apq5Shimmer</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>180.433976</td>\n",
       "      <td>51.653057</td>\n",
       "      <td>13.292053</td>\n",
       "      <td>0.027039</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.012019</td>\n",
       "      <td>0.013197</td>\n",
       "      <td>0.113439</td>\n",
       "      <td>1.124025</td>\n",
       "      <td>0.046161</td>\n",
       "      <td>0.067371</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>190.751972</td>\n",
       "      <td>34.887596</td>\n",
       "      <td>11.243993</td>\n",
       "      <td>0.016118</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.006764</td>\n",
       "      <td>0.007168</td>\n",
       "      <td>0.079053</td>\n",
       "      <td>0.740666</td>\n",
       "      <td>0.029396</td>\n",
       "      <td>0.038308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>124.477366</td>\n",
       "      <td>26.621493</td>\n",
       "      <td>13.423983</td>\n",
       "      <td>0.026740</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.010862</td>\n",
       "      <td>0.011512</td>\n",
       "      <td>0.102565</td>\n",
       "      <td>0.974095</td>\n",
       "      <td>0.039042</td>\n",
       "      <td>0.058131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>182.557207</td>\n",
       "      <td>39.933612</td>\n",
       "      <td>12.235210</td>\n",
       "      <td>0.020701</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.008979</td>\n",
       "      <td>0.008983</td>\n",
       "      <td>0.080388</td>\n",
       "      <td>0.811653</td>\n",
       "      <td>0.025759</td>\n",
       "      <td>0.037847</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>195.969796</td>\n",
       "      <td>41.446983</td>\n",
       "      <td>14.669165</td>\n",
       "      <td>0.015063</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.005371</td>\n",
       "      <td>0.006017</td>\n",
       "      <td>0.082016</td>\n",
       "      <td>0.827343</td>\n",
       "      <td>0.029087</td>\n",
       "      <td>0.043951</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     meanF0Hz  stdevF0Hz        HNR  localJitter  localabsoluteJitter  \\\n",
       "0  180.433976  51.653057  13.292053     0.027039             0.000151   \n",
       "1  190.751972  34.887596  11.243993     0.016118             0.000085   \n",
       "2  124.477366  26.621493  13.423983     0.026740             0.000216   \n",
       "3  182.557207  39.933612  12.235210     0.020701             0.000114   \n",
       "4  195.969796  41.446983  14.669165     0.015063             0.000077   \n",
       "\n",
       "   rapJitter  ppq5Jitter  localShimmer  localdbShimmer  apq3Shimmer  \\\n",
       "0   0.012019    0.013197      0.113439        1.124025     0.046161   \n",
       "1   0.006764    0.007168      0.079053        0.740666     0.029396   \n",
       "2   0.010862    0.011512      0.102565        0.974095     0.039042   \n",
       "3   0.008979    0.008983      0.080388        0.811653     0.025759   \n",
       "4   0.005371    0.006017      0.082016        0.827343     0.029087   \n",
       "\n",
       "   apq5Shimmer  label  \n",
       "0     0.067371      0  \n",
       "1     0.038308      0  \n",
       "2     0.058131      0  \n",
       "3     0.037847      0  \n",
       "4     0.043951      0  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only acoustic features\n",
    "df = pd.read_csv(\"../MDVR_acoustic_features.csv\")\n",
    "#df = shuffle(df)\n",
    "#df.reset_index(inplace=True, drop=True)\n",
    "df.drop('voiceID', inplace = True, axis = 1)\n",
    "df['label'].value_counts()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37, 12)\n",
      "         meanF0Hz  stdevF0Hz        HNR  localJitter  localabsoluteJitter  \\\n",
      "count   37.000000  37.000000  37.000000    37.000000            37.000000   \n",
      "mean   167.457574  40.580354  13.481044     0.023604             0.000151   \n",
      "std     30.826544  12.639763   1.689425     0.005694             0.000062   \n",
      "min     99.176942  15.856715  10.195438     0.013899             0.000077   \n",
      "25%    139.689970  34.365179  12.332291     0.019678             0.000111   \n",
      "50%    173.417455  39.933612  13.388906     0.022659             0.000131   \n",
      "75%    190.751972  46.792915  14.583647     0.027164             0.000189   \n",
      "max    214.216909  81.862069  16.854876     0.038871             0.000332   \n",
      "\n",
      "       rapJitter  ppq5Jitter  localShimmer  localdbShimmer  apq3Shimmer  \\\n",
      "count  37.000000   37.000000     37.000000       37.000000    37.000000   \n",
      "mean    0.010275    0.010958      0.096316        0.940552     0.036721   \n",
      "std     0.003032    0.002919      0.021066        0.173345     0.010148   \n",
      "min     0.005279    0.005674      0.060868        0.629243     0.023605   \n",
      "25%     0.008344    0.009032      0.080560        0.810418     0.029396   \n",
      "50%     0.009854    0.010480      0.095878        0.963974     0.035746   \n",
      "75%     0.012019    0.013001      0.105540        1.005431     0.040549   \n",
      "max     0.017499    0.017930      0.179428        1.531849     0.070886   \n",
      "\n",
      "       apq5Shimmer      label  \n",
      "count    37.000000  37.000000  \n",
      "mean      0.051479   0.432432  \n",
      "std       0.014166   0.502247  \n",
      "min       0.028934   0.000000  \n",
      "25%       0.040420   0.000000  \n",
      "50%       0.049436   0.000000  \n",
      "75%       0.058131   1.000000  \n",
      "max       0.103642   1.000000  \n",
      "label\n",
      "0    21\n",
      "1    16\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# shape\n",
    "print(df.shape)\n",
    "\n",
    "# descriptions\n",
    "print(df.describe())\n",
    "\n",
    "# class distribution\n",
    "print(df.groupby('label').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA - Check outliers Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x2160 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# histograms\n",
    "plt.figure(figsize=(30,30))\n",
    "#df_all.hist(figsize=(30,30))\n",
    "#plt.show()\n",
    "\n",
    "#box plot to check outliers\n",
    "cols = df.columns.drop('label')\n",
    "fig, ax = plt.subplots(4,3, figsize=(30,30))\n",
    "for i,t in enumerate(cols):\n",
    "    sns.boxplot(y=t, x= \"label\", data=df, ax=ax[i//3,i % 3])\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00011058627489265645\n",
      "0.00018935814179033646\n",
      "7.877186689768e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanF0Hz</th>\n",
       "      <th>stdevF0Hz</th>\n",
       "      <th>HNR</th>\n",
       "      <th>localJitter</th>\n",
       "      <th>localabsoluteJitter</th>\n",
       "      <th>rapJitter</th>\n",
       "      <th>ppq5Jitter</th>\n",
       "      <th>localShimmer</th>\n",
       "      <th>localdbShimmer</th>\n",
       "      <th>apq3Shimmer</th>\n",
       "      <th>apq5Shimmer</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>116.991841</td>\n",
       "      <td>58.387577</td>\n",
       "      <td>10.195438</td>\n",
       "      <td>0.038871</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.016799</td>\n",
       "      <td>0.01793</td>\n",
       "      <td>0.127226</td>\n",
       "      <td>1.246093</td>\n",
       "      <td>0.048545</td>\n",
       "      <td>0.071562</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      meanF0Hz  stdevF0Hz        HNR  localJitter  localabsoluteJitter  \\\n",
       "22  116.991841  58.387577  10.195438     0.038871             0.000332   \n",
       "\n",
       "    rapJitter  ppq5Jitter  localShimmer  localdbShimmer  apq3Shimmer  \\\n",
       "22   0.016799     0.01793      0.127226        1.246093     0.048545   \n",
       "\n",
       "    apq5Shimmer  label  \n",
       "22     0.071562      1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jitter = df.sort_values(\"localabsoluteJitter\")\n",
    "Q1=df_jitter['localabsoluteJitter'].quantile(0.25)\n",
    "Q3=df_jitter['localabsoluteJitter'].quantile(0.75)\n",
    "IQR=Q3-Q1\n",
    "print(Q1)\n",
    "print(Q3)\n",
    "print(IQR)\n",
    "Lower_Whisker = Q1 - 1.5*IQR\n",
    "Upper_Whisker = Q3 + 1.5*IQR\n",
    "\n",
    "df_1 = df_jitter[df_jitter['localabsoluteJitter'] > Upper_Whisker]\n",
    "df_1.append(df_jitter[df_jitter['localabsoluteJitter'] < Lower_Whisker])\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#separate dependent and independent variable for acoustic features only\n",
    "X = df.iloc[:, :-1]\n",
    "df_X = df.iloc[:, :-1].values\n",
    "df_Y = df.iloc[:,-1].values\n",
    "\n",
    "# Split the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_Y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.683159</td>\n",
       "      <td>0.934727</td>\n",
       "      <td>0.514127</td>\n",
       "      <td>0.365714</td>\n",
       "      <td>0.252388</td>\n",
       "      <td>0.420615</td>\n",
       "      <td>0.386582</td>\n",
       "      <td>0.466749</td>\n",
       "      <td>0.463082</td>\n",
       "      <td>0.318015</td>\n",
       "      <td>0.281224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.480170</td>\n",
       "      <td>0.261822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.569791</td>\n",
       "      <td>0.502888</td>\n",
       "      <td>0.657009</td>\n",
       "      <td>0.649233</td>\n",
       "      <td>0.761632</td>\n",
       "      <td>0.693850</td>\n",
       "      <td>0.862800</td>\n",
       "      <td>0.605668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.090560</td>\n",
       "      <td>0.042909</td>\n",
       "      <td>0.506918</td>\n",
       "      <td>0.539225</td>\n",
       "      <td>0.746808</td>\n",
       "      <td>0.250842</td>\n",
       "      <td>0.425005</td>\n",
       "      <td>0.726118</td>\n",
       "      <td>0.703052</td>\n",
       "      <td>0.422196</td>\n",
       "      <td>0.570045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.994842</td>\n",
       "      <td>0.722379</td>\n",
       "      <td>0.545786</td>\n",
       "      <td>0.309113</td>\n",
       "      <td>0.114155</td>\n",
       "      <td>0.280805</td>\n",
       "      <td>0.314770</td>\n",
       "      <td>0.169704</td>\n",
       "      <td>0.231142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.834140</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.111415</td>\n",
       "      <td>0.545052</td>\n",
       "      <td>0.320417</td>\n",
       "      <td>0.500617</td>\n",
       "      <td>0.571964</td>\n",
       "      <td>0.589996</td>\n",
       "      <td>0.625574</td>\n",
       "      <td>0.341612</td>\n",
       "      <td>0.430574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.552909</td>\n",
       "      <td>0.367817</td>\n",
       "      <td>0.533634</td>\n",
       "      <td>0.433380</td>\n",
       "      <td>0.359524</td>\n",
       "      <td>0.374398</td>\n",
       "      <td>0.456565</td>\n",
       "      <td>0.493161</td>\n",
       "      <td>0.466750</td>\n",
       "      <td>0.267652</td>\n",
       "      <td>0.362105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.493679</td>\n",
       "      <td>0.402748</td>\n",
       "      <td>0.328072</td>\n",
       "      <td>0.390382</td>\n",
       "      <td>0.350274</td>\n",
       "      <td>0.326849</td>\n",
       "      <td>0.383806</td>\n",
       "      <td>0.287253</td>\n",
       "      <td>0.293049</td>\n",
       "      <td>0.046075</td>\n",
       "      <td>0.220798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.786174</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.337921</td>\n",
       "      <td>0.375990</td>\n",
       "      <td>0.222888</td>\n",
       "      <td>0.363734</td>\n",
       "      <td>0.369304</td>\n",
       "      <td>0.430656</td>\n",
       "      <td>0.462488</td>\n",
       "      <td>0.289103</td>\n",
       "      <td>0.329359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.614618</td>\n",
       "      <td>0.399953</td>\n",
       "      <td>0.889615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.195013</td>\n",
       "      <td>0.190002</td>\n",
       "      <td>0.115829</td>\n",
       "      <td>0.207765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.816853</td>\n",
       "      <td>0.437984</td>\n",
       "      <td>0.794685</td>\n",
       "      <td>0.185842</td>\n",
       "      <td>0.083057</td>\n",
       "      <td>0.154837</td>\n",
       "      <td>0.183334</td>\n",
       "      <td>0.285719</td>\n",
       "      <td>0.239425</td>\n",
       "      <td>0.211324</td>\n",
       "      <td>0.218521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.700864</td>\n",
       "      <td>0.636256</td>\n",
       "      <td>0.482207</td>\n",
       "      <td>0.375300</td>\n",
       "      <td>0.252123</td>\n",
       "      <td>0.384398</td>\n",
       "      <td>0.547164</td>\n",
       "      <td>0.577768</td>\n",
       "      <td>0.753885</td>\n",
       "      <td>0.462431</td>\n",
       "      <td>0.557817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.742865</td>\n",
       "      <td>0.383990</td>\n",
       "      <td>0.016731</td>\n",
       "      <td>0.109800</td>\n",
       "      <td>0.049823</td>\n",
       "      <td>0.121526</td>\n",
       "      <td>0.136899</td>\n",
       "      <td>0.300104</td>\n",
       "      <td>0.208236</td>\n",
       "      <td>0.192255</td>\n",
       "      <td>0.197484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.406907</td>\n",
       "      <td>0.292622</td>\n",
       "      <td>0.323518</td>\n",
       "      <td>0.238807</td>\n",
       "      <td>0.267768</td>\n",
       "      <td>0.188812</td>\n",
       "      <td>0.220659</td>\n",
       "      <td>0.324978</td>\n",
       "      <td>0.271886</td>\n",
       "      <td>0.182494</td>\n",
       "      <td>0.241995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.956389</td>\n",
       "      <td>0.519176</td>\n",
       "      <td>0.846626</td>\n",
       "      <td>0.195491</td>\n",
       "      <td>0.053206</td>\n",
       "      <td>0.155377</td>\n",
       "      <td>0.286094</td>\n",
       "      <td>0.362372</td>\n",
       "      <td>0.415555</td>\n",
       "      <td>0.083407</td>\n",
       "      <td>0.265298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.183314</td>\n",
       "      <td>0.748748</td>\n",
       "      <td>0.207447</td>\n",
       "      <td>0.549912</td>\n",
       "      <td>0.678122</td>\n",
       "      <td>0.444735</td>\n",
       "      <td>0.717190</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.771460</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.878517</td>\n",
       "      <td>0.808793</td>\n",
       "      <td>0.207746</td>\n",
       "      <td>0.656238</td>\n",
       "      <td>0.375828</td>\n",
       "      <td>0.601039</td>\n",
       "      <td>0.671499</td>\n",
       "      <td>0.692733</td>\n",
       "      <td>0.681796</td>\n",
       "      <td>0.542009</td>\n",
       "      <td>0.515748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.286603</td>\n",
       "      <td>0.692708</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.561147</td>\n",
       "      <td>0.660458</td>\n",
       "      <td>0.582011</td>\n",
       "      <td>0.640740</td>\n",
       "      <td>0.403060</td>\n",
       "      <td>0.471447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.800043</td>\n",
       "      <td>0.587059</td>\n",
       "      <td>0.616969</td>\n",
       "      <td>0.057579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007527</td>\n",
       "      <td>0.031460</td>\n",
       "      <td>0.349004</td>\n",
       "      <td>0.370225</td>\n",
       "      <td>0.181998</td>\n",
       "      <td>0.316385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.507116</td>\n",
       "      <td>0.740410</td>\n",
       "      <td>0.152838</td>\n",
       "      <td>0.014238</td>\n",
       "      <td>0.259766</td>\n",
       "      <td>0.222270</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.004960</td>\n",
       "      <td>0.008294</td>\n",
       "      <td>0.212069</td>\n",
       "      <td>0.367974</td>\n",
       "      <td>0.640116</td>\n",
       "      <td>0.225463</td>\n",
       "      <td>0.355771</td>\n",
       "      <td>0.737220</td>\n",
       "      <td>0.700462</td>\n",
       "      <td>0.576919</td>\n",
       "      <td>0.690740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.653031</td>\n",
       "      <td>0.679960</td>\n",
       "      <td>0.691176</td>\n",
       "      <td>0.285881</td>\n",
       "      <td>0.203509</td>\n",
       "      <td>0.322988</td>\n",
       "      <td>0.341569</td>\n",
       "      <td>0.526876</td>\n",
       "      <td>0.462657</td>\n",
       "      <td>0.562512</td>\n",
       "      <td>0.470020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.374243</td>\n",
       "      <td>0.740990</td>\n",
       "      <td>0.392612</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.930363</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969657</td>\n",
       "      <td>0.887486</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.632931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.687884</td>\n",
       "      <td>0.448478</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.344184</td>\n",
       "      <td>0.233918</td>\n",
       "      <td>0.373195</td>\n",
       "      <td>0.445853</td>\n",
       "      <td>0.627894</td>\n",
       "      <td>0.781902</td>\n",
       "      <td>0.543576</td>\n",
       "      <td>0.505942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.653064</td>\n",
       "      <td>0.540207</td>\n",
       "      <td>0.190435</td>\n",
       "      <td>0.336495</td>\n",
       "      <td>0.243318</td>\n",
       "      <td>0.302831</td>\n",
       "      <td>0.303238</td>\n",
       "      <td>0.322142</td>\n",
       "      <td>0.340903</td>\n",
       "      <td>0.071511</td>\n",
       "      <td>0.187788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.629798</td>\n",
       "      <td>0.903023</td>\n",
       "      <td>0.375639</td>\n",
       "      <td>0.650029</td>\n",
       "      <td>0.490687</td>\n",
       "      <td>0.551607</td>\n",
       "      <td>0.689425</td>\n",
       "      <td>0.867586</td>\n",
       "      <td>0.924690</td>\n",
       "      <td>0.748823</td>\n",
       "      <td>0.809812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0   0.683159  0.934727  0.514127  0.365714  0.252388  0.420615  0.386582   \n",
       "1   0.480170  0.261822  0.000000  0.569791  0.502888  0.657009  0.649233   \n",
       "2   0.090560  0.042909  0.506918  0.539225  0.746808  0.250842  0.425005   \n",
       "3   0.994842  0.722379  0.545786  0.309113  0.114155  0.280805  0.314770   \n",
       "4   0.834140  0.575758  0.111415  0.545052  0.320417  0.500617  0.571964   \n",
       "5   0.552909  0.367817  0.533634  0.433380  0.359524  0.374398  0.456565   \n",
       "6   0.493679  0.402748  0.328072  0.390382  0.350274  0.326849  0.383806   \n",
       "7   0.786174  1.000000  0.337921  0.375990  0.222888  0.363734  0.369304   \n",
       "8   0.614618  0.399953  0.889615  0.000000  0.004697  0.000000  0.000000   \n",
       "9   0.816853  0.437984  0.794685  0.185842  0.083057  0.154837  0.183334   \n",
       "10  0.700864  0.636256  0.482207  0.375300  0.252123  0.384398  0.547164   \n",
       "11  0.742865  0.383990  0.016731  0.109800  0.049823  0.121526  0.136899   \n",
       "12  0.406907  0.292622  0.323518  0.238807  0.267768  0.188812  0.220659   \n",
       "13  0.956389  0.519176  0.846626  0.195491  0.053206  0.155377  0.286094   \n",
       "14  0.183314  0.748748  0.207447  0.549912  0.678122  0.444735  0.717190   \n",
       "15  0.878517  0.808793  0.207746  0.656238  0.375828  0.601039  0.671499   \n",
       "16  0.000000  0.000000  0.286603  0.692708  1.000000  0.561147  0.660458   \n",
       "17  0.800043  0.587059  0.616969  0.057579  0.000000  0.007527  0.031460   \n",
       "18  1.000000  0.507116  0.740410  0.152838  0.014238  0.259766  0.222270   \n",
       "19  0.004960  0.008294  0.212069  0.367974  0.640116  0.225463  0.355771   \n",
       "20  0.653031  0.679960  0.691176  0.285881  0.203509  0.322988  0.341569   \n",
       "21  0.374243  0.740990  0.392612  1.000000  0.930363  1.000000  1.000000   \n",
       "22  0.687884  0.448478  1.000000  0.344184  0.233918  0.373195  0.445853   \n",
       "23  0.653064  0.540207  0.190435  0.336495  0.243318  0.302831  0.303238   \n",
       "24  0.629798  0.903023  0.375639  0.650029  0.490687  0.551607  0.689425   \n",
       "\n",
       "           7         8         9        10  \n",
       "0   0.466749  0.463082  0.318015  0.281224  \n",
       "1   0.761632  0.693850  0.862800  0.605668  \n",
       "2   0.726118  0.703052  0.422196  0.570045  \n",
       "3   0.169704  0.231142  0.000000  0.108383  \n",
       "4   0.589996  0.625574  0.341612  0.430574  \n",
       "5   0.493161  0.466750  0.267652  0.362105  \n",
       "6   0.287253  0.293049  0.046075  0.220798  \n",
       "7   0.430656  0.462488  0.289103  0.329359  \n",
       "8   0.195013  0.190002  0.115829  0.207765  \n",
       "9   0.285719  0.239425  0.211324  0.218521  \n",
       "10  0.577768  0.753885  0.462431  0.557817  \n",
       "11  0.300104  0.208236  0.192255  0.197484  \n",
       "12  0.324978  0.271886  0.182494  0.241995  \n",
       "13  0.362372  0.415555  0.083407  0.265298  \n",
       "14  1.000000  1.000000  0.771460  1.000000  \n",
       "15  0.692733  0.681796  0.542009  0.515748  \n",
       "16  0.582011  0.640740  0.403060  0.471447  \n",
       "17  0.349004  0.370225  0.181998  0.316385  \n",
       "18  0.000000  0.000000  0.002874  0.000000  \n",
       "19  0.737220  0.700462  0.576919  0.690740  \n",
       "20  0.526876  0.462657  0.562512  0.470020  \n",
       "21  0.969657  0.887486  1.000000  0.632931  \n",
       "22  0.627894  0.781902  0.543576  0.505942  \n",
       "23  0.322142  0.340903  0.071511  0.187788  \n",
       "24  0.867586  0.924690  0.748823  0.809812  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale for acoustic features\n",
    "#sc = StandardScaler()\n",
    "sc = MinMaxScaler()\n",
    "#sc = RobustScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *****************KNN Experiments******************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model\n",
    "### without tuning the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.66666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67         6\n",
      "           1       0.67      0.67      0.67         6\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.67      0.67      0.67        12\n",
      "weighted avg       0.67      0.67      0.67        12\n",
      "\n",
      "0.6666666666666667\n",
      "[1 1 0 0 0 1 0 0 1 0 1 1]\n",
      "[[4 2]\n",
      " [2 4]]\n"
     ]
    }
   ],
   "source": [
    "###### KNNN ###########\n",
    "# Fit classifier to the Training set\n",
    "#KNN\n",
    "model_knn = KNeighborsClassifier(n_neighbors = 10)\n",
    "model_knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred_knn = model_knn.predict(X_test)\n",
    "\n",
    "conf_matrix_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "\n",
    "accuracy_knn = ((conf_matrix_knn[0,0] + conf_matrix_knn[1,1])/(conf_matrix_knn[0,0] +conf_matrix_knn[0,1]+conf_matrix_knn[1,0]+conf_matrix_knn[1,1]))*100\n",
    "\n",
    "\n",
    "print(accuracy_knn)\n",
    "\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "#Checking performance our model with ROC Score.\n",
    "print(roc_auc_score(y_test, y_pred_knn))\n",
    "\n",
    "print(y_pred_knn)\n",
    "\n",
    "print(conf_matrix_knn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best leaf_size: 1\n",
      "Best p: 1\n",
      "Best n_neighbors: 9\n",
      "Best Score: 0.76\n",
      "Best Hyperparameters: {'leaf_size': 1, 'n_neighbors': 9, 'p': 1}\n",
      "{'leaf_size': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49], 'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], 'p': [1, 2]}\n",
      "83.33333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         6\n",
      "           1       0.75      1.00      0.86         6\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.88      0.83      0.83        12\n",
      "weighted avg       0.88      0.83      0.83        12\n",
      "\n",
      "0.8333333333333334\n",
      "[1 1 0 0 1 1 0 0 1 1 1 1]\n",
      "[1 0 0 0 1 1 0 0 0 1 1 1]\n",
      "[[4 2]\n",
      " [0 6]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "########Hyperparameter tuning for KNN####################\n",
    "#List Hyperparameters that we want to tune.\n",
    "leaf_size = list(range(1,50))\n",
    "n_neighbors = list(range(1,20)) #neighbours must be < number of samples (22)\n",
    "p=[1,2]\n",
    "#Convert to dictionary\n",
    "hyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)\n",
    "#Create new KNN object\n",
    "knn_2 = KNeighborsClassifier()\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "#Use GridSearch\n",
    "clf = GridSearchCV(knn_2, hyperparameters, cv=10)\n",
    "\n",
    "#clf = RandomizedSearchCV(knn_2, hyperparameters, n_iter=500, cv=8, scoring=\"recall\")\n",
    "#Fit the model\n",
    "best_model = clf.fit(X_train, y_train)\n",
    "#Print The value of best Hyperparameters\n",
    "print('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])\n",
    "print('Best p:', best_model.best_estimator_.get_params()['p'])\n",
    "print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])\n",
    "print('Best Score: %s' % best_model.best_score_)\n",
    "print('Best Hyperparameters: %s' % best_model.best_params_)\n",
    "print(hyperparameters)\n",
    "y_pred_knn_2 = best_model.predict(X_test)\n",
    "\n",
    "conf_matrix_knn_2 = confusion_matrix(y_test, y_pred_knn_2)\n",
    "\n",
    "accuracy_knn_2 = ((conf_matrix_knn_2[0,0] + conf_matrix_knn_2[1,1])/(conf_matrix_knn_2[0,0] +conf_matrix_knn_2[0,1]+conf_matrix_knn_2[1,0]+conf_matrix_knn_2[1,1]))*100\n",
    "\n",
    "\n",
    "print(accuracy_knn_2)\n",
    "\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred_knn_2))\n",
    "#Checking performance our model with ROC Score.\n",
    "print(roc_auc_score(y_test, y_pred_knn_2))\n",
    "\n",
    "print(y_pred_knn_2)\n",
    "print(y_test)\n",
    "\n",
    "print(conf_matrix_knn_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model\n",
    "### using the optimal parameters gotten above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.33333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         6\n",
      "           1       0.75      1.00      0.86         6\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.88      0.83      0.83        12\n",
      "weighted avg       0.88      0.83      0.83        12\n",
      "\n",
      "0.8333333333333334\n",
      "[1 1 0 0 1 1 0 0 1 1 1 1]\n",
      "[1 0 0 0 1 1 0 0 0 1 1 1]\n",
      "[[4 2]\n",
      " [0 6]]\n"
     ]
    }
   ],
   "source": [
    "model_knn = KNeighborsClassifier(n_neighbors = 9, p = 1, leaf_size = 1)\n",
    "model_knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred_knn = model_knn.predict(X_test)\n",
    "\n",
    "conf_matrix_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "\n",
    "accuracy_knn = ((conf_matrix_knn[0,0] + conf_matrix_knn[1,1])/(conf_matrix_knn[0,0] +conf_matrix_knn[0,1]+conf_matrix_knn[1,0]+conf_matrix_knn[1,1]))*100\n",
    "\n",
    "\n",
    "print(accuracy_knn)\n",
    "\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "#Checking performance our model with ROC Score.\n",
    "print(roc_auc_score(y_test, y_pred_knn))\n",
    "\n",
    "print(y_pred_knn)\n",
    "print(y_test)\n",
    "\n",
    "print(conf_matrix_knn)\n",
    "\n",
    "####################using the acoustic + MFCC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation with Leave one out method -IGNORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.649 (0.477)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0]\n",
      "Confusion Matrix for KNN using k-fold (leave one out)\n",
      "[[18  3]\n",
      " [10  6]]\n",
      "64.86486486486487\n"
     ]
    }
   ],
   "source": [
    "df_X = sc.fit_transform(df_X)\n",
    "k_fold = KFold(n_splits=37)\n",
    "#KNN\n",
    "model_knn_kfold = KNeighborsClassifier(n_neighbors = 9, p =1, leaf_size = 1)\n",
    "y_pred_kfold_knn = cross_val_predict(model_knn_kfold, df_X, df_Y, cv=k_fold)\n",
    "\n",
    "scores = cross_val_score(model_knn_kfold, df_X, df_Y, scoring='accuracy', cv=k_fold, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "\n",
    "print(df_Y)\n",
    "print(y_pred_kfold_knn)\n",
    "conf_matrix_knn_kfold = confusion_matrix(df_Y, y_pred_kfold_knn)\n",
    "print(\"Confusion Matrix for KNN using k-fold (leave one out)\")\n",
    "print(conf_matrix_knn_kfold)\n",
    "\n",
    "\n",
    "accuracy_knn_2 = ((conf_matrix_knn_kfold[0,0] + conf_matrix_knn_kfold[1,1])/(conf_matrix_knn_kfold[0,0] +conf_matrix_knn_kfold[0,1]+conf_matrix_knn_kfold[1,0]+conf_matrix_knn_kfold[1,1]))*100\n",
    "\n",
    "\n",
    "print(accuracy_knn_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Fold Evaluation using optimal paramaters. (k =4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divided into 4 parts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:76: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:77: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:76: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:76: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:77: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:76: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Kfold Evaluation for MDVR-KCL Dataset - Classification Accuracy\n",
      "    Loops  fold 1     fold 2     fold 3     fold 4  mean accuracy\n",
      "0       1    70.0  44.444444  66.666667  44.444444      56.388889\n",
      "1       2    70.0  77.777778  55.555556  55.555556      64.722222\n",
      "2       3    70.0  77.777778  55.555556  33.333333      59.166667\n",
      "3       4    60.0  66.666667  44.444444  66.666667      59.444444\n",
      "4       5    70.0  66.666667  55.555556  55.555556      61.944444\n",
      "5       6    60.0  77.777778  88.888889  33.333333      65.000000\n",
      "6       7    60.0  77.777778  66.666667  66.666667      67.777778\n",
      "7       8    70.0  77.777778  66.666667  33.333333      61.944444\n",
      "8       9    40.0  55.555556  66.666667  77.777778      60.000000\n",
      "9      10    50.0  77.777778  55.555556  55.555556      59.722222\n",
      "10     11    80.0  66.666667  55.555556  22.222222      56.111111\n",
      "KNN Kfold Evaluation for MDVR-KCL Dataset - Specificity\n",
      "    Loops      fold 1      fold 2      fold 3      fold 4  mean specificity\n",
      "0       1   80.000000  100.000000   71.428571   80.000000         82.857143\n",
      "1       2   66.666667  100.000000  100.000000  100.000000         91.666667\n",
      "2       3  100.000000   80.000000   80.000000   60.000000         80.000000\n",
      "3       4  100.000000   71.428571  100.000000   80.000000         87.857143\n",
      "4       5  100.000000   80.000000   50.000000  100.000000         82.500000\n",
      "5       6   66.666667   83.333333  100.000000   75.000000         81.250000\n",
      "6       7   75.000000  100.000000   83.333333   66.666667         81.250000\n",
      "7       8   66.666667  100.000000   71.428571  100.000000         84.523810\n",
      "8       9   80.000000   80.000000   80.000000   83.333333         80.833333\n",
      "9      10   66.666667   83.333333  100.000000  100.000000         87.500000\n",
      "10     11  100.000000   40.000000   57.142857  100.000000         74.285714\n",
      "KNN Kfold Evaluation for MDVR-KCL Dataset - Sensitivity/Recall\n",
      "    Loops     fold 1      fold 2     fold 3     fold 4  \\\n",
      "0       1  60.000000    0.000000  50.000000   0.000000   \n",
      "1       2  75.000000   50.000000   0.000000   0.000000   \n",
      "2       3  25.000000   75.000000  25.000000   0.000000   \n",
      "3       4  20.000000   50.000000   0.000000  50.000000   \n",
      "4       5  25.000000   50.000000  66.666667  20.000000   \n",
      "5       6  50.000000   66.666667  75.000000   0.000000   \n",
      "6       7  50.000000   50.000000  33.333333  66.666667   \n",
      "7       8  75.000000   50.000000  50.000000   0.000000   \n",
      "8       9   0.000000   25.000000  50.000000  66.666667   \n",
      "9      10  25.000000   66.666667   0.000000  20.000000   \n",
      "10     11  33.333333  100.000000  50.000000   0.000000   \n",
      "\n",
      "    mean sensitivity/recall  \n",
      "0                 27.500000  \n",
      "1                 31.250000  \n",
      "2                 31.250000  \n",
      "3                 30.000000  \n",
      "4                 40.416667  \n",
      "5                 47.916667  \n",
      "6                 50.000000  \n",
      "7                 43.750000  \n",
      "8                 35.416667  \n",
      "9                 27.916667  \n",
      "10                45.833333  \n",
      "KNN Kfold Evaluation for MDVR-KCL Dataset - Precision\n",
      "    Loops      fold 1      fold 2      fold 3      fold 4  mean precision\n",
      "0       1   75.000000         NaN   33.333333    0.000000             NaN\n",
      "1       2   60.000000  100.000000         NaN         NaN             NaN\n",
      "2       3  100.000000   75.000000   50.000000    0.000000       56.250000\n",
      "3       4  100.000000   33.333333         NaN   66.666667             NaN\n",
      "4       5  100.000000   66.666667   40.000000  100.000000       76.666667\n",
      "5       6   50.000000   66.666667  100.000000    0.000000       54.166667\n",
      "6       7   75.000000  100.000000   50.000000   50.000000       68.750000\n",
      "7       8   60.000000  100.000000   33.333333         NaN             NaN\n",
      "8       9    0.000000   50.000000   66.666667   66.666667       45.833333\n",
      "9      10   33.333333   66.666667         NaN  100.000000             NaN\n",
      "10     11  100.000000   57.142857   25.000000         NaN             NaN\n",
      "KNN Kfold Evaluation for MDVR-KCL Dataset - F1 score\n",
      "    Loops     fold 1     fold 2     fold 3     fold 4  mean f1 score\n",
      "0       1  66.666667        NaN  40.000000        NaN            NaN\n",
      "1       2  66.666667  66.666667        NaN        NaN            NaN\n",
      "2       3  40.000000  75.000000  33.333333        NaN            NaN\n",
      "3       4  33.333333  40.000000        NaN  57.142857            NaN\n",
      "4       5  40.000000  57.142857  50.000000  33.333333      45.119048\n",
      "5       6  50.000000  66.666667  85.714286        NaN            NaN\n",
      "6       7  60.000000  66.666667  40.000000  57.142857      55.952381\n",
      "7       8  66.666667  66.666667  40.000000        NaN            NaN\n",
      "8       9        NaN  33.333333  57.142857  66.666667            NaN\n",
      "9      10  28.571429  66.666667        NaN  33.333333            NaN\n",
      "10     11  50.000000  72.727273  33.333333        NaN            NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:77: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:76: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:77: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:76: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:76: RuntimeWarning: invalid value encountered in longlong_scalars\n"
     ]
    }
   ],
   "source": [
    "#df_kfold = shuffle(df)\n",
    "#df_kfold.reset_index(inplace=True, drop=True)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "df_kfold = df\n",
    "df_Xnew = df_kfold.iloc[:, :-1].values\n",
    "df_Ynew = df_kfold.iloc[:,-1].values\n",
    "\n",
    "\n",
    "X_kfold = pd.DataFrame(df_Xnew)\n",
    "y_kfold = pd.DataFrame(df_Ynew)\n",
    "#print(X_kfold)\n",
    "#print(y_kfold)\n",
    "\n",
    "parts = 4\n",
    "kfold = KFold(parts, True, None) \n",
    "\n",
    "# splits into 5 groups \n",
    "print(\"Divided into %s parts.\" %parts)\n",
    "\n",
    "k_list = []\n",
    "k_specificity = []\n",
    "k_sensitivity = []\n",
    "k_precision = []\n",
    "k_f1 = []\n",
    "for i in range (1,12):\n",
    "    row = []\n",
    "    row_specificity = []\n",
    "    row_sensitivity = []\n",
    "    row_precision = []\n",
    "    row_f1 = []\n",
    "    \n",
    "    row.append(i)\n",
    "    row_specificity.append(i)\n",
    "    row_sensitivity.append(i)\n",
    "    row_precision.append(i)\n",
    "    row_f1.append(i)\n",
    "    \n",
    "    total = 0\n",
    "    total_specificity = 0\n",
    "    total_sensitivity = 0\n",
    "    total_precision = 0\n",
    "    total_f1 = 0\n",
    "    \n",
    "    #print(\"Loop\", i)\n",
    "    for train, test in kfold.split(X_kfold,y_kfold):\n",
    "        #print('\\ntrain: %s, test: %s' % (train, test))\n",
    "        Xtrain_kfold = X_kfold.iloc[train, :]\n",
    "        Ytrain_kfold = y_kfold.iloc[train, :]\n",
    "        Xtest_kfold = X_kfold.iloc[test, :]\n",
    "        Ytest_kfold = y_kfold.iloc[test, :]\n",
    "        #print(Xtest_kfold)\n",
    "        #print(Ytest_kfold)\n",
    "        #print(Ytrain_kfold)\n",
    "\n",
    "        Xtrain_kfold = sc.fit_transform(Xtrain_kfold)\n",
    "        Xtest_kfold = sc.transform(Xtest_kfold)\n",
    "\n",
    "        #modelling\n",
    "        model_knn_new = KNeighborsClassifier(n_neighbors = 9, p =1, leaf_size = 1)\n",
    "        model_knn_new.fit(Xtrain_kfold, Ytrain_kfold)\n",
    "        y_pred_knn_new = model_knn_new.predict(Xtest_kfold)\n",
    "\n",
    "        conf_matrix_knn_kfold = confusion_matrix(Ytest_kfold, y_pred_knn_new)\n",
    "        TN = conf_matrix_knn_kfold[0][0]\n",
    "        FP = conf_matrix_knn_kfold[0][1]\n",
    "        FN = conf_matrix_knn_kfold[1][0]\n",
    "        TP = conf_matrix_knn_kfold[1][1]\n",
    "        \n",
    "        \n",
    "        #total = (conf_matrix_knn_kfold[0,0] +conf_matrix_knn_kfold[0,1]+conf_matrix_knn_kfold[1,0]+conf_matrix_knn_kfold[1,1])\n",
    "\n",
    "        #accuracy_knn_kfold = ((conf_matrix_knn_kfold[0,0] + conf_matrix_knn_kfold[1,1])/total)*100\n",
    "        accuracy_knn_kfold = ((TP + TN) / (TP + TN + FP + FN)) * 100\n",
    "        sensitivity_knn_kfold = (TP/(TP+FN)) * 100 #recall\n",
    "        specificity_knn_kfold = (TN/(TN + FP)) * 100\n",
    "        precision_knn_kfold = (TP/(TP+FP)) * 100\n",
    "        f1_knn_kfold = 2 *((sensitivity_knn_kfold * precision_knn_kfold)/(sensitivity_knn_kfold + precision_knn_kfold))\n",
    "        #sensitivity_knn_kfold = ((conf_matrix_knn_kfold[0,0] + conf_matrix_knn_kfold[1,1])/total)*100\n",
    "\n",
    "        #print(\"Confusion Matrix:\\n \", conf_matrix_knn_kfold)\n",
    "        #print(\"Accuracy \", accuracy_knn_kfold)\n",
    "\n",
    "        row.append(accuracy_knn_kfold)\n",
    "        row_specificity.append(specificity_knn_kfold)\n",
    "        row_sensitivity.append(sensitivity_knn_kfold)\n",
    "        row_precision.append(precision_knn_kfold)\n",
    "        row_f1.append(f1_knn_kfold)\n",
    "        \n",
    "        total += accuracy_knn_kfold\n",
    "        total_specificity += specificity_knn_kfold\n",
    "        total_sensitivity += sensitivity_knn_kfold\n",
    "        total_precision += precision_knn_kfold\n",
    "        total_f1 += f1_knn_kfold\n",
    "        \n",
    "        #plot roc only for the first iteration\n",
    "        #if i == 1:\n",
    "           # metrics.plot_roc_curve(model_knn_new, Xtest_kfold, Ytest_kfold,name='ROC fold {}'.format(j),\n",
    "                     #    alpha=0.3, lw=1, ax=ax)\n",
    "        \n",
    "        \n",
    "    average = row.append(total/parts)\n",
    "    \n",
    "    row_specificity.append(total_specificity/parts)\n",
    "    row_sensitivity.append(total_sensitivity/parts)\n",
    "    row_precision.append(total_precision/parts)\n",
    "    row_f1.append(total_f1/parts)\n",
    "        \n",
    "    #print(row)\n",
    "    k_list.append(row)\n",
    "    k_specificity.append(row_specificity)\n",
    "    k_sensitivity.append(row_sensitivity)\n",
    "    k_precision.append(row_precision)\n",
    "    k_f1.append(row_f1)\n",
    "    \n",
    "      \n",
    "k_list = pd.DataFrame(k_list, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean accuracy'])\n",
    "print(\"KNN Kfold Evaluation for MDVR-KCL Dataset - Classification Accuracy\")\n",
    "print(k_list)\n",
    "    \n",
    "\n",
    "k_specificity = pd.DataFrame(k_specificity, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean specificity'])\n",
    "print(\"KNN Kfold Evaluation for MDVR-KCL Dataset - Specificity\")\n",
    "print(k_specificity)\n",
    "\n",
    "k_sensitivity = pd.DataFrame(k_sensitivity, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean sensitivity/recall'])\n",
    "print(\"KNN Kfold Evaluation for MDVR-KCL Dataset - Sensitivity/Recall\")\n",
    "print(k_sensitivity)\n",
    "\n",
    "k_precision = pd.DataFrame(k_precision, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean precision'])\n",
    "print(\"KNN Kfold Evaluation for MDVR-KCL Dataset - Precision\")\n",
    "print(k_precision)\n",
    "\n",
    "k_f1 = pd.DataFrame(k_f1, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean f1 score'])\n",
    "print(\"KNN Kfold Evaluation for MDVR-KCL Dataset - F1 score\")\n",
    "print(k_f1)\n",
    "    \n",
    "    \n",
    "    \n",
    "#print(df.sample(n=7))\n",
    "#print(df)\n",
    "\n",
    "#x = df.take(np.random.permutation(len(df))[:4])\n",
    "#x= df.sample(n=7)\n",
    "#print(x)\n",
    "#print(df.drop(x))\n",
    "\n",
    "#drop_indices = np.random.choice(df.index, 4, replace=False)\n",
    "#df_subset = df.drop(drop_indices)\n",
    "#print(drop_indices)\n",
    "#print(df_subset)\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# *****************Decision Tree Experiments***************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model\n",
    "### without tuning the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73         6\n",
      "           1       0.71      0.83      0.77         6\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.76      0.75      0.75        12\n",
      "weighted avg       0.76      0.75      0.75        12\n",
      "\n",
      "0.7500000000000002\n",
      "[1 1 0 0 1 1 0 0 1 0 1 1]\n",
      "[[4 2]\n",
      " [1 5]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(334.8, 684.9359999999999, 'X[1] <= 0.277\\ngini = 0.48\\nsamples = 25\\nvalue = [15, 10]'),\n",
       " Text(167.4, 532.728, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
       " Text(502.20000000000005, 532.728, 'X[6] <= 0.254\\ngini = 0.408\\nsamples = 21\\nvalue = [15, 6]'),\n",
       " Text(334.8, 380.52, 'gini = 0.0\\nsamples = 6\\nvalue = [6, 0]'),\n",
       " Text(669.6, 380.52, 'X[3] <= 0.376\\ngini = 0.48\\nsamples = 15\\nvalue = [9, 6]'),\n",
       " Text(334.8, 228.312, 'X[0] <= 0.668\\ngini = 0.408\\nsamples = 7\\nvalue = [2, 5]'),\n",
       " Text(167.4, 76.10399999999993, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(502.20000000000005, 76.10399999999993, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 5]'),\n",
       " Text(1004.4000000000001, 228.312, 'X[0] <= 0.279\\ngini = 0.219\\nsamples = 8\\nvalue = [7, 1]'),\n",
       " Text(837.0, 76.10399999999993, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(1171.8, 76.10399999999993, 'gini = 0.0\\nsamples = 7\\nvalue = [7, 0]')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x1008 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###### KNNN ###########\n",
    "# Fit classifier to the Training set\n",
    "#Decision Tree\n",
    "import matplotlib.pyplot as plt\n",
    "model_dt = tree.DecisionTreeClassifier()\n",
    "model_dt = model_dt.fit(X_train, y_train)\n",
    "\n",
    "y_pred_knn = model_dt.predict(X_test)\n",
    "\n",
    "conf_matrix_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "\n",
    "accuracy_knn = ((conf_matrix_knn[0,0] + conf_matrix_knn[1,1])/(conf_matrix_knn[0,0] +conf_matrix_knn[0,1]+conf_matrix_knn[1,0]+conf_matrix_knn[1,1]))*100\n",
    "\n",
    "\n",
    "print(accuracy_knn)\n",
    "\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "#Checking performance our model with ROC Score.\n",
    "print(roc_auc_score(y_test, y_pred_knn))\n",
    "\n",
    "print(y_pred_knn)\n",
    "\n",
    "print(conf_matrix_knn)\n",
    "\n",
    "plt.figure(figsize=(24,14))\n",
    "tree.plot_tree(model_dt, filled=True, fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning for Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.6\n",
      "Best Hyperparameters: {'criterion': 'gini', 'max_depth': 1, 'min_samples_leaf': 1, 'min_samples_split': 3}\n",
      "{'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9], 'min_samples_leaf': [1, 2, 3, 4], 'criterion': ['gini', 'entropy']}\n",
      "75.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73         6\n",
      "           1       0.71      0.83      0.77         6\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.76      0.75      0.75        12\n",
      "weighted avg       0.76      0.75      0.75        12\n",
      "\n",
      "0.7500000000000002\n",
      "[1 1 0 0 1 1 0 0 1 0 1 1]\n",
      "[1 0 0 0 1 1 0 0 0 1 1 1]\n",
      "[[4 2]\n",
      " [1 5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "########Hyperparameter tuning for KNN####################\n",
    "#List Hyperparameters that we want to tune.\n",
    "#n_components = list(range(1,X.shape[1]+1,1))\n",
    "max_depth = list(range(1,10))\n",
    "min_samples_split = list(range(2,10)) #neighbours must be < number of samples (22)\n",
    "min_samples_leaf = list(range(1,5))\n",
    "criterion=['gini','entropy']\n",
    "#Convert to dictionary\n",
    "hyperparameters = dict(max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, criterion = criterion)\n",
    "#Create new KNN object\n",
    "dt_2 = tree.DecisionTreeClassifier()\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=4, n_repeats=3, random_state=1)\n",
    "\n",
    "#Use GridSearch\n",
    "clf = GridSearchCV(dt_2, hyperparameters, refit=True)\n",
    "\n",
    "#clf = RandomizedSearchCV(knn_2, hyperparameters, n_iter=500, cv=8, scoring=\"recall\")\n",
    "#Fit the model\n",
    "best_model = clf.fit(X_train, y_train)\n",
    "#Print The value of best Hyperparameters\n",
    "#print('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])\n",
    "#print('Best p:', best_model.best_estimator_.get_params()['p'])\n",
    "#print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])\n",
    "print('Best Score: %s' % best_model.best_score_)\n",
    "print('Best Hyperparameters: %s' % best_model.best_params_)\n",
    "print(hyperparameters)\n",
    "y_pred_knn_2 = best_model.predict(X_test)\n",
    "\n",
    "conf_matrix_knn_2 = confusion_matrix(y_test, y_pred_knn_2)\n",
    "\n",
    "accuracy_knn_2 = ((conf_matrix_knn_2[0,0] + conf_matrix_knn_2[1,1])/(conf_matrix_knn_2[0,0] +conf_matrix_knn_2[0,1]+conf_matrix_knn_2[1,0]+conf_matrix_knn_2[1,1]))*100\n",
    "\n",
    "\n",
    "print(accuracy_knn_2)\n",
    "\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred_knn_2))\n",
    "#Checking performance our model with ROC Score.\n",
    "print(roc_auc_score(y_test, y_pred_knn_2))\n",
    "\n",
    "print(y_pred_knn_2)\n",
    "print(y_test)\n",
    "\n",
    "print(conf_matrix_knn_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model (Decision Tree)\n",
    "### using the optimal parameters gotten above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 2]\n",
      " [1 5]]\n",
      "75.0\n"
     ]
    }
   ],
   "source": [
    "#model_dt = tree.DecisionTreeClassifier(max_depth = 6, criterion='entropy',min_samples_leaf=2, min_samples_split=2 )\n",
    "model_dt = tree.DecisionTreeClassifier(max_depth = 1, criterion='gini',min_samples_leaf=1, min_samples_split=2 )\n",
    "model_dt = model_dt.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dt_2 = best_model.predict(X_test)\n",
    "\n",
    "conf_matrix_dt_2 = confusion_matrix(y_test, y_pred_dt_2)\n",
    "\n",
    "accuracy_dt_2 = ((conf_matrix_dt_2[0,0] + conf_matrix_dt_2[1,1])/(conf_matrix_dt_2[0,0] +conf_matrix_dt_2[0,1]+conf_matrix_dt_2[1,0]+conf_matrix_dt_2[1,1]))*100\n",
    "\n",
    "print(conf_matrix_dt_2)\n",
    "print(accuracy_dt_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation with Leave one out method - IGNORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.568 (0.495)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0]\n",
      "Confusion Matrix for Dt using k-fold (leave one out)\n",
      "[[17  4]\n",
      " [11  5]]\n",
      "59.45945945945946\n"
     ]
    }
   ],
   "source": [
    "df_X = sc.fit_transform(df_X)\n",
    "k_fold = KFold(n_splits=37)\n",
    "#KNN\n",
    "#model_knn_kfold = tree.DecisionTreeClassifier(max_depth = 6, criterion='entropy',min_samples_leaf=2, min_samples_split=2 )\n",
    "model_dt = tree.DecisionTreeClassifier(max_depth = 1, criterion='gini',min_samples_leaf=1, min_samples_split=2 )\n",
    "y_pred_kfold_knn = cross_val_predict(model_dt, df_X, df_Y, cv=k_fold)\n",
    "scores = cross_val_score(model_dt, df_X, df_Y, scoring='accuracy', cv=k_fold, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "\n",
    "print(df_Y)\n",
    "print(y_pred_kfold_knn)\n",
    "conf_matrix_knn_kfold = confusion_matrix(df_Y, y_pred_kfold_knn)\n",
    "print(\"Confusion Matrix for Dt using k-fold (leave one out)\")\n",
    "print(conf_matrix_knn_kfold)\n",
    "\n",
    "\n",
    "accuracy_knn_2 = ((conf_matrix_knn_kfold[0,0] + conf_matrix_knn_kfold[1,1])/(conf_matrix_knn_kfold[0,0] +conf_matrix_knn_kfold[0,1]+conf_matrix_knn_kfold[1,0]+conf_matrix_knn_kfold[1,1]))*100\n",
    "\n",
    "\n",
    "print(accuracy_knn_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Fold Evaluation using optimal paramaters. (k =4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divided into 4 parts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:77: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:77: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:76: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:76: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:76: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:76: RuntimeWarning: invalid value encountered in longlong_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decsion Tree Kfold Evaluation for MDVR-KCL Dataset Classification Accuracy\n",
      "    Loops  fold 1     fold 2     fold 3     fold 4  mean accuracy\n",
      "0       1    50.0  55.555556  55.555556  55.555556      54.166667\n",
      "1       2    50.0  55.555556  77.777778  44.444444      56.944444\n",
      "2       3    60.0  77.777778  66.666667  66.666667      67.777778\n",
      "3       4    50.0  55.555556  77.777778  55.555556      59.722222\n",
      "4       5    60.0  55.555556  66.666667  66.666667      62.222222\n",
      "5       6    60.0  44.444444  77.777778  66.666667      62.222222\n",
      "6       7    60.0  44.444444  66.666667  55.555556      56.666667\n",
      "7       8    60.0  55.555556  88.888889  55.555556      65.000000\n",
      "8       9    70.0  44.444444  55.555556  22.222222      48.055556\n",
      "9      10    70.0  55.555556  66.666667  55.555556      61.944444\n",
      "10     11    50.0  77.777778  22.222222  44.444444      48.611111\n",
      "Decsion Tree Kfold Evaluation for MDVR-KCL Dataset - Specificity\n",
      "    Loops      fold 1      fold 2      fold 3      fold 4  mean specificity\n",
      "0       1   55.555556   75.000000   50.000000   75.000000         63.888889\n",
      "1       2   33.333333   60.000000  100.000000   80.000000         68.333333\n",
      "2       3   80.000000   85.714286   50.000000  100.000000         78.928571\n",
      "3       4   66.666667   60.000000  100.000000  100.000000         81.666667\n",
      "4       5   57.142857   50.000000   66.666667  100.000000         68.452381\n",
      "5       6   66.666667   42.857143   83.333333   80.000000         68.214286\n",
      "6       7   66.666667  100.000000  100.000000   60.000000         81.666667\n",
      "7       8   75.000000  100.000000   87.500000   25.000000         71.875000\n",
      "8       9   85.714286   40.000000  100.000000   33.333333         64.761905\n",
      "9      10  100.000000  100.000000   66.666667   50.000000         79.166667\n",
      "10     11   42.857143   80.000000    0.000000   42.857143         41.428571\n",
      "Decsion Tree Kfold Evaluation for MDVR-KCL Dataset - Sensitivity/Recall\n",
      "    Loops     fold 1     fold 2      fold 3  fold 4  mean sensitivity/recall\n",
      "0       1   0.000000  40.000000   60.000000    40.0                35.000000\n",
      "1       2  75.000000  50.000000   50.000000     0.0                43.750000\n",
      "2       3  40.000000  50.000000   80.000000    25.0                48.750000\n",
      "3       4  25.000000  50.000000   50.000000     0.0                31.250000\n",
      "4       5  66.666667  66.666667   66.666667    25.0                56.250000\n",
      "5       6  57.142857  50.000000   66.666667    50.0                55.952381\n",
      "6       7  50.000000   0.000000    0.000000    50.0                25.000000\n",
      "7       8  50.000000   0.000000  100.000000    80.0                57.500000\n",
      "8       9  33.333333  50.000000   33.333333     0.0                29.166667\n",
      "9      10  50.000000  33.333333   66.666667   100.0                62.500000\n",
      "10     11  66.666667  75.000000   28.571429    50.0                55.059524\n",
      "Decsion Tree Kfold Evaluation for MDVR-KCL Dataset - Precision\n",
      "    Loops      fold 1      fold 2      fold 3      fold 4  mean precision\n",
      "0       1    0.000000   66.666667   60.000000   66.666667       48.333333\n",
      "1       2   42.857143   50.000000  100.000000    0.000000       48.214286\n",
      "2       3   66.666667   50.000000   66.666667  100.000000       70.833333\n",
      "3       4   33.333333   50.000000  100.000000         NaN             NaN\n",
      "4       5   40.000000   40.000000   80.000000  100.000000       65.000000\n",
      "5       6   80.000000   20.000000   66.666667   66.666667       58.333333\n",
      "6       7   50.000000         NaN         NaN   50.000000             NaN\n",
      "7       8   75.000000         NaN   50.000000   57.142857             NaN\n",
      "8       9   50.000000   40.000000  100.000000    0.000000       47.500000\n",
      "9      10  100.000000  100.000000   50.000000   20.000000       67.500000\n",
      "10     11   33.333333   75.000000   50.000000   20.000000       44.583333\n",
      "Decsion Tree Kfold Evaluation for MDVR-KCL Dataset - F1 score\n",
      "    Loops     fold 1     fold 2     fold 3     fold 4  mean f1 score\n",
      "0       1        NaN  50.000000  60.000000  50.000000            NaN\n",
      "1       2  54.545455  50.000000  66.666667        NaN            NaN\n",
      "2       3  50.000000  50.000000  72.727273  40.000000      53.181818\n",
      "3       4  28.571429  50.000000  66.666667        NaN            NaN\n",
      "4       5  50.000000  50.000000  72.727273  40.000000      53.181818\n",
      "5       6  66.666667  28.571429  66.666667  57.142857      54.761905\n",
      "6       7  50.000000        NaN        NaN  50.000000            NaN\n",
      "7       8  60.000000        NaN  66.666667  66.666667            NaN\n",
      "8       9  40.000000  44.444444  50.000000        NaN            NaN\n",
      "9      10  66.666667  50.000000  57.142857  33.333333      51.785714\n",
      "10     11  44.444444  75.000000  36.363636  28.571429      46.094877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:77: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "#df_kfold = shuffle(df)\n",
    "#df_kfold.reset_index(inplace=True, drop=True)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "df_kfold = df\n",
    "df_Xnew = df_kfold.iloc[:, :-1].values\n",
    "df_Ynew = df_kfold.iloc[:,-1].values\n",
    "\n",
    "\n",
    "X_kfold = pd.DataFrame(df_Xnew)\n",
    "y_kfold = pd.DataFrame(df_Ynew)\n",
    "#print(X_kfold)\n",
    "#print(y_kfold)\n",
    "\n",
    "parts = 4\n",
    "kfold = KFold(parts, True, None) \n",
    "\n",
    "# splits into 5 groups \n",
    "print(\"Divided into %s parts.\" %parts)\n",
    "\n",
    "k_dt_list = []\n",
    "k_dt_specificity = []\n",
    "k_dt_sensitivity = []\n",
    "k_dt_precision = []\n",
    "k_dt_f1 = []\n",
    "\n",
    "for i in range (1,12):\n",
    "    row = []\n",
    "    row_specificity = []\n",
    "    row_sensitivity = []\n",
    "    row_precision = []\n",
    "    row_f1 = []\n",
    "    \n",
    "    row.append(i)\n",
    "    row_specificity.append(i)\n",
    "    row_sensitivity.append(i)\n",
    "    row_precision.append(i)\n",
    "    row_f1.append(i)\n",
    "    \n",
    "    total = 0\n",
    "    total_specificity = 0\n",
    "    total_sensitivity = 0\n",
    "    total_precision = 0\n",
    "    total_f1 = 0\n",
    "    #print(\"Loop\", i)\n",
    "    for train, test in kfold.split(X_kfold,y_kfold):\n",
    "        #print('\\ntrain: %s, test: %s' % (train, test))\n",
    "        Xtrain_kfold = X_kfold.iloc[train, :]\n",
    "        Ytrain_kfold = y_kfold.iloc[train, :]\n",
    "        Xtest_kfold = X_kfold.iloc[test, :]\n",
    "        Ytest_kfold = y_kfold.iloc[test, :]\n",
    "        #print(Xtest_kfold)\n",
    "        #print(Ytest_kfold)\n",
    "\n",
    "        Xtrain_kfold = sc.fit_transform(Xtrain_kfold)\n",
    "        Xtest_kfold = sc.transform(Xtest_kfold)\n",
    "\n",
    "        #modelling\n",
    "        #model_knn_new = tree.DecisionTreeClassifier(max_depth = 6, criterion='entropy',min_samples_leaf=2, min_samples_split=2 )\n",
    "        model_dt_new = tree.DecisionTreeClassifier(max_depth = 1, criterion='gini',min_samples_leaf=1, min_samples_split=2 )\n",
    "        model_dt_new.fit(Xtrain_kfold, Ytrain_kfold)\n",
    "        y_pred_dt_new = model_dt_new.predict(Xtest_kfold)\n",
    "\n",
    "        #conf_matrix_dt_kfold = confusion_matrix(Ytest_kfold, y_pred_dt_new)\n",
    "        conf_matrix_knn_kfold = confusion_matrix(Ytest_kfold, y_pred_dt_new)\n",
    "\n",
    "        #accuracy_dt_kfold = ((conf_matrix_dt_kfold[0,0] + conf_matrix_dt_kfold[1,1])/(conf_matrix_dt_kfold[0,0] +conf_matrix_dt_kfold[0,1]+conf_matrix_dt_kfold[1,0]+conf_matrix_dt_kfold[1,1]))*100\n",
    "        TN = conf_matrix_knn_kfold[0][0]\n",
    "        FP = conf_matrix_knn_kfold[0][1]\n",
    "        FN = conf_matrix_knn_kfold[1][0]\n",
    "        TP = conf_matrix_knn_kfold[1][1]\n",
    "        \n",
    "    \n",
    "        accuracy_knn_kfold = ((TP + TN) / (TP + TN + FP + FN)) * 100\n",
    "        sensitivity_knn_kfold = (TP/(TP+FN)) * 100 #recall\n",
    "        specificity_knn_kfold = (TN/(TN + FP)) * 100\n",
    "        precision_knn_kfold = (TP/(TP+FP)) *100\n",
    "        f1_knn_kfold = 2 *((sensitivity_knn_kfold * precision_knn_kfold)/(sensitivity_knn_kfold + precision_knn_kfold))\n",
    "\n",
    "\n",
    "        row.append(accuracy_knn_kfold)\n",
    "        row_specificity.append(specificity_knn_kfold)\n",
    "        row_sensitivity.append(sensitivity_knn_kfold)\n",
    "        row_precision.append(precision_knn_kfold)\n",
    "        row_f1.append(f1_knn_kfold)\n",
    "        \n",
    "        total += accuracy_knn_kfold\n",
    "        total_specificity += specificity_knn_kfold\n",
    "        total_sensitivity += sensitivity_knn_kfold\n",
    "        total_precision += precision_knn_kfold\n",
    "        total_f1 += f1_knn_kfold\n",
    "\n",
    "    average = row.append(total/parts)   \n",
    "    row_specificity.append(total_specificity/parts)\n",
    "    row_sensitivity.append(total_sensitivity/parts)\n",
    "    row_precision.append(total_precision/parts)\n",
    "    row_f1.append(total_f1/parts)\n",
    "        \n",
    "    #print(row)\n",
    "    k_dt_list.append(row)\n",
    "    k_dt_specificity.append(row_specificity)\n",
    "    k_dt_sensitivity.append(row_sensitivity)\n",
    "    k_dt_precision.append(row_precision)\n",
    "    k_dt_f1.append(row_f1)\n",
    "    \n",
    "k_dt_list = pd.DataFrame(k_dt_list, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean accuracy'])\n",
    "print(\"Decsion Tree Kfold Evaluation for MDVR-KCL Dataset Classification Accuracy\")\n",
    "print(k_dt_list)    \n",
    "\n",
    "k_dt_specificity = pd.DataFrame(k_dt_specificity, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean specificity'])\n",
    "print(\"Decsion Tree Kfold Evaluation for MDVR-KCL Dataset - Specificity\")\n",
    "print(k_dt_specificity)\n",
    "\n",
    "k_dt_sensitivity = pd.DataFrame(k_dt_sensitivity, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean sensitivity/recall'])\n",
    "print(\"Decsion Tree Kfold Evaluation for MDVR-KCL Dataset - Sensitivity/Recall\")\n",
    "print(k_dt_sensitivity)\n",
    "\n",
    "k_dt_precision = pd.DataFrame(k_dt_precision, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean precision'])\n",
    "print(\"Decsion Tree Kfold Evaluation for MDVR-KCL Dataset - Precision\")\n",
    "print(k_dt_precision)\n",
    "\n",
    "k_dt_f1 = pd.DataFrame(k_dt_f1, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean f1 score'])\n",
    "print(\"Decsion Tree Kfold Evaluation for MDVR-KCL Dataset - F1 score\")\n",
    "print(k_dt_f1)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# *****************SVM Experiments***************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model\n",
    "### without tuning the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.67      0.57         6\n",
      "           1       0.50      0.33      0.40         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.50      0.50      0.49        12\n",
      "weighted avg       0.50      0.50      0.49        12\n",
      "\n",
      "0.5\n",
      "[0 1 0 0 1 0 0 0 1 0 1 0]\n",
      "[[4 2]\n",
      " [4 2]]\n"
     ]
    }
   ],
   "source": [
    "###### KNNN ###########\n",
    "# Fit classifier to the Training set\n",
    "#Decision Tree\n",
    "import matplotlib.pyplot as plt\n",
    "model_svm = svm.SVC()\n",
    "model_svm = model_dt.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = model_dt.predict(X_test)\n",
    "\n",
    "conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "\n",
    "accuracy_svm = ((conf_matrix_svm[0,0] + conf_matrix_svm[1,1])/(conf_matrix_svm[0,0] +conf_matrix_svm[0,1]+conf_matrix_svm[1,0]+conf_matrix_svm[1,1]))*100\n",
    "\n",
    "\n",
    "print(accuracy_svm)\n",
    "\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "#Checking performance our model with ROC Score.\n",
    "print(roc_auc_score(y_test, y_pred_svm))\n",
    "\n",
    "print(y_pred_svm)\n",
    "\n",
    "print(conf_matrix_svm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.68\n",
      "Best Hyperparameters: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "{'C': [0.1, 1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'kernel': ['rbf']}\n",
      "66.66666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67         6\n",
      "           1       0.67      0.67      0.67         6\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.67      0.67      0.67        12\n",
      "weighted avg       0.67      0.67      0.67        12\n",
      "\n",
      "0.6666666666666667\n",
      "[1 1 0 0 1 1 0 0 1 0 1 0]\n",
      "[1 0 0 0 1 1 0 0 0 1 1 1]\n",
      "[[4 2]\n",
      " [2 4]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "########Hyperparameter tuning for SVM####################\n",
    "#List Hyperparameters that we want to tune.\n",
    "#n_components = list(range(1,X.shape[1]+1,1))\n",
    "C = [0.1, 1, 10, 100, 1000]\n",
    "gamma = [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "kernel = ['rbf']\n",
    "\n",
    "#Convert to dictionary\n",
    "hyperparameters = dict(C=C, gamma=gamma, kernel=kernel)\n",
    "#Create new KNN object\n",
    "svm2 = svm.SVC()\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "#Use GridSearch\n",
    "clf = GridSearchCV(svm2, hyperparameters, refit=True)\n",
    "\n",
    "#clf = RandomizedSearchCV(knn_2, hyperparameters, n_iter=500, cv=8, scoring=\"recall\")\n",
    "#Fit the model\n",
    "best_model = clf.fit(X_train, y_train)\n",
    "#Print The value of best Hyperparameters\n",
    "#print('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])\n",
    "#print('Best p:', best_model.best_estimator_.get_params()['p'])\n",
    "#print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])\n",
    "print('Best Score: %s' % best_model.best_score_)\n",
    "print('Best Hyperparameters: %s' % best_model.best_params_)\n",
    "print(hyperparameters)\n",
    "y_pred_knn_2 = best_model.predict(X_test)\n",
    "\n",
    "conf_matrix_knn_2 = confusion_matrix(y_test, y_pred_knn_2)\n",
    "\n",
    "accuracy_knn_2 = ((conf_matrix_knn_2[0,0] + conf_matrix_knn_2[1,1])/(conf_matrix_knn_2[0,0] +conf_matrix_knn_2[0,1]+conf_matrix_knn_2[1,0]+conf_matrix_knn_2[1,1]))*100\n",
    "\n",
    "\n",
    "print(accuracy_knn_2)\n",
    "\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred_knn_2))\n",
    "#Checking performance our model with ROC Score.\n",
    "print(roc_auc_score(y_test, y_pred_knn_2))\n",
    "\n",
    "print(y_pred_knn_2)\n",
    "print(y_test)\n",
    "\n",
    "print(conf_matrix_knn_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model (SVM)\n",
    "### using the optimal parameters gotten above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 2]\n",
      " [2 4]]\n",
      "66.66666666666666\n"
     ]
    }
   ],
   "source": [
    "model_svm = svm.SVC(C = 10, gamma=0.1,kernel='rbf')\n",
    "model_svm = model_svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm_2 = best_model.predict(X_test)\n",
    "\n",
    "conf_matrix_svm_2 = confusion_matrix(y_test, y_pred_svm_2)\n",
    "\n",
    "accuracy_svm_2 = ((conf_matrix_svm_2[0,0] + conf_matrix_svm_2[1,1])/(conf_matrix_svm_2[0,0] +conf_matrix_svm_2[0,1]+conf_matrix_svm_2[1,0]+conf_matrix_svm_2[1,1]))*100\n",
    "\n",
    "print(conf_matrix_svm_2)\n",
    "print(accuracy_svm_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation (SVM) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation with Leave one out method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.757 (0.429)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0]\n",
      "Confusion Matrix for Dt using k-fold (leave one out)\n",
      "[[17  4]\n",
      " [ 5 11]]\n",
      "75.67567567567568\n"
     ]
    }
   ],
   "source": [
    "df_X = sc.fit_transform(df_X)\n",
    "k_fold = KFold(n_splits=37)\n",
    "#KNN\n",
    "#model_knn_kfold = tree.DecisionTreeClassifier(max_depth = 6, criterion='entropy',min_samples_leaf=2, min_samples_split=2 )\n",
    "model_svm = svm.SVC(C = 10, gamma=0.1,kernel='rbf')\n",
    "y_pred_kfold_svm = cross_val_predict(model_svm, df_X, df_Y, cv=k_fold)\n",
    "scores = cross_val_score(model_svm, df_X, df_Y, scoring='accuracy', cv=k_fold, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "\n",
    "print(df_Y)\n",
    "print(y_pred_kfold_knn)\n",
    "conf_matrix_svm_kfold = confusion_matrix(df_Y, y_pred_kfold_svm)\n",
    "print(\"Confusion Matrix for Dt using k-fold (leave one out)\")\n",
    "print(conf_matrix_svm_kfold)\n",
    "\n",
    "\n",
    "accuracy_svm_2 = ((conf_matrix_svm_kfold[0,0] + conf_matrix_svm_kfold[1,1])/(conf_matrix_svm_kfold[0,0] +conf_matrix_svm_kfold[0,1]+conf_matrix_svm_kfold[1,0]+conf_matrix_svm_kfold[1,1]))*100\n",
    "\n",
    "\n",
    "print(accuracy_svm_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Fold Evaluation using optimal paramaters. (k =4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divided into 4 parts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:75: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:76: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Kfold Evaluation for MDVR-KCL Dataset Classification Accuracy\n",
      "    Loops  fold 1     fold 2     fold 3     fold 4  mean accuracy\n",
      "0       1    90.0  66.666667  77.777778  66.666667      75.277778\n",
      "1       2    80.0  66.666667  77.777778  66.666667      72.777778\n",
      "2       3    50.0  66.666667  77.777778  77.777778      68.055556\n",
      "3       4    80.0  66.666667  88.888889  55.555556      72.777778\n",
      "4       5    80.0  55.555556  77.777778  77.777778      72.777778\n",
      "5       6    70.0  55.555556  66.666667  88.888889      70.277778\n",
      "6       7    50.0  88.888889  88.888889  77.777778      76.388889\n",
      "7       8    60.0  77.777778  66.666667  88.888889      73.333333\n",
      "8       9    80.0  77.777778  66.666667  66.666667      72.777778\n",
      "9      10    70.0  66.666667  55.555556  88.888889      70.277778\n",
      "10     11    90.0  55.555556  66.666667  66.666667      69.722222\n",
      "SVM Kfold Evaluation for MDVR-KCL Dataset - Specificity\n",
      "    Loops      fold 1      fold 2      fold 3      fold 4  mean specificity\n",
      "0       1   87.500000   75.000000   75.000000  100.000000         84.375000\n",
      "1       2  100.000000   75.000000   80.000000   71.428571         81.607143\n",
      "2       3  100.000000   40.000000   83.333333  100.000000         80.833333\n",
      "3       4  100.000000   60.000000  100.000000   66.666667         81.666667\n",
      "4       5   71.428571  100.000000   80.000000   83.333333         83.690476\n",
      "5       6   60.000000   75.000000   85.714286   80.000000         75.178571\n",
      "6       7   50.000000  100.000000   75.000000  100.000000         81.250000\n",
      "7       8  100.000000   50.000000   66.666667  100.000000         79.166667\n",
      "8       9  100.000000  100.000000   80.000000   57.142857         84.285714\n",
      "9      10   66.666667  100.000000   60.000000  100.000000         81.666667\n",
      "10     11  100.000000   57.142857   83.333333  100.000000         85.119048\n",
      "SVM Kfold Evaluation for MDVR-KCL Dataset - Sensitivity/Recall\n",
      "    Loops      fold 1      fold 2      fold 3      fold 4  \\\n",
      "0       1  100.000000   60.000000   80.000000   25.000000   \n",
      "1       2   60.000000   60.000000   75.000000   50.000000   \n",
      "2       3   28.571429  100.000000   66.666667    0.000000   \n",
      "3       4   66.666667   75.000000   66.666667   33.333333   \n",
      "4       5  100.000000   33.333333   75.000000   66.666667   \n",
      "5       6   80.000000   40.000000    0.000000  100.000000   \n",
      "6       7   50.000000   50.000000  100.000000   60.000000   \n",
      "7       8   20.000000  100.000000   66.666667   66.666667   \n",
      "8       9   60.000000   60.000000   50.000000  100.000000   \n",
      "9      10   71.428571    0.000000   50.000000   50.000000   \n",
      "10     11   80.000000   50.000000   33.333333   50.000000   \n",
      "\n",
      "    mean sensitivity/recall  \n",
      "0                 66.250000  \n",
      "1                 61.250000  \n",
      "2                 48.809524  \n",
      "3                 60.416667  \n",
      "4                 68.750000  \n",
      "5                 55.000000  \n",
      "6                 65.000000  \n",
      "7                 63.333333  \n",
      "8                 67.500000  \n",
      "9                 42.857143  \n",
      "10                53.333333  \n",
      "SVM Kfold Evaluation for MDVR-KCL Dataset - Precision\n",
      "    Loops      fold 1      fold 2      fold 3      fold 4  mean precision\n",
      "0       1   66.666667   75.000000   80.000000  100.000000       80.416667\n",
      "1       2  100.000000   75.000000   75.000000   33.333333       70.833333\n",
      "2       3  100.000000   57.142857   66.666667         NaN             NaN\n",
      "3       4  100.000000   60.000000  100.000000   33.333333       73.333333\n",
      "4       5   60.000000  100.000000   75.000000   66.666667       75.416667\n",
      "5       6   66.666667   66.666667    0.000000   80.000000       53.333333\n",
      "6       7   40.000000  100.000000   83.333333  100.000000       80.833333\n",
      "7       8  100.000000   71.428571   50.000000  100.000000       80.357143\n",
      "8       9  100.000000  100.000000   66.666667   40.000000       76.666667\n",
      "9      10   83.333333         NaN   50.000000  100.000000             NaN\n",
      "10     11  100.000000   25.000000   50.000000  100.000000       68.750000\n",
      "SVM Kfold Evaluation for MDVR-KCL Dataset - F1 score\n",
      "    Loops     fold 1     fold 2     fold 3     fold 4  mean f1 score\n",
      "0       1  80.000000  66.666667  80.000000  40.000000      66.666667\n",
      "1       2  75.000000  66.666667  75.000000  40.000000      64.166667\n",
      "2       3  44.444444  72.727273  66.666667        NaN            NaN\n",
      "3       4  80.000000  66.666667  80.000000  33.333333      65.000000\n",
      "4       5  75.000000  50.000000  75.000000  66.666667      66.666667\n",
      "5       6  72.727273  50.000000        NaN  88.888889            NaN\n",
      "6       7  44.444444  66.666667  90.909091  75.000000      69.255051\n",
      "7       8  33.333333  83.333333  57.142857  80.000000      63.452381\n",
      "8       9  75.000000  75.000000  57.142857  57.142857      66.071429\n",
      "9      10  76.923077        NaN  50.000000  66.666667            NaN\n",
      "10     11  88.888889  33.333333  40.000000  66.666667      57.222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:75: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#df_kfold = shuffle(df)\n",
    "#df_kfold.reset_index(inplace=True, drop=True)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "df_kfold = df\n",
    "df_Xnew = df_kfold.iloc[:, :-1].values\n",
    "df_Ynew = df_kfold.iloc[:,-1].values\n",
    "\n",
    "\n",
    "X_kfold = pd.DataFrame(df_Xnew)\n",
    "y_kfold = pd.DataFrame(df_Ynew)\n",
    "#print(X_kfold)\n",
    "#print(y_kfold)\n",
    "\n",
    "parts = 4\n",
    "kfold = KFold(parts, True, None) \n",
    "\n",
    "# splits into 5 groups \n",
    "print(\"Divided into %s parts.\" %parts)\n",
    "\n",
    "k_svm_list = []\n",
    "k_svm_specificity = []\n",
    "k_svm_sensitivity = []\n",
    "k_svm_precision = []\n",
    "k_svm_f1 = []\n",
    "\n",
    "for i in range (1,12):\n",
    "    row = []\n",
    "    row_specificity = []\n",
    "    row_sensitivity = []\n",
    "    row_precision = []\n",
    "    row_f1 = []\n",
    "    \n",
    "    row.append(i)\n",
    "    row_specificity.append(i)\n",
    "    row_sensitivity.append(i)\n",
    "    row_precision.append(i)\n",
    "    row_f1.append(i)\n",
    "    \n",
    "    total = 0\n",
    "    total_specificity = 0\n",
    "    total_sensitivity = 0\n",
    "    total_precision = 0\n",
    "    total_f1 = 0\n",
    "    #print(\"Loop\", i)\n",
    "    for train, test in kfold.split(X_kfold,y_kfold):\n",
    "        #print('\\ntrain: %s, test: %s' % (train, test))\n",
    "        Xtrain_kfold = X_kfold.iloc[train, :]\n",
    "        Ytrain_kfold = y_kfold.iloc[train, :]\n",
    "        Xtest_kfold = X_kfold.iloc[test, :]\n",
    "        Ytest_kfold = y_kfold.iloc[test, :]\n",
    "        #print(Xtest_kfold)\n",
    "        #print(Ytest_kfold)\n",
    "\n",
    "        Xtrain_kfold = sc.fit_transform(Xtrain_kfold)\n",
    "        Xtest_kfold = sc.transform(Xtest_kfold)\n",
    "\n",
    "        #modelling\n",
    "        \n",
    "        model_svm_new = svm.SVC(C = 10, gamma=0.1,kernel='rbf')\n",
    "        model_svm_new.fit(Xtrain_kfold, Ytrain_kfold)\n",
    "        y_pred_svm_new = model_svm_new.predict(Xtest_kfold)\n",
    "\n",
    "        conf_matrix_knn_kfold = confusion_matrix(Ytest_kfold, y_pred_svm_new)\n",
    "\n",
    "        #accuracy_dt_kfold = ((conf_matrix_dt_kfold[0,0] + conf_matrix_dt_kfold[1,1])/(conf_matrix_dt_kfold[0,0] +conf_matrix_dt_kfold[0,1]+conf_matrix_dt_kfold[1,0]+conf_matrix_dt_kfold[1,1]))*100\n",
    "        TN = conf_matrix_knn_kfold[0][0]\n",
    "        FP = conf_matrix_knn_kfold[0][1]\n",
    "        FN = conf_matrix_knn_kfold[1][0]\n",
    "        TP = conf_matrix_knn_kfold[1][1]\n",
    "        \n",
    "    \n",
    "        accuracy_knn_kfold = ((TP + TN) / (TP + TN + FP + FN)) * 100\n",
    "        sensitivity_knn_kfold = (TP/(TP+FN)) * 100 #recall\n",
    "        specificity_knn_kfold = (TN/(TN + FP)) * 100\n",
    "        precision_knn_kfold = (TP/(TP+FP)) *100\n",
    "        f1_knn_kfold = 2 *((sensitivity_knn_kfold * precision_knn_kfold)/(sensitivity_knn_kfold + precision_knn_kfold))\n",
    "\n",
    "\n",
    "        row.append(accuracy_knn_kfold)\n",
    "        row_specificity.append(specificity_knn_kfold)\n",
    "        row_sensitivity.append(sensitivity_knn_kfold)\n",
    "        row_precision.append(precision_knn_kfold)\n",
    "        row_f1.append(f1_knn_kfold)\n",
    "        \n",
    "        total += accuracy_knn_kfold\n",
    "        total_specificity += specificity_knn_kfold\n",
    "        total_sensitivity += sensitivity_knn_kfold\n",
    "        total_precision += precision_knn_kfold\n",
    "        total_f1 += f1_knn_kfold\n",
    "\n",
    "    average = row.append(total/parts)   \n",
    "    row_specificity.append(total_specificity/parts)\n",
    "    row_sensitivity.append(total_sensitivity/parts)\n",
    "    row_precision.append(total_precision/parts)\n",
    "    row_f1.append(total_f1/parts)\n",
    "        \n",
    "    #print(row)\n",
    "    k_svm_list.append(row)\n",
    "    k_svm_specificity.append(row_specificity)\n",
    "    k_svm_sensitivity.append(row_sensitivity)\n",
    "    k_svm_precision.append(row_precision)\n",
    "    k_svm_f1.append(row_f1)\n",
    "    \n",
    "k_svm_list = pd.DataFrame(k_svm_list, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean accuracy'])\n",
    "print(\"SVM Kfold Evaluation for MDVR-KCL Dataset Classification Accuracy\")\n",
    "print(k_svm_list)    \n",
    "\n",
    "k_svm_specificity = pd.DataFrame(k_svm_specificity, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean specificity'])\n",
    "print(\"SVM Kfold Evaluation for MDVR-KCL Dataset - Specificity\")\n",
    "print(k_svm_specificity)\n",
    "\n",
    "k_svm_sensitivity = pd.DataFrame(k_svm_sensitivity, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean sensitivity/recall'])\n",
    "print(\"SVM Kfold Evaluation for MDVR-KCL Dataset - Sensitivity/Recall\")\n",
    "print(k_svm_sensitivity)\n",
    "\n",
    "k_svm_precision = pd.DataFrame(k_svm_precision, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean precision'])\n",
    "print(\"SVM Kfold Evaluation for MDVR-KCL Dataset - Precision\")\n",
    "print(k_svm_precision)\n",
    "\n",
    "k_svm_f1 = pd.DataFrame(k_svm_f1, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean f1 score'])\n",
    "print(\"SVM Kfold Evaluation for MDVR-KCL Dataset - F1 score\")\n",
    "print(k_svm_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# *****************Naive Bayes Experiments***************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model\n",
    "### without tuning the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.66666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.50         6\n",
      "           1       0.60      1.00      0.75         6\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.80      0.67      0.62        12\n",
      "weighted avg       0.80      0.67      0.62        12\n",
      "\n",
      "0.6666666666666667\n",
      "[1 1 0 1 1 1 0 1 1 1 1 1]\n",
      "[[2 4]\n",
      " [0 6]]\n"
     ]
    }
   ],
   "source": [
    "###### KNNN ###########\n",
    "# Fit classifier to the Training set\n",
    "#NB\n",
    "model_nb = GaussianNB()\n",
    "model_nb = model_nb.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred_nb = model_nb.predict(X_test)\n",
    "\n",
    "conf_matrix_nb = confusion_matrix(y_test, y_pred_nb)\n",
    "\n",
    "accuracy_nb = ((conf_matrix_nb[0,0] + conf_matrix_nb[1,1])/(conf_matrix_nb[0,0] +conf_matrix_nb[0,1]+conf_matrix_nb[1,0]+conf_matrix_nb[1,1]))*100\n",
    "\n",
    "\n",
    "print(accuracy_nb)\n",
    "\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "#Checking performance our model with ROC Score.\n",
    "print(roc_auc_score(y_test, y_pred_nb))\n",
    "\n",
    "print(y_pred_nb)\n",
    "\n",
    "print(conf_matrix_nb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning for Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB doesnt have important parameters to tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation (Naive Bayes) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation with Leave one out method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.757 (0.429)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 0]\n",
      "Confusion Matrix for Dt using k-fold (leave one out)\n",
      "[[17  4]\n",
      " [ 5 11]]\n",
      "75.67567567567568\n"
     ]
    }
   ],
   "source": [
    "df_X = sc.fit_transform(df_X)\n",
    "k_fold = KFold(n_splits=37)\n",
    "#KNN\n",
    "#model_knn_kfold = tree.DecisionTreeClassifier(max_depth = 6, criterion='entropy',min_samples_leaf=2, min_samples_split=2 )\n",
    "model_nb_2 = GaussianNB()\n",
    "y_pred_kfold_nb = cross_val_predict(model_nb_2, df_X, df_Y, cv=k_fold)\n",
    "scores = cross_val_score(model_nb_2, df_X, df_Y, scoring='accuracy', cv=k_fold, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "\n",
    "print(df_Y)\n",
    "print(y_pred_kfold_nb)\n",
    "conf_matrix_nb_kfold = confusion_matrix(df_Y, y_pred_kfold_nb)\n",
    "print(\"Confusion Matrix for Dt using k-fold (leave one out)\")\n",
    "print(conf_matrix_nb_kfold)\n",
    "\n",
    "\n",
    "accuracy_nb_2 = ((conf_matrix_nb_kfold[0,0] + conf_matrix_nb_kfold[1,1])/(conf_matrix_nb_kfold[0,0] +conf_matrix_nb_kfold[0,1]+conf_matrix_nb_kfold[1,0]+conf_matrix_nb_kfold[1,1]))*100\n",
    "\n",
    "\n",
    "print(accuracy_nb_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Fold Evaluation using optimal paramaters. (k =4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divided into 4 parts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Kfold Evaluation for MDVR-KCL Dataset Classification Accuracy\n",
      "    Loops  fold 1     fold 2     fold 3      fold 4  mean accuracy\n",
      "0       1    70.0  88.888889  55.555556   66.666667      70.277778\n",
      "1       2    60.0  77.777778  66.666667   66.666667      67.777778\n",
      "2       3    80.0  44.444444  77.777778   66.666667      67.222222\n",
      "3       4    60.0  88.888889  44.444444  100.000000      73.333333\n",
      "4       5    80.0  55.555556  66.666667   66.666667      67.222222\n",
      "5       6    70.0  55.555556  88.888889   66.666667      70.277778\n",
      "6       7    90.0  77.777778  55.555556   77.777778      75.277778\n",
      "7       8    60.0  55.555556  88.888889   66.666667      67.777778\n",
      "8       9    80.0  66.666667  55.555556   77.777778      70.000000\n",
      "9      10    60.0  55.555556  88.888889   66.666667      67.777778\n",
      "10     11    80.0  66.666667  77.777778   77.777778      75.555556\n",
      "Naive Bayes Kfold Evaluation for MDVR-KCL Dataset - Specificity\n",
      "    Loops      fold 1      fold 2      fold 3      fold 4  mean specificity\n",
      "0       1   80.000000  100.000000   50.000000   75.000000         76.250000\n",
      "1       2   60.000000   75.000000   66.666667   80.000000         70.416667\n",
      "2       3   83.333333   66.666667   80.000000   57.142857         71.785714\n",
      "3       4   60.000000  100.000000   25.000000  100.000000         71.250000\n",
      "4       5   71.428571   50.000000   80.000000  100.000000         75.357143\n",
      "5       6   60.000000   60.000000   83.333333   80.000000         70.833333\n",
      "6       7  100.000000   80.000000   50.000000   85.714286         78.928571\n",
      "7       8   50.000000   66.666667  100.000000   75.000000         72.916667\n",
      "8       9   83.333333   80.000000   33.333333  100.000000         74.166667\n",
      "9      10   57.142857   75.000000  100.000000   60.000000         73.035714\n",
      "10     11   80.000000   66.666667   75.000000  100.000000         80.416667\n",
      "Naive Bayes Kfold Evaluation for MDVR-KCL Dataset - Sensitivity/Recall\n",
      "    Loops      fold 1      fold 2      fold 3  fold 4  mean sensitivity/recall\n",
      "0       1   60.000000   66.666667   66.666667    60.0                63.333333\n",
      "1       2   60.000000  100.000000   66.666667    50.0                69.166667\n",
      "2       3   75.000000   33.333333   75.000000   100.0                70.833333\n",
      "3       4   60.000000   75.000000   60.000000   100.0                73.750000\n",
      "4       5  100.000000   60.000000   50.000000    25.0                58.750000\n",
      "5       6   80.000000   50.000000  100.000000    50.0                70.000000\n",
      "6       7   80.000000   75.000000   60.000000    50.0                66.250000\n",
      "7       8   75.000000   33.333333   75.000000    60.0                60.833333\n",
      "8       9   75.000000   50.000000  100.000000    60.0                71.250000\n",
      "9      10   66.666667   40.000000   75.000000    75.0                64.166667\n",
      "10     11   80.000000   66.666667  100.000000    50.0                74.166667\n",
      "Naive Bayes Kfold Evaluation for MDVR-KCL Dataset - Precision\n",
      "    Loops      fold 1      fold 2      fold 3      fold 4  mean precision\n",
      "0       1   75.000000  100.000000   40.000000   75.000000       72.500000\n",
      "1       2   60.000000   33.333333   80.000000   66.666667       60.000000\n",
      "2       3   75.000000   66.666667   75.000000   40.000000       64.166667\n",
      "3       4   60.000000  100.000000   50.000000  100.000000       77.500000\n",
      "4       5   60.000000   60.000000   66.666667  100.000000       71.666667\n",
      "5       6   66.666667   50.000000   75.000000   66.666667       64.583333\n",
      "6       7  100.000000   75.000000   60.000000   50.000000       71.250000\n",
      "7       8   50.000000   33.333333  100.000000   75.000000       64.583333\n",
      "8       9   75.000000   66.666667   42.857143  100.000000       71.130952\n",
      "9      10   40.000000   66.666667  100.000000   60.000000       66.666667\n",
      "10     11   80.000000   80.000000   33.333333  100.000000       73.333333\n",
      "Naive Bayes Kfold Evaluation for MDVR-KCL Dataset - F1 score\n",
      "    Loops     fold 1     fold 2     fold 3      fold 4  mean f1 score\n",
      "0       1  66.666667  80.000000  50.000000   66.666667      65.833333\n",
      "1       2  60.000000  50.000000  72.727273   57.142857      59.967532\n",
      "2       3  75.000000  44.444444  75.000000   57.142857      62.896825\n",
      "3       4  60.000000  85.714286  54.545455  100.000000      75.064935\n",
      "4       5  75.000000  60.000000  57.142857   40.000000      58.035714\n",
      "5       6  72.727273  50.000000  85.714286   57.142857      66.396104\n",
      "6       7  88.888889  75.000000  60.000000   50.000000      68.472222\n",
      "7       8  60.000000  33.333333  85.714286   66.666667      61.428571\n",
      "8       9  75.000000  57.142857  60.000000   75.000000      66.785714\n",
      "9      10  50.000000  50.000000  85.714286   66.666667      63.095238\n",
      "10     11  80.000000  72.727273  50.000000   66.666667      67.348485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#df_kfold = shuffle(df)\n",
    "#df_kfold.reset_index(inplace=True, drop=True)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "df_kfold = df\n",
    "df_Xnew = df_kfold.iloc[:, :-1].values\n",
    "df_Ynew = df_kfold.iloc[:,-1].values\n",
    "\n",
    "\n",
    "X_kfold = pd.DataFrame(df_Xnew)\n",
    "y_kfold = pd.DataFrame(df_Ynew)\n",
    "#print(X_kfold)\n",
    "#print(y_kfold)\n",
    "\n",
    "parts = 4\n",
    "kfold = KFold(parts, True, None) \n",
    "\n",
    "# splits into 5 groups \n",
    "print(\"Divided into %s parts.\" %parts)\n",
    "\n",
    "k_nb_list = []\n",
    "k_nb_specificity = []\n",
    "k_nb_sensitivity = []\n",
    "k_nb_precision = []\n",
    "k_nb_f1 = []\n",
    "\n",
    "for i in range (1,12):\n",
    "    row = []\n",
    "    row_specificity = []\n",
    "    row_sensitivity = []\n",
    "    row_precision = []\n",
    "    row_f1 = []\n",
    "    \n",
    "    row.append(i)\n",
    "    row_specificity.append(i)\n",
    "    row_sensitivity.append(i)\n",
    "    row_precision.append(i)\n",
    "    row_f1.append(i)\n",
    "    \n",
    "    total = 0\n",
    "    total_specificity = 0\n",
    "    total_sensitivity = 0\n",
    "    total_precision = 0\n",
    "    total_f1 = 0\n",
    "    #print(\"Loop\", i)\n",
    "    for train, test in kfold.split(X_kfold,y_kfold):\n",
    "        #print('\\ntrain: %s, test: %s' % (train, test))\n",
    "        Xtrain_kfold = X_kfold.iloc[train, :]\n",
    "        Ytrain_kfold = y_kfold.iloc[train, :]\n",
    "        Xtest_kfold = X_kfold.iloc[test, :]\n",
    "        Ytest_kfold = y_kfold.iloc[test, :]\n",
    "        #print(Xtest_kfold)\n",
    "        #print(Ytest_kfold)\n",
    "\n",
    "        Xtrain_kfold = sc.fit_transform(Xtrain_kfold)\n",
    "        Xtest_kfold = sc.transform(Xtest_kfold)\n",
    "\n",
    "        #modelling\n",
    "        \n",
    "        model_nb_new = GaussianNB()\n",
    "        model_nb_new.fit(Xtrain_kfold, Ytrain_kfold)\n",
    "\n",
    "        y_pred_nb_new = model_nb_new.predict(Xtest_kfold)\n",
    "\n",
    "        conf_matrix_nb_kfold = confusion_matrix(Ytest_kfold, y_pred_nb_new)\n",
    "\n",
    "        #accuracy_dt_kfold = ((conf_matrix_dt_kfold[0,0] + conf_matrix_dt_kfold[1,1])/(conf_matrix_dt_kfold[0,0] +conf_matrix_dt_kfold[0,1]+conf_matrix_dt_kfold[1,0]+conf_matrix_dt_kfold[1,1]))*100\n",
    "        TN = conf_matrix_nb_kfold[0][0]\n",
    "        FP = conf_matrix_nb_kfold[0][1]\n",
    "        FN = conf_matrix_nb_kfold[1][0]\n",
    "        TP = conf_matrix_nb_kfold[1][1]\n",
    "        \n",
    "    \n",
    "        accuracy_knn_kfold = ((TP + TN) / (TP + TN + FP + FN)) * 100\n",
    "        sensitivity_knn_kfold = (TP/(TP+FN)) * 100 #recall\n",
    "        specificity_knn_kfold = (TN/(TN + FP)) * 100\n",
    "        precision_knn_kfold = (TP/(TP+FP)) *100\n",
    "        f1_knn_kfold = 2 *((sensitivity_knn_kfold * precision_knn_kfold)/(sensitivity_knn_kfold + precision_knn_kfold))\n",
    "\n",
    "\n",
    "        row.append(accuracy_knn_kfold)\n",
    "        row_specificity.append(specificity_knn_kfold)\n",
    "        row_sensitivity.append(sensitivity_knn_kfold)\n",
    "        row_precision.append(precision_knn_kfold)\n",
    "        row_f1.append(f1_knn_kfold)\n",
    "        \n",
    "        total += accuracy_knn_kfold\n",
    "        total_specificity += specificity_knn_kfold\n",
    "        total_sensitivity += sensitivity_knn_kfold\n",
    "        total_precision += precision_knn_kfold\n",
    "        total_f1 += f1_knn_kfold\n",
    "\n",
    "    average = row.append(total/parts)   \n",
    "    row_specificity.append(total_specificity/parts)\n",
    "    row_sensitivity.append(total_sensitivity/parts)\n",
    "    row_precision.append(total_precision/parts)\n",
    "    row_f1.append(total_f1/parts)\n",
    "        \n",
    "    #print(row)\n",
    "    k_nb_list.append(row)\n",
    "    k_nb_specificity.append(row_specificity)\n",
    "    k_nb_sensitivity.append(row_sensitivity)\n",
    "    k_nb_precision.append(row_precision)\n",
    "    k_nb_f1.append(row_f1)\n",
    "    \n",
    "k_nb_list = pd.DataFrame(k_nb_list, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean accuracy'])\n",
    "print(\"Naive Bayes Kfold Evaluation for MDVR-KCL Dataset Classification Accuracy\")\n",
    "print(k_nb_list)    \n",
    "\n",
    "k_nb_specificity = pd.DataFrame(k_nb_specificity, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean specificity'])\n",
    "print(\"Naive Bayes Kfold Evaluation for MDVR-KCL Dataset - Specificity\")\n",
    "print(k_nb_specificity)\n",
    "\n",
    "k_nb_sensitivity = pd.DataFrame(k_nb_sensitivity, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean sensitivity/recall'])\n",
    "print(\"Naive Bayes Kfold Evaluation for MDVR-KCL Dataset - Sensitivity/Recall\")\n",
    "print(k_nb_sensitivity)\n",
    "\n",
    "k_nb_precision = pd.DataFrame(k_nb_precision, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean precision'])\n",
    "print(\"Naive Bayes Kfold Evaluation for MDVR-KCL Dataset - Precision\")\n",
    "print(k_nb_precision)\n",
    "\n",
    "k_nb_f1 = pd.DataFrame(k_nb_f1, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean f1 score'])\n",
    "print(\"Naive Bayes Kfold Evaluation for MDVR-KCL Dataset - F1 score\")\n",
    "print(k_nb_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# *****************Logistic Regression Experiments***************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model\n",
    "### without tuning the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73         6\n",
      "           1       0.71      0.83      0.77         6\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.76      0.75      0.75        12\n",
      "weighted avg       0.76      0.75      0.75        12\n",
      "\n",
      "0.7500000000000002\n",
      "[1 1 0 0 1 1 0 0 1 1 1 0]\n",
      "[[4 2]\n",
      " [1 5]]\n"
     ]
    }
   ],
   "source": [
    "###### KNNN ###########\n",
    "# Fit classifier to the Training set\n",
    "#NB\n",
    "\n",
    "\n",
    "model_lr = LogisticRegression(random_state=0)\n",
    "model_lr = model_lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = model_lr.predict(X_test)\n",
    "\n",
    "conf_matrix_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "\n",
    "accuracy_lr = ((conf_matrix_lr[0,0] + conf_matrix_lr[1,1])/(conf_matrix_lr[0,0] +conf_matrix_lr[0,1]+conf_matrix_lr[1,0]+conf_matrix_lr[1,1]))*100\n",
    "\n",
    "\n",
    "print(accuracy_lr)\n",
    "\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "#Checking performance our model with ROC Score.\n",
    "print(roc_auc_score(y_test, y_pred_lr))\n",
    "\n",
    "print(y_pred_lr)\n",
    "\n",
    "print(conf_matrix_lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning for LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.7066666666666667\n",
      "Best Hyperparameters: {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "{'solver': ['newton-cg', 'lbfgs', 'liblinear'], 'penalty': ['l2'], 'C': [100, 10, 1.0, 0.1, 0.01]}\n",
      "75.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73         6\n",
      "           1       0.71      0.83      0.77         6\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.76      0.75      0.75        12\n",
      "weighted avg       0.76      0.75      0.75        12\n",
      "\n",
      "0.7500000000000002\n",
      "[1 1 0 0 1 1 0 0 1 1 1 0]\n",
      "[1 0 0 0 1 1 0 0 0 1 1 1]\n",
      "[[4 2]\n",
      " [1 5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "########Hyperparameter tuning for SVM####################\n",
    "#List Hyperparameters that we want to tune.\n",
    "#n_components = list(range(1,X.shape[1]+1,1))\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "penalty = ['l2']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "\n",
    "#Convert to dictionary\n",
    "hyperparameters = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "#Create new LR object\n",
    "model_lr2 = LogisticRegression()\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "#Use GridSearch\n",
    "clf = GridSearchCV(model_lr2, hyperparameters, cv=cv)\n",
    "\n",
    "#clf = RandomizedSearchCV(knn_2, hyperparameters, n_iter=500, cv=8, scoring=\"recall\")\n",
    "#Fit the model\n",
    "best_model = clf.fit(X_train, y_train)\n",
    "#Print The value of best Hyperparameters\n",
    "#print('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])\n",
    "#print('Best p:', best_model.best_estimator_.get_params()['p'])\n",
    "#print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])\n",
    "print('Best Score: %s' % best_model.best_score_)\n",
    "print('Best Hyperparameters: %s' % best_model.best_params_)\n",
    "print(hyperparameters)\n",
    "y_pred_knn_2 = best_model.predict(X_test)\n",
    "\n",
    "conf_matrix_knn_2 = confusion_matrix(y_test, y_pred_knn_2)\n",
    "\n",
    "accuracy_knn_2 = ((conf_matrix_knn_2[0,0] + conf_matrix_knn_2[1,1])/(conf_matrix_knn_2[0,0] +conf_matrix_knn_2[0,1]+conf_matrix_knn_2[1,0]+conf_matrix_knn_2[1,1]))*100\n",
    "\n",
    "\n",
    "print(accuracy_knn_2)\n",
    "\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred_knn_2))\n",
    "#Checking performance our model with ROC Score.\n",
    "print(roc_auc_score(y_test, y_pred_knn_2))\n",
    "\n",
    "print(y_pred_knn_2)\n",
    "print(y_test)\n",
    "\n",
    "print(conf_matrix_knn_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model (LR)\n",
    "### using the optimal parameters gotten above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 2]\n",
      " [1 5]]\n",
      "75.0\n"
     ]
    }
   ],
   "source": [
    "model_lr = LogisticRegression(C= 10, penalty='l2',solver= 'newton-cg')\n",
    "model_lr = model_lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr_2 = best_model.predict(X_test)\n",
    "\n",
    "conf_matrix_lr_2 = confusion_matrix(y_test, y_pred_lr_2)\n",
    "\n",
    "accuracy_lr_2 = ((conf_matrix_lr_2[0,0] + conf_matrix_lr_2[1,1])/(conf_matrix_lr_2[0,0] +conf_matrix_lr_2[0,1]+conf_matrix_lr_2[1,0]+conf_matrix_lr_2[1,1]))*100\n",
    "\n",
    "print(conf_matrix_lr_2)\n",
    "print(accuracy_lr_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation (LR) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Fold Evaluation using optimal paramaters. (k =4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divided into 4 parts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Kfold Evaluation for MDVR-KCL Dataset Classification Accuracy\n",
      "    Loops  fold 1      fold 2     fold 3     fold 4  mean accuracy\n",
      "0       1    70.0   77.777778  88.888889  66.666667      75.833333\n",
      "1       2    80.0   44.444444  77.777778  77.777778      70.000000\n",
      "2       3    90.0   77.777778  66.666667  55.555556      72.500000\n",
      "3       4    70.0  100.000000  66.666667  66.666667      75.833333\n",
      "4       5    60.0   88.888889  77.777778  66.666667      73.333333\n",
      "5       6    60.0   88.888889  55.555556  77.777778      70.555556\n",
      "6       7    80.0   55.555556  55.555556  55.555556      61.666667\n",
      "7       8    70.0   77.777778  66.666667  66.666667      70.277778\n",
      "8       9    70.0   66.666667  66.666667  77.777778      70.277778\n",
      "9      10    60.0   88.888889  55.555556  55.555556      65.000000\n",
      "10     11    80.0   77.777778  55.555556  66.666667      70.000000\n",
      "Logistic Regression Kfold Evaluation for MDVR-KCL Dataset - Specificity\n",
      "    Loops      fold 1      fold 2      fold 3      fold 4  mean specificity\n",
      "0       1   57.142857  100.000000   75.000000  100.000000         83.035714\n",
      "1       2  100.000000   60.000000   71.428571  100.000000         82.857143\n",
      "2       3  100.000000  100.000000   66.666667   80.000000         86.666667\n",
      "3       4   66.666667  100.000000   75.000000   80.000000         80.416667\n",
      "4       5   80.000000  100.000000   71.428571   75.000000         81.607143\n",
      "5       6  100.000000   80.000000   50.000000  100.000000         82.500000\n",
      "6       7  100.000000  100.000000   50.000000   66.666667         79.166667\n",
      "7       8  100.000000   83.333333   66.666667   60.000000         77.500000\n",
      "8       9   83.333333   75.000000  100.000000   75.000000         83.333333\n",
      "9      10  100.000000   83.333333  100.000000   50.000000         83.333333\n",
      "10     11   83.333333   80.000000   80.000000   80.000000         80.833333\n",
      "Logistic Regression Kfold Evaluation for MDVR-KCL Dataset - Sensitivity/Recall\n",
      "    Loops      fold 1      fold 2      fold 3      fold 4  \\\n",
      "0       1  100.000000   50.000000  100.000000   25.000000   \n",
      "1       2   50.000000   25.000000  100.000000   66.666667   \n",
      "2       3   75.000000   60.000000   66.666667   25.000000   \n",
      "3       4   75.000000  100.000000   60.000000   50.000000   \n",
      "4       5   40.000000   75.000000  100.000000   60.000000   \n",
      "5       6   33.333333  100.000000   66.666667   33.333333   \n",
      "6       7   60.000000   42.857143  100.000000   33.333333   \n",
      "7       8   50.000000   66.666667   66.666667   75.000000   \n",
      "8       9   50.000000   60.000000   50.000000  100.000000   \n",
      "9      10   33.333333  100.000000   33.333333  100.000000   \n",
      "10     11   75.000000   75.000000   25.000000   50.000000   \n",
      "\n",
      "    mean sensitivity/recall  \n",
      "0                 68.750000  \n",
      "1                 60.416667  \n",
      "2                 56.666667  \n",
      "3                 71.250000  \n",
      "4                 68.750000  \n",
      "5                 58.333333  \n",
      "6                 59.047619  \n",
      "7                 64.583333  \n",
      "8                 65.000000  \n",
      "9                 66.666667  \n",
      "10                56.250000  \n",
      "Logistic Regression Kfold Evaluation for MDVR-KCL Dataset - Precision\n",
      "    Loops      fold 1      fold 2      fold 3      fold 4  mean precision\n",
      "0       1   50.000000  100.000000   83.333333  100.000000       83.333333\n",
      "1       2  100.000000   33.333333   50.000000  100.000000       70.833333\n",
      "2       3  100.000000  100.000000   50.000000   50.000000       75.000000\n",
      "3       4   60.000000  100.000000   75.000000   66.666667       75.416667\n",
      "4       5   66.666667  100.000000   50.000000   75.000000       72.916667\n",
      "5       6  100.000000   80.000000   40.000000  100.000000       80.000000\n",
      "6       7  100.000000  100.000000   20.000000   33.333333       63.333333\n",
      "7       8  100.000000   66.666667   50.000000   60.000000       69.166667\n",
      "8       9   66.666667   75.000000  100.000000   33.333333       68.750000\n",
      "9      10  100.000000   75.000000  100.000000   20.000000       73.750000\n",
      "10     11   75.000000   75.000000   50.000000   66.666667       66.666667\n",
      "Logistic Regression Kfold Evaluation for MDVR-KCL Dataset - F1 score\n",
      "    Loops     fold 1      fold 2     fold 3     fold 4  mean f1 score\n",
      "0       1  66.666667   66.666667  90.909091  40.000000      66.060606\n",
      "1       2  66.666667   28.571429  66.666667  80.000000      60.476190\n",
      "2       3  85.714286   75.000000  57.142857  33.333333      62.797619\n",
      "3       4  66.666667  100.000000  66.666667  57.142857      72.619048\n",
      "4       5  50.000000   85.714286  66.666667  66.666667      67.261905\n",
      "5       6  50.000000   88.888889  50.000000  50.000000      59.722222\n",
      "6       7  75.000000   60.000000  33.333333  33.333333      50.416667\n",
      "7       8  66.666667   66.666667  57.142857  66.666667      64.285714\n",
      "8       9  57.142857   66.666667  66.666667  50.000000      60.119048\n",
      "9      10  50.000000   85.714286  50.000000  33.333333      54.761905\n",
      "10     11  75.000000   75.000000  33.333333  57.142857      60.119048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#df_kfold = shuffle(df)\n",
    "#df_kfold.reset_index(inplace=True, drop=True)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "df_kfold = df\n",
    "df_Xnew = df_kfold.iloc[:, :-1].values\n",
    "df_Ynew = df_kfold.iloc[:,-1].values\n",
    "\n",
    "\n",
    "X_kfold = pd.DataFrame(df_Xnew)\n",
    "y_kfold = pd.DataFrame(df_Ynew)\n",
    "#print(X_kfold)\n",
    "#print(y_kfold)\n",
    "\n",
    "parts = 4\n",
    "kfold = KFold(parts, True, None) \n",
    "\n",
    "# splits into 5 groups \n",
    "print(\"Divided into %s parts.\" %parts)\n",
    "\n",
    "k_lr_list = []\n",
    "k_lr_specificity = []\n",
    "k_lr_sensitivity = []\n",
    "k_lr_precision = []\n",
    "k_lr_f1 = []\n",
    "\n",
    "for i in range (1,12):\n",
    "    row = []\n",
    "    row_specificity = []\n",
    "    row_sensitivity = []\n",
    "    row_precision = []\n",
    "    row_f1 = []\n",
    "    \n",
    "    row.append(i)\n",
    "    row_specificity.append(i)\n",
    "    row_sensitivity.append(i)\n",
    "    row_precision.append(i)\n",
    "    row_f1.append(i)\n",
    "    \n",
    "    total = 0\n",
    "    total_specificity = 0\n",
    "    total_sensitivity = 0\n",
    "    total_precision = 0\n",
    "    total_f1 = 0\n",
    "    #print(\"Loop\", i)\n",
    "    for train, test in kfold.split(X_kfold,y_kfold):\n",
    "        #print('\\ntrain: %s, test: %s' % (train, test))\n",
    "        Xtrain_kfold = X_kfold.iloc[train, :]\n",
    "        Ytrain_kfold = y_kfold.iloc[train, :]\n",
    "        Xtest_kfold = X_kfold.iloc[test, :]\n",
    "        Ytest_kfold = y_kfold.iloc[test, :]\n",
    "        #print(Xtest_kfold)\n",
    "        #print(Ytest_kfold)\n",
    "\n",
    "        Xtrain_kfold = sc.fit_transform(Xtrain_kfold)\n",
    "        Xtest_kfold = sc.transform(Xtest_kfold)\n",
    "\n",
    "        #modelling\n",
    "        model_nb_new = LogisticRegression(C= 10, penalty='l2',solver= 'newton-cg')\n",
    "        model_nb_new.fit(Xtrain_kfold, Ytrain_kfold)\n",
    "\n",
    "        y_pred_nb_new = model_nb_new.predict(Xtest_kfold)\n",
    "\n",
    "        conf_matrix_knn_kfold = confusion_matrix(Ytest_kfold, y_pred_nb_new)\n",
    "\n",
    "\n",
    "        #accuracy_dt_kfold = ((conf_matrix_dt_kfold[0,0] + conf_matrix_dt_kfold[1,1])/(conf_matrix_dt_kfold[0,0] +conf_matrix_dt_kfold[0,1]+conf_matrix_dt_kfold[1,0]+conf_matrix_dt_kfold[1,1]))*100\n",
    "        TN = conf_matrix_knn_kfold[0][0]\n",
    "        FP = conf_matrix_knn_kfold[0][1]\n",
    "        FN = conf_matrix_knn_kfold[1][0]\n",
    "        TP = conf_matrix_knn_kfold[1][1]\n",
    "        \n",
    "    \n",
    "        accuracy_knn_kfold = ((TP + TN) / (TP + TN + FP + FN)) * 100\n",
    "        sensitivity_knn_kfold = (TP/(TP+FN)) * 100 #recall\n",
    "        specificity_knn_kfold = (TN/(TN + FP)) * 100\n",
    "        precision_knn_kfold = (TP/(TP+FP)) *100\n",
    "        f1_knn_kfold = 2 *((sensitivity_knn_kfold * precision_knn_kfold)/(sensitivity_knn_kfold + precision_knn_kfold))\n",
    "\n",
    "\n",
    "        row.append(accuracy_knn_kfold)\n",
    "        row_specificity.append(specificity_knn_kfold)\n",
    "        row_sensitivity.append(sensitivity_knn_kfold)\n",
    "        row_precision.append(precision_knn_kfold)\n",
    "        row_f1.append(f1_knn_kfold)\n",
    "        \n",
    "        total += accuracy_knn_kfold\n",
    "        total_specificity += specificity_knn_kfold\n",
    "        total_sensitivity += sensitivity_knn_kfold\n",
    "        total_precision += precision_knn_kfold\n",
    "        total_f1 += f1_knn_kfold\n",
    "\n",
    "    average = row.append(total/parts)   \n",
    "    row_specificity.append(total_specificity/parts)\n",
    "    row_sensitivity.append(total_sensitivity/parts)\n",
    "    row_precision.append(total_precision/parts)\n",
    "    row_f1.append(total_f1/parts)\n",
    "        \n",
    "    #print(row)\n",
    "    k_lr_list.append(row)\n",
    "    k_lr_specificity.append(row_specificity)\n",
    "    k_lr_sensitivity.append(row_sensitivity)\n",
    "    k_lr_precision.append(row_precision)\n",
    "    k_lr_f1.append(row_f1)\n",
    "    \n",
    "k_lr_list = pd.DataFrame(k_lr_list, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean accuracy'])\n",
    "print(\"Logistic Regression Kfold Evaluation for MDVR-KCL Dataset Classification Accuracy\")\n",
    "print(k_lr_list)    \n",
    "\n",
    "k_lr_specificity = pd.DataFrame(k_lr_specificity, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean specificity'])\n",
    "print(\"Logistic Regression Kfold Evaluation for MDVR-KCL Dataset - Specificity\")\n",
    "print(k_lr_specificity)\n",
    "\n",
    "k_lr_sensitivity = pd.DataFrame(k_lr_sensitivity, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean sensitivity/recall'])\n",
    "print(\"Logistic Regression Kfold Evaluation for MDVR-KCL Dataset - Sensitivity/Recall\")\n",
    "print(k_lr_sensitivity)\n",
    "\n",
    "k_lr_precision = pd.DataFrame(k_lr_precision, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean precision'])\n",
    "print(\"Logistic Regression Kfold Evaluation for MDVR-KCL Dataset - Precision\")\n",
    "print(k_lr_precision)\n",
    "\n",
    "k_lr_f1 = pd.DataFrame(k_lr_f1, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean f1 score'])\n",
    "print(\"Logistic Regression Kfold Evaluation for MDVR-KCL Dataset - F1 score\")\n",
    "print(k_lr_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# *****************Gradient Boosting Experiments***************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model\n",
    "### without tuning the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73         6\n",
      "           1       0.71      0.83      0.77         6\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.76      0.75      0.75        12\n",
      "weighted avg       0.76      0.75      0.75        12\n",
      "\n",
      "0.7500000000000002\n",
      "[1 1 0 0 1 1 0 0 1 0 1 1]\n",
      "[[4 2]\n",
      " [1 5]]\n"
     ]
    }
   ],
   "source": [
    "###### KNNN ###########\n",
    "# Fit classifier to the Training set\n",
    "#NB\n",
    "\n",
    "model_gb = GradientBoostingClassifier(random_state=0)\n",
    "model_gb = model_gb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gb = model_gb.predict(X_test)\n",
    "\n",
    "conf_matrix_gb = confusion_matrix(y_test, y_pred_gb)\n",
    "\n",
    "accuracy_gb = ((conf_matrix_gb[0,0] + conf_matrix_gb[1,1])/(conf_matrix_gb[0,0] +conf_matrix_gb[0,1]+conf_matrix_gb[1,0]+conf_matrix_gb[1,1]))*100\n",
    "\n",
    "\n",
    "print(accuracy_gb)\n",
    "\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred_gb))\n",
    "#Checking performance our model with ROC Score.\n",
    "print(roc_auc_score(y_test, y_pred_gb))\n",
    "\n",
    "print(y_pred_gb)\n",
    "\n",
    "print(conf_matrix_gb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning for Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.68\n",
      "Best Hyperparameters: {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 4}\n",
      "{'n_estimators': [1, 2, 4, 8, 16, 32, 64, 100, 200], 'max_depth': [1, 3, 5, 7, 9], 'learning_rate': [1, 0.5, 0.25, 0.1, 0.05, 0.01]}\n",
      "50.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.67      0.57         6\n",
      "           1       0.50      0.33      0.40         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.50      0.50      0.49        12\n",
      "weighted avg       0.50      0.50      0.49        12\n",
      "\n",
      "0.5\n",
      "[0 1 0 0 1 0 0 0 1 0 1 0]\n",
      "[1 0 0 0 1 1 0 0 0 1 1 1]\n",
      "[[4 2]\n",
      " [4 2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "########Hyperparameter tuning for SVM####################\n",
    "#List Hyperparameters that we want to tune.\n",
    "#n_components = list(range(1,X.shape[1]+1,1))\n",
    "n_estimators = [1, 2, 4, 8, 16, 32, 64, 100, 200] #[5,50,250,500]\n",
    "max_depth = [1,3,5,7,9]\n",
    "learning_rate = [1, 0.5, 0.25, 0.1, 0.05, 0.01] #[0.01,0.1,1,10,100] \n",
    "\n",
    "#Convert to dictionary\n",
    "hyperparameters = dict(n_estimators=n_estimators,max_depth=max_depth,learning_rate=learning_rate)\n",
    "\n",
    "#Create new LR object\n",
    "model_gb2 = GradientBoostingClassifier()\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "#Use GridSearch\n",
    "clf = GridSearchCV(model_gb2, hyperparameters, cv=10)\n",
    "\n",
    "#clf = RandomizedSearchCV(knn_2, hyperparameters, n_iter=500, cv=8, scoring=\"recall\")\n",
    "#Fit the model\n",
    "best_model = clf.fit(X_train, y_train)\n",
    "#Print The value of best Hyperparameters\n",
    "#print('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])\n",
    "#print('Best p:', best_model.best_estimator_.get_params()['p'])\n",
    "#print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])\n",
    "print('Best Score: %s' % best_model.best_score_)\n",
    "print('Best Hyperparameters: %s' % best_model.best_params_)\n",
    "print(hyperparameters)\n",
    "y_pred_knn_2 = best_model.predict(X_test)\n",
    "\n",
    "conf_matrix_knn_2 = confusion_matrix(y_test, y_pred_knn_2)\n",
    "\n",
    "accuracy_knn_2 = ((conf_matrix_knn_2[0,0] + conf_matrix_knn_2[1,1])/(conf_matrix_knn_2[0,0] +conf_matrix_knn_2[0,1]+conf_matrix_knn_2[1,0]+conf_matrix_knn_2[1,1]))*100\n",
    "\n",
    "\n",
    "print(accuracy_knn_2)\n",
    "\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred_knn_2))\n",
    "#Checking performance our model with ROC Score.\n",
    "print(roc_auc_score(y_test, y_pred_knn_2))\n",
    "\n",
    "print(y_pred_knn_2)\n",
    "print(y_test)\n",
    "\n",
    "print(conf_matrix_knn_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model (GB)\n",
    "### using the optimal parameters gotten above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 2]\n",
      " [0 6]]\n",
      "83.33333333333334\n"
     ]
    }
   ],
   "source": [
    "model_gb = GradientBoostingClassifier(learning_rate= 0.5, max_depth=1,n_estimators=3)\n",
    "model_gb = model_gb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gb_2 = model_gb.predict(X_test)\n",
    "\n",
    "conf_matrix_gb_2 = confusion_matrix(y_test, y_pred_gb_2)\n",
    "\n",
    "accuracy_gb_2 = ((conf_matrix_gb_2[0,0] + conf_matrix_gb_2[1,1])/(conf_matrix_gb_2[0,0] +conf_matrix_gb_2[0,1]+conf_matrix_gb_2[1,0]+conf_matrix_gb_2[1,1]))*100\n",
    "\n",
    "print(conf_matrix_gb_2)\n",
    "print(accuracy_gb_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation (GB) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Fold Evaluation using optimal paramaters. (k =4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divided into 4 parts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:76: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:77: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:77: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:77: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:77: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Kfold Evaluation for MDVR-KCL Dataset Classification Accuracy\n",
      "    Loops  fold 1     fold 2     fold 3     fold 4  mean accuracy\n",
      "0       1    50.0  44.444444  77.777778  55.555556      56.944444\n",
      "1       2    80.0  33.333333  44.444444  66.666667      56.111111\n",
      "2       3    40.0  55.555556  55.555556  55.555556      51.666667\n",
      "3       4    60.0  55.555556  33.333333  55.555556      51.111111\n",
      "4       5    50.0  44.444444  66.666667  66.666667      56.944444\n",
      "5       6    40.0  55.555556  55.555556  66.666667      54.444444\n",
      "6       7    70.0  55.555556  55.555556  55.555556      59.166667\n",
      "7       8    40.0  44.444444  44.444444  66.666667      48.888889\n",
      "8       9    30.0  66.666667  55.555556  66.666667      54.722222\n",
      "9      10    50.0  77.777778  66.666667  55.555556      62.500000\n",
      "10     11    50.0  66.666667  22.222222  44.444444      45.833333\n",
      "Gradient Boosting Kfold Evaluation for MDVR-KCL Dataset - Specificity\n",
      "    Loops      fold 1      fold 2      fold 3      fold 4  mean specificity\n",
      "0       1   37.500000  100.000000  100.000000   50.000000         71.875000\n",
      "1       2  100.000000   60.000000   75.000000   80.000000         78.750000\n",
      "2       3   40.000000   42.857143   80.000000  100.000000         65.714286\n",
      "3       4   66.666667   50.000000   75.000000   80.000000         67.916667\n",
      "4       5   66.666667   75.000000   60.000000   83.333333         71.250000\n",
      "5       6   40.000000   75.000000   60.000000   85.714286         65.178571\n",
      "6       7   83.333333   57.142857   75.000000  100.000000         78.869048\n",
      "7       8   75.000000   80.000000   50.000000   83.333333         72.083333\n",
      "8       9   28.571429  100.000000   60.000000   80.000000         67.142857\n",
      "9      10  100.000000   66.666667   66.666667  100.000000         83.333333\n",
      "10     11   75.000000   66.666667   28.571429  100.000000         67.559524\n",
      "Gradient Boosting Kfold Evaluation for MDVR-KCL Dataset - Sensitivity/Recall\n",
      "    Loops      fold 1      fold 2     fold 3     fold 4  \\\n",
      "0       1  100.000000    0.000000  50.000000  60.000000   \n",
      "1       2   33.333333    0.000000  20.000000  50.000000   \n",
      "2       3   40.000000  100.000000  25.000000  20.000000   \n",
      "3       4   50.000000   66.666667   0.000000  25.000000   \n",
      "4       5   25.000000   20.000000  75.000000  33.333333   \n",
      "5       6   40.000000   40.000000  50.000000   0.000000   \n",
      "6       7   50.000000   50.000000  40.000000  20.000000   \n",
      "7       8   16.666667    0.000000  33.333333  33.333333   \n",
      "8       9   33.333333   40.000000  50.000000  50.000000   \n",
      "9      10    0.000000  100.000000  66.666667  20.000000   \n",
      "10     11   33.333333   66.666667   0.000000   0.000000   \n",
      "\n",
      "    mean sensitivity/recall  \n",
      "0                 52.500000  \n",
      "1                 25.833333  \n",
      "2                 46.250000  \n",
      "3                 35.416667  \n",
      "4                 38.333333  \n",
      "5                 32.500000  \n",
      "6                 40.000000  \n",
      "7                 20.833333  \n",
      "8                 43.333333  \n",
      "9                 46.666667  \n",
      "10                25.000000  \n",
      "Gradient Boosting Kfold Evaluation for MDVR-KCL Dataset - Precision\n",
      "    Loops      fold 1      fold 2      fold 3      fold 4  mean precision\n",
      "0       1   28.571429         NaN  100.000000   60.000000             NaN\n",
      "1       2  100.000000    0.000000   50.000000   66.666667       54.166667\n",
      "2       3   40.000000   33.333333   50.000000  100.000000       55.833333\n",
      "3       4   50.000000   40.000000    0.000000   50.000000       35.000000\n",
      "4       5   33.333333   50.000000   60.000000   50.000000       48.333333\n",
      "5       6   40.000000   66.666667   50.000000    0.000000       39.166667\n",
      "6       7   66.666667   25.000000   66.666667  100.000000       64.583333\n",
      "7       8   50.000000    0.000000   25.000000   50.000000       31.250000\n",
      "8       9   16.666667  100.000000   50.000000   66.666667       58.333333\n",
      "9      10         NaN   60.000000   50.000000  100.000000             NaN\n",
      "10     11   66.666667   50.000000    0.000000         NaN             NaN\n",
      "Gradient Boosting Kfold Evaluation for MDVR-KCL Dataset - F1 score\n",
      "    Loops     fold 1     fold 2     fold 3     fold 4  mean f1 score\n",
      "0       1  44.444444        NaN  66.666667  60.000000            NaN\n",
      "1       2  50.000000        NaN  28.571429  57.142857            NaN\n",
      "2       3  40.000000  50.000000  33.333333  33.333333      39.166667\n",
      "3       4  50.000000  50.000000        NaN  33.333333            NaN\n",
      "4       5  28.571429  28.571429  66.666667  40.000000      40.952381\n",
      "5       6  40.000000  50.000000  50.000000        NaN            NaN\n",
      "6       7  57.142857  33.333333  50.000000  33.333333      43.452381\n",
      "7       8  25.000000        NaN  28.571429  40.000000            NaN\n",
      "8       9  22.222222  57.142857  50.000000  57.142857      46.626984\n",
      "9      10        NaN  75.000000  57.142857  33.333333            NaN\n",
      "10     11  44.444444  57.142857        NaN        NaN            NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:76: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:77: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:76: RuntimeWarning: invalid value encountered in longlong_scalars\n"
     ]
    }
   ],
   "source": [
    "#df_kfold = shuffle(df)\n",
    "#df_kfold.reset_index(inplace=True, drop=True)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "df_kfold = df\n",
    "df_Xnew = df_kfold.iloc[:, :-1].values\n",
    "df_Ynew = df_kfold.iloc[:,-1].values\n",
    "\n",
    "\n",
    "X_kfold = pd.DataFrame(df_Xnew)\n",
    "y_kfold = pd.DataFrame(df_Ynew)\n",
    "#print(X_kfold)\n",
    "#print(y_kfold)\n",
    "\n",
    "parts = 4\n",
    "kfold = KFold(parts, True, None) \n",
    "\n",
    "# splits into 5 groups \n",
    "print(\"Divided into %s parts.\" %parts)\n",
    "\n",
    "k_gb_list = []\n",
    "k_gb_specificity = []\n",
    "k_gb_sensitivity = []\n",
    "k_gb_precision = []\n",
    "k_gb_f1 = []\n",
    "\n",
    "for i in range (1,12):\n",
    "    row = []\n",
    "    row_specificity = []\n",
    "    row_sensitivity = []\n",
    "    row_precision = []\n",
    "    row_f1 = []\n",
    "    \n",
    "    row.append(i)\n",
    "    row_specificity.append(i)\n",
    "    row_sensitivity.append(i)\n",
    "    row_precision.append(i)\n",
    "    row_f1.append(i)\n",
    "    \n",
    "    total = 0\n",
    "    total_specificity = 0\n",
    "    total_sensitivity = 0\n",
    "    total_precision = 0\n",
    "    total_f1 = 0\n",
    "    #print(\"Loop\", i)\n",
    "    for train, test in kfold.split(X_kfold,y_kfold):\n",
    "        #print('\\ntrain: %s, test: %s' % (train, test))\n",
    "        Xtrain_kfold = X_kfold.iloc[train, :]\n",
    "        Ytrain_kfold = y_kfold.iloc[train, :]\n",
    "        Xtest_kfold = X_kfold.iloc[test, :]\n",
    "        Ytest_kfold = y_kfold.iloc[test, :]\n",
    "        #print(Xtest_kfold)\n",
    "        #print(Ytest_kfold)\n",
    "\n",
    "        Xtrain_kfold = sc.fit_transform(Xtrain_kfold)\n",
    "        Xtest_kfold = sc.transform(Xtest_kfold)\n",
    "\n",
    "        #modelling        \n",
    "        model_nb_new = GradientBoostingClassifier(learning_rate= 0.5, max_depth=1,n_estimators=3)\n",
    "        model_nb_new.fit(Xtrain_kfold, Ytrain_kfold)\n",
    "\n",
    "        y_pred_nb_new = model_nb_new.predict(Xtest_kfold)\n",
    "\n",
    "        conf_matrix_knn_kfold = confusion_matrix(Ytest_kfold, y_pred_nb_new)\n",
    "\n",
    "\n",
    "        #accuracy_dt_kfold = ((conf_matrix_dt_kfold[0,0] + conf_matrix_dt_kfold[1,1])/(conf_matrix_dt_kfold[0,0] +conf_matrix_dt_kfold[0,1]+conf_matrix_dt_kfold[1,0]+conf_matrix_dt_kfold[1,1]))*100\n",
    "        TN = conf_matrix_knn_kfold[0][0]\n",
    "        FP = conf_matrix_knn_kfold[0][1]\n",
    "        FN = conf_matrix_knn_kfold[1][0]\n",
    "        TP = conf_matrix_knn_kfold[1][1]\n",
    "        \n",
    "    \n",
    "        accuracy_knn_kfold = ((TP + TN) / (TP + TN + FP + FN)) * 100\n",
    "        sensitivity_knn_kfold = (TP/(TP+FN)) * 100 #recall\n",
    "        specificity_knn_kfold = (TN/(TN + FP)) * 100\n",
    "        precision_knn_kfold = (TP/(TP+FP)) *100\n",
    "        f1_knn_kfold = 2 *((sensitivity_knn_kfold * precision_knn_kfold)/(sensitivity_knn_kfold + precision_knn_kfold))\n",
    "\n",
    "\n",
    "        row.append(accuracy_knn_kfold)\n",
    "        row_specificity.append(specificity_knn_kfold)\n",
    "        row_sensitivity.append(sensitivity_knn_kfold)\n",
    "        row_precision.append(precision_knn_kfold)\n",
    "        row_f1.append(f1_knn_kfold)\n",
    "        \n",
    "        total += accuracy_knn_kfold\n",
    "        total_specificity += specificity_knn_kfold\n",
    "        total_sensitivity += sensitivity_knn_kfold\n",
    "        total_precision += precision_knn_kfold\n",
    "        total_f1 += f1_knn_kfold\n",
    "\n",
    "    average = row.append(total/parts)   \n",
    "    row_specificity.append(total_specificity/parts)\n",
    "    row_sensitivity.append(total_sensitivity/parts)\n",
    "    row_precision.append(total_precision/parts)\n",
    "    row_f1.append(total_f1/parts)\n",
    "        \n",
    "    #print(row)\n",
    "    k_gb_list.append(row)\n",
    "    k_gb_specificity.append(row_specificity)\n",
    "    k_gb_sensitivity.append(row_sensitivity)\n",
    "    k_gb_precision.append(row_precision)\n",
    "    k_gb_f1.append(row_f1)\n",
    "    \n",
    "k_gb_list = pd.DataFrame(k_gb_list, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean accuracy'])\n",
    "print(\"Gradient Boosting Kfold Evaluation for MDVR-KCL Dataset Classification Accuracy\")\n",
    "print(k_gb_list)    \n",
    "\n",
    "k_gb_specificity = pd.DataFrame(k_gb_specificity, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean specificity'])\n",
    "print(\"Gradient Boosting Kfold Evaluation for MDVR-KCL Dataset - Specificity\")\n",
    "print(k_gb_specificity)\n",
    "\n",
    "k_gb_sensitivity = pd.DataFrame(k_gb_sensitivity, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean sensitivity/recall'])\n",
    "print(\"Gradient Boosting Kfold Evaluation for MDVR-KCL Dataset - Sensitivity/Recall\")\n",
    "print(k_gb_sensitivity)\n",
    "\n",
    "k_gb_precision = pd.DataFrame(k_gb_precision, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean precision'])\n",
    "print(\"Gradient Boosting Kfold Evaluation for MDVR-KCL Dataset - Precision\")\n",
    "print(k_gb_precision)\n",
    "\n",
    "k_gb_f1 = pd.DataFrame(k_gb_f1, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean f1 score'])\n",
    "print(\"Gradient Boosting Kfold Evaluation for MDVR-KCL Dataset - F1 score\")\n",
    "print(k_gb_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# *****************Random Forest Experiments***************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model\n",
    "### without tuning the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.67      0.57         6\n",
      "           1       0.50      0.33      0.40         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.50      0.50      0.49        12\n",
      "weighted avg       0.50      0.50      0.49        12\n",
      "\n",
      "0.5\n",
      "[0 1 0 0 0 0 0 0 1 0 1 1]\n",
      "[[4 2]\n",
      " [4 2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "###### KNNN ###########\n",
    "# Fit classifier to the Training set\n",
    "#NB\n",
    "\n",
    "model_gb = RandomForestClassifier()\n",
    "model_gb = model_gb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gb = model_gb.predict(X_test)\n",
    "\n",
    "conf_matrix_gb = confusion_matrix(y_test, y_pred_gb)\n",
    "\n",
    "accuracy_gb = ((conf_matrix_gb[0,0] + conf_matrix_gb[1,1])/(conf_matrix_gb[0,0] +conf_matrix_gb[0,1]+conf_matrix_gb[1,0]+conf_matrix_gb[1,1]))*100\n",
    "\n",
    "\n",
    "print(accuracy_gb)\n",
    "\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred_gb))\n",
    "#Checking performance our model with ROC Score.\n",
    "print(roc_auc_score(y_test, y_pred_gb))\n",
    "\n",
    "print(y_pred_gb)\n",
    "\n",
    "print(conf_matrix_gb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.8\n",
      "Best Hyperparameters: {'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 16}\n",
      "{'n_estimators': [1, 2, 4, 8, 16, 32, 64, 100, 200], 'max_depth': [1, 3, 5, 7, 9], 'max_features': ['auto', 'sqrt', 'log2'], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 5, 10, 15]}\n",
      "66.66666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.50      0.60         6\n",
      "           1       0.62      0.83      0.71         6\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.69      0.67      0.66        12\n",
      "weighted avg       0.69      0.67      0.66        12\n",
      "\n",
      "0.6666666666666667\n",
      "[1 1 0 0 0 1 0 1 1 1 1 1]\n",
      "[1 0 0 0 1 1 0 0 0 1 1 1]\n",
      "[[3 3]\n",
      " [1 5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "########Hyperparameter tuning for SVM####################\n",
    "#List Hyperparameters that we want to tune.\n",
    "#n_components = list(range(1,X.shape[1]+1,1))\n",
    "n_estimators = [1, 2, 4, 8, 16, 32, 64, 100, 200] #[5,50,250,500]\n",
    "max_depth = [1,3,5,7,9]\n",
    "max_features = ['auto', 'sqrt', 'log2'] #[0.01,0.1,1,10,100] \n",
    "min_samples_split = [2,5,10]\n",
    "min_samples_leaf = [1,2,5,10,15]\n",
    "\n",
    "#Convert to dictionary\n",
    "hyperparameters = dict(n_estimators=n_estimators,max_depth=max_depth,max_features=max_features, min_samples_split=min_samples_split,min_samples_leaf=min_samples_leaf )\n",
    "\n",
    "#Create new LR object\n",
    "model_gb2 = RandomForestClassifier()\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "#Use GridSearch\n",
    "clf = GridSearchCV(model_gb2, hyperparameters, cv=10)\n",
    "\n",
    "#clf = RandomizedSearchCV(knn_2, hyperparameters, n_iter=500, cv=8, scoring=\"recall\")\n",
    "#Fit the model\n",
    "best_model = clf.fit(X_train, y_train)\n",
    "#Print The value of best Hyperparameters\n",
    "#print('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])\n",
    "#print('Best p:', best_model.best_estimator_.get_params()['p'])\n",
    "#print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])\n",
    "print('Best Score: %s' % best_model.best_score_)\n",
    "print('Best Hyperparameters: %s' % best_model.best_params_)\n",
    "print(hyperparameters)\n",
    "y_pred_knn_2 = best_model.predict(X_test)\n",
    "\n",
    "conf_matrix_knn_2 = confusion_matrix(y_test, y_pred_knn_2)\n",
    "\n",
    "accuracy_knn_2 = ((conf_matrix_knn_2[0,0] + conf_matrix_knn_2[1,1])/(conf_matrix_knn_2[0,0] +conf_matrix_knn_2[0,1]+conf_matrix_knn_2[1,0]+conf_matrix_knn_2[1,1]))*100\n",
    "\n",
    "\n",
    "print(accuracy_knn_2)\n",
    "\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred_knn_2))\n",
    "#Checking performance our model with ROC Score.\n",
    "print(roc_auc_score(y_test, y_pred_knn_2))\n",
    "\n",
    "print(y_pred_knn_2)\n",
    "print(y_test)\n",
    "\n",
    "print(conf_matrix_knn_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model (Random Forest)\n",
    "### using the optimal parameters gotten above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 3]\n",
      " [1 5]]\n",
      "66.66666666666666\n"
     ]
    }
   ],
   "source": [
    "model_gb = RandomForestClassifier(n_estimators=16,max_depth=3,max_features='auto', min_samples_split=10,min_samples_leaf=5)\n",
    "model_gb = model_gb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gb_2 = model_gb.predict(X_test)\n",
    "\n",
    "conf_matrix_gb_2 = confusion_matrix(y_test, y_pred_gb_2)\n",
    "\n",
    "accuracy_gb_2 = ((conf_matrix_gb_2[0,0] + conf_matrix_gb_2[1,1])/(conf_matrix_gb_2[0,0] +conf_matrix_gb_2[0,1]+conf_matrix_gb_2[1,0]+conf_matrix_gb_2[1,1]))*100\n",
    "\n",
    "print(conf_matrix_gb_2)\n",
    "print(accuracy_gb_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation (RF) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Fold Evaluation using optimal paramaters. (k =4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divided into 4 parts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:77: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:77: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:77: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:77: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:77: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Kfold Evaluation for MDVR-KCL Dataset Classification Accuracy\n",
      "    Loops  fold 1     fold 2     fold 3      fold 4  mean accuracy\n",
      "0       1    50.0  44.444444  77.777778  100.000000      68.055556\n",
      "1       2    70.0  44.444444  55.555556   55.555556      56.388889\n",
      "2       3    60.0  66.666667  33.333333   55.555556      53.888889\n",
      "3       4    30.0  33.333333  55.555556   66.666667      46.388889\n",
      "4       5    60.0  55.555556  66.666667   77.777778      65.000000\n",
      "5       6    60.0  55.555556  55.555556   77.777778      62.222222\n",
      "6       7    70.0  66.666667  55.555556   55.555556      61.944444\n",
      "7       8    30.0  44.444444  77.777778   66.666667      54.722222\n",
      "8       9    60.0  66.666667  77.777778   66.666667      67.777778\n",
      "9      10    70.0  55.555556  66.666667   77.777778      67.500000\n",
      "10     11    40.0  77.777778  88.888889   66.666667      68.333333\n",
      "Gradient Boosting Kfold Evaluation for MDVR-KCL Dataset - Specificity\n",
      "    Loops      fold 1      fold 2     fold 3      fold 4  mean specificity\n",
      "0       1  100.000000   28.571429  60.000000  100.000000         72.142857\n",
      "1       2   80.000000   33.333333  80.000000   80.000000         68.333333\n",
      "2       3  100.000000   40.000000  33.333333   66.666667         60.000000\n",
      "3       4   75.000000   50.000000  42.857143   75.000000         60.714286\n",
      "4       5   75.000000   50.000000  60.000000  100.000000         71.250000\n",
      "5       6  100.000000   83.333333  60.000000   66.666667         77.500000\n",
      "6       7   80.000000   85.714286  42.857143  100.000000         77.142857\n",
      "7       8   66.666667   20.000000  83.333333   71.428571         60.357143\n",
      "8       9   66.666667   60.000000  83.333333   50.000000         65.000000\n",
      "9      10   71.428571  100.000000  40.000000   66.666667         69.523810\n",
      "10     11   75.000000   80.000000  83.333333   83.333333         80.416667\n",
      "Gradient Boosting Kfold Evaluation for MDVR-KCL Dataset - Sensitivity/Recall\n",
      "    Loops     fold 1      fold 2      fold 3      fold 4  \\\n",
      "0       1  16.666667  100.000000  100.000000  100.000000   \n",
      "1       2  60.000000   66.666667   25.000000   25.000000   \n",
      "2       3  33.333333  100.000000   33.333333   33.333333   \n",
      "3       4   0.000000    0.000000  100.000000   60.000000   \n",
      "4       5   0.000000   60.000000   75.000000   60.000000   \n",
      "5       6  33.333333    0.000000   50.000000  100.000000   \n",
      "6       7  60.000000    0.000000  100.000000   42.857143   \n",
      "7       8  14.285714   75.000000   66.666667   50.000000   \n",
      "8       9  50.000000   75.000000   66.666667   80.000000   \n",
      "9      10  66.666667   33.333333  100.000000  100.000000   \n",
      "10     11  16.666667   75.000000  100.000000   33.333333   \n",
      "\n",
      "    mean sensitivity/recall  \n",
      "0                 79.166667  \n",
      "1                 44.166667  \n",
      "2                 50.000000  \n",
      "3                 40.000000  \n",
      "4                 48.750000  \n",
      "5                 45.833333  \n",
      "6                 50.714286  \n",
      "7                 51.488095  \n",
      "8                 67.916667  \n",
      "9                 75.000000  \n",
      "10                56.250000  \n",
      "Gradient Boosting Kfold Evaluation for MDVR-KCL Dataset - Precision\n",
      "    Loops  fold 1      fold 2     fold 3      fold 4  mean precision\n",
      "0       1   100.0   28.571429  66.666667  100.000000       73.809524\n",
      "1       2    75.0   33.333333  50.000000   50.000000       52.083333\n",
      "2       3   100.0   57.142857  20.000000   33.333333       52.619048\n",
      "3       4     0.0    0.000000  33.333333   75.000000       27.083333\n",
      "4       5     0.0   60.000000  60.000000  100.000000       55.000000\n",
      "5       6   100.0    0.000000  50.000000   60.000000       52.500000\n",
      "6       7    75.0    0.000000  33.333333  100.000000       52.083333\n",
      "7       8    50.0   42.857143  66.666667   33.333333       48.214286\n",
      "8       9    50.0   60.000000  66.666667   66.666667       60.833333\n",
      "9      10    50.0  100.000000  57.142857   60.000000       66.785714\n",
      "10     11    50.0   75.000000  75.000000   50.000000       62.500000\n",
      "Gradient Boosting Kfold Evaluation for MDVR-KCL Dataset - F1 score\n",
      "    Loops     fold 1     fold 2     fold 3      fold 4  mean f1 score\n",
      "0       1  28.571429  44.444444  80.000000  100.000000      63.253968\n",
      "1       2  66.666667  44.444444  33.333333   33.333333      44.444444\n",
      "2       3  50.000000  72.727273  25.000000   33.333333      45.265152\n",
      "3       4        NaN        NaN  50.000000   66.666667            NaN\n",
      "4       5        NaN  60.000000  66.666667   75.000000            NaN\n",
      "5       6  50.000000        NaN  50.000000   75.000000            NaN\n",
      "6       7  66.666667        NaN  50.000000   60.000000            NaN\n",
      "7       8  22.222222  54.545455  66.666667   40.000000      45.858586\n",
      "8       9  50.000000  66.666667  66.666667   72.727273      64.015152\n",
      "9      10  57.142857  50.000000  72.727273   75.000000      63.717532\n",
      "10     11  25.000000  75.000000  85.714286   40.000000      56.428571\n"
     ]
    }
   ],
   "source": [
    "#df_kfold = shuffle(df)\n",
    "#df_kfold.reset_index(inplace=True, drop=True)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "df_kfold = df\n",
    "df_Xnew = df_kfold.iloc[:, :-1].values\n",
    "df_Ynew = df_kfold.iloc[:,-1].values\n",
    "\n",
    "\n",
    "X_kfold = pd.DataFrame(df_Xnew)\n",
    "y_kfold = pd.DataFrame(df_Ynew)\n",
    "#print(X_kfold)\n",
    "#print(y_kfold)\n",
    "\n",
    "parts = 4\n",
    "kfold = KFold(parts, True, None) \n",
    "\n",
    "# splits into 5 groups \n",
    "print(\"Divided into %s parts.\" %parts)\n",
    "\n",
    "k_rf_list = []\n",
    "k_rf_specificity = []\n",
    "k_rf_sensitivity = []\n",
    "k_rf_precision = []\n",
    "k_rf_f1 = []\n",
    "\n",
    "for i in range (1,12):\n",
    "    row = []\n",
    "    row_specificity = []\n",
    "    row_sensitivity = []\n",
    "    row_precision = []\n",
    "    row_f1 = []\n",
    "    \n",
    "    row.append(i)\n",
    "    row_specificity.append(i)\n",
    "    row_sensitivity.append(i)\n",
    "    row_precision.append(i)\n",
    "    row_f1.append(i)\n",
    "    \n",
    "    total = 0\n",
    "    total_specificity = 0\n",
    "    total_sensitivity = 0\n",
    "    total_precision = 0\n",
    "    total_f1 = 0\n",
    "    #print(\"Loop\", i)\n",
    "    for train, test in kfold.split(X_kfold,y_kfold):\n",
    "        #print('\\ntrain: %s, test: %s' % (train, test))\n",
    "        Xtrain_kfold = X_kfold.iloc[train, :]\n",
    "        Ytrain_kfold = y_kfold.iloc[train, :]\n",
    "        Xtest_kfold = X_kfold.iloc[test, :]\n",
    "        Ytest_kfold = y_kfold.iloc[test, :]\n",
    "        #print(Xtest_kfold)\n",
    "        #print(Ytest_kfold)\n",
    "\n",
    "        Xtrain_kfold = sc.fit_transform(Xtrain_kfold)\n",
    "        Xtest_kfold = sc.transform(Xtest_kfold)\n",
    "\n",
    "        #modelling              \n",
    "        model_nb_new = RandomForestClassifier(n_estimators=16,max_depth=3,max_features='auto', min_samples_split=10,min_samples_leaf=5)\n",
    "        model_nb_new.fit(Xtrain_kfold, Ytrain_kfold)\n",
    "\n",
    "        y_pred_nb_new = model_nb_new.predict(Xtest_kfold)\n",
    "\n",
    "        conf_matrix_knn_kfold = confusion_matrix(Ytest_kfold, y_pred_nb_new)\n",
    "\n",
    "\n",
    "        #accuracy_dt_kfold = ((conf_matrix_dt_kfold[0,0] + conf_matrix_dt_kfold[1,1])/(conf_matrix_dt_kfold[0,0] +conf_matrix_dt_kfold[0,1]+conf_matrix_dt_kfold[1,0]+conf_matrix_dt_kfold[1,1]))*100\n",
    "        TN = conf_matrix_knn_kfold[0][0]\n",
    "        FP = conf_matrix_knn_kfold[0][1]\n",
    "        FN = conf_matrix_knn_kfold[1][0]\n",
    "        TP = conf_matrix_knn_kfold[1][1]\n",
    "        \n",
    "    \n",
    "        accuracy_knn_kfold = ((TP + TN) / (TP + TN + FP + FN)) * 100\n",
    "        sensitivity_knn_kfold = (TP/(TP+FN)) * 100 #recall\n",
    "        specificity_knn_kfold = (TN/(TN + FP)) * 100\n",
    "        precision_knn_kfold = (TP/(TP+FP)) *100\n",
    "        f1_knn_kfold = 2 *((sensitivity_knn_kfold * precision_knn_kfold)/(sensitivity_knn_kfold + precision_knn_kfold))\n",
    "\n",
    "\n",
    "        row.append(accuracy_knn_kfold)\n",
    "        row_specificity.append(specificity_knn_kfold)\n",
    "        row_sensitivity.append(sensitivity_knn_kfold)\n",
    "        row_precision.append(precision_knn_kfold)\n",
    "        row_f1.append(f1_knn_kfold)\n",
    "        \n",
    "        total += accuracy_knn_kfold\n",
    "        total_specificity += specificity_knn_kfold\n",
    "        total_sensitivity += sensitivity_knn_kfold\n",
    "        total_precision += precision_knn_kfold\n",
    "        total_f1 += f1_knn_kfold\n",
    "\n",
    "    average = row.append(total/parts)   \n",
    "    row_specificity.append(total_specificity/parts)\n",
    "    row_sensitivity.append(total_sensitivity/parts)\n",
    "    row_precision.append(total_precision/parts)\n",
    "    row_f1.append(total_f1/parts)\n",
    "        \n",
    "    #print(row)\n",
    "    k_rf_list.append(row)\n",
    "    k_rf_specificity.append(row_specificity)\n",
    "    k_rf_sensitivity.append(row_sensitivity)\n",
    "    k_rf_precision.append(row_precision)\n",
    "    k_rf_f1.append(row_f1)\n",
    "    \n",
    "k_rf_list = pd.DataFrame(k_rf_list, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean accuracy'])\n",
    "print(\"Gradient Boosting Kfold Evaluation for MDVR-KCL Dataset Classification Accuracy\")\n",
    "print(k_rf_list)    \n",
    "\n",
    "k_rf_specificity = pd.DataFrame(k_rf_specificity, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean specificity'])\n",
    "print(\"Gradient Boosting Kfold Evaluation for MDVR-KCL Dataset - Specificity\")\n",
    "print(k_rf_specificity)\n",
    "\n",
    "k_rf_sensitivity = pd.DataFrame(k_rf_sensitivity, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean sensitivity/recall'])\n",
    "print(\"Gradient Boosting Kfold Evaluation for MDVR-KCL Dataset - Sensitivity/Recall\")\n",
    "print(k_rf_sensitivity)\n",
    "\n",
    "k_rf_precision = pd.DataFrame(k_rf_precision, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean precision'])\n",
    "print(\"Gradient Boosting Kfold Evaluation for MDVR-KCL Dataset - Precision\")\n",
    "print(k_rf_precision)\n",
    "\n",
    "k_rf_f1 = pd.DataFrame(k_rf_f1, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean f1 score'])\n",
    "print(\"Gradient Boosting Kfold Evaluation for MDVR-KCL Dataset - F1 score\")\n",
    "print(k_rf_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.11111111111111\n",
      "58.48484848484848\n",
      "72.22222222222221\n",
      "70.22727272727272\n",
      "70.47979797979798\n",
      "54.3939393939394\n",
      "61.111111111111114\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNN</th>\n",
       "      <th>Decision Trees</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>GB</th>\n",
       "      <th>Random Forest</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Performance Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Classification Accuracy</td>\n",
       "      <td>61.111111</td>\n",
       "      <td>58.484848</td>\n",
       "      <td>72.222222</td>\n",
       "      <td>70.227273</td>\n",
       "      <td>70.479798</td>\n",
       "      <td>54.393939</td>\n",
       "      <td>61.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Specificity Accuracy</td>\n",
       "      <td>83.138528</td>\n",
       "      <td>69.852994</td>\n",
       "      <td>72.222222</td>\n",
       "      <td>70.227273</td>\n",
       "      <td>70.479798</td>\n",
       "      <td>54.393939</td>\n",
       "      <td>61.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               KNN  Decision Trees        SVM  Naive Bayes  \\\n",
       "Performance Metric                                                           \n",
       "Classification Accuracy  61.111111       58.484848  72.222222    70.227273   \n",
       "Specificity Accuracy     83.138528       69.852994  72.222222    70.227273   \n",
       "\n",
       "                         Logistic Regression         GB  Random Forest  \n",
       "Performance Metric                                                      \n",
       "Classification Accuracy            70.479798  54.393939      61.111111  \n",
       "Specificity Accuracy               70.479798  54.393939      61.111111  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comparison = []\n",
    "\n",
    "##################classifictaion accuracy\n",
    "knn_mean_accuracy = k_list[\"mean accuracy\"].mean()\n",
    "dt_mean_accuracy = k_dt_list[\"mean accuracy\"].mean()\n",
    "svm_mean_accuracy = k_svm_list[\"mean accuracy\"].mean()\n",
    "nb_mean_accuracy = k_nb_list[\"mean accuracy\"].mean()\n",
    "lr_mean_accuracy = k_lr_list[\"mean accuracy\"].mean()\n",
    "gb_mean_accuracy = k_gb_list[\"mean accuracy\"].mean()\n",
    "rf_mean_accuracy = k_rf_list[\"mean accuracy\"].mean()\n",
    "\n",
    "print(knn_mean_accuracy)\n",
    "print(dt_mean_accuracy)\n",
    "print(svm_mean_accuracy)\n",
    "print(nb_mean_accuracy)\n",
    "print(lr_mean_accuracy)\n",
    "print(gb_mean_accuracy)\n",
    "print(rf_mean_accuracy)\n",
    "rf_mean_accuracy\n",
    "\n",
    "classification_accuracy = ['Classification Accuracy',knn_mean_accuracy,dt_mean_accuracy,svm_mean_accuracy,nb_mean_accuracy,lr_mean_accuracy,gb_mean_accuracy,rf_mean_accuracy]\n",
    "df_comparison.append(classification_accuracy)\n",
    "\n",
    "#########################specificity\n",
    "knn_mean_specificity = k_specificity[\"mean specificity\"].mean()\n",
    "dt_mean_specificity = k_dt_specificity[\"mean specificity\"].mean()\n",
    "\n",
    "#specificity = ['Specificity',knn_mean_specificity,dt_mean_specificity]\n",
    "specificity = ['Specificity Accuracy',knn_mean_specificity,dt_mean_specificity,svm_mean_accuracy,nb_mean_accuracy,lr_mean_accuracy,gb_mean_accuracy,rf_mean_accuracy]\n",
    "\n",
    "df_comparison.append(specificity)\n",
    "\n",
    "df_comparison = pd.DataFrame(df_comparison, columns=[\"Performance Metric\", \"KNN\", \"Decision Trees\",\"SVM\", \"Naive Bayes\", \"Logistic Regression\", \"GB\", \"Random Forest\"])\n",
    "\n",
    "df_comparison = df_comparison.set_index('Performance Metric')\n",
    "df_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNN</th>\n",
       "      <th>Decision Trees</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>GB</th>\n",
       "      <th>Random Forest</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Performance Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Classification Accuracy</td>\n",
       "      <td>61.111111</td>\n",
       "      <td>58.484848</td>\n",
       "      <td>72.222222</td>\n",
       "      <td>70.227273</td>\n",
       "      <td>70.479798</td>\n",
       "      <td>54.393939</td>\n",
       "      <td>61.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Specificity Accuracy</td>\n",
       "      <td>83.138528</td>\n",
       "      <td>69.852994</td>\n",
       "      <td>72.222222</td>\n",
       "      <td>70.227273</td>\n",
       "      <td>70.479798</td>\n",
       "      <td>54.393939</td>\n",
       "      <td>61.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               KNN  Decision Trees        SVM  Naive Bayes  \\\n",
       "Performance Metric                                                           \n",
       "Classification Accuracy  61.111111       58.484848  72.222222    70.227273   \n",
       "Specificity Accuracy     83.138528       69.852994  72.222222    70.227273   \n",
       "\n",
       "                         Logistic Regression         GB  Random Forest  \n",
       "Performance Metric                                                      \n",
       "Classification Accuracy            70.479798  54.393939      61.111111  \n",
       "Specificity Accuracy               70.479798  54.393939      61.111111  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = df_comparison.loc[ ['Classification Accuracy' , 'Specificity Accuracy'] , : ]\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), <a list of 2 Text xticklabel objects>)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_comparison.plot(kind=\"bar\", figsize=(15, 10))\n",
    "plt.xticks(rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x14ea2b32d88>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_comparison[['KNN','Decision Trees']].plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loops</th>\n",
       "      <th>fold 1</th>\n",
       "      <th>fold 2</th>\n",
       "      <th>fold 3</th>\n",
       "      <th>fold 4</th>\n",
       "      <th>mean accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>73.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>75.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>72.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>60.0</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>67.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>75.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>80.0</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>60.0</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>73.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>80.0</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>90.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>75.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>60.0</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>76.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>60.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>65.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loops  fold 1     fold 2     fold 3     fold 4  mean accuracy\n",
       "0       1    60.0  77.777778  88.888889  66.666667      73.333333\n",
       "1       2    70.0  66.666667  88.888889  77.777778      75.833333\n",
       "2       3    80.0  77.777778  66.666667  66.666667      72.777778\n",
       "3       4    60.0  77.777778  44.444444  88.888889      67.777778\n",
       "4       5    80.0  88.888889  77.777778  55.555556      75.555556\n",
       "5       6    80.0  55.555556  66.666667  77.777778      70.000000\n",
       "6       7    60.0  77.777778  66.666667  88.888889      73.333333\n",
       "7       8    80.0  44.444444  77.777778  77.777778      70.000000\n",
       "8       9    90.0  66.666667  77.777778  66.666667      75.277778\n",
       "9      10    60.0  77.777778  88.888889  77.777778      76.111111\n",
       "10     11    60.0  66.666667  66.666667  66.666667      65.000000"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loops</th>\n",
       "      <th>fold 1</th>\n",
       "      <th>fold 2</th>\n",
       "      <th>fold 3</th>\n",
       "      <th>fold 4</th>\n",
       "      <th>mean accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70.0</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>70.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>60.0</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>67.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>80.0</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>67.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>60.0</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>73.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>67.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>70.0</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>70.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>90.0</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>75.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>60.0</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>67.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>80.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>60.0</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>67.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>80.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>75.555556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loops  fold 1     fold 2     fold 3      fold 4  mean accuracy\n",
       "0       1    70.0  88.888889  55.555556   66.666667      70.277778\n",
       "1       2    60.0  77.777778  66.666667   66.666667      67.777778\n",
       "2       3    80.0  44.444444  77.777778   66.666667      67.222222\n",
       "3       4    60.0  88.888889  44.444444  100.000000      73.333333\n",
       "4       5    80.0  55.555556  66.666667   66.666667      67.222222\n",
       "5       6    70.0  55.555556  88.888889   66.666667      70.277778\n",
       "6       7    90.0  77.777778  55.555556   77.777778      75.277778\n",
       "7       8    60.0  55.555556  88.888889   66.666667      67.777778\n",
       "8       9    80.0  66.666667  55.555556   77.777778      70.000000\n",
       "9      10    60.0  55.555556  88.888889   66.666667      67.777778\n",
       "10     11    80.0  66.666667  77.777778   77.777778      75.555556"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_nb_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
