{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on MDVR-KCL Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import seaborn as sns\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy import mean\n",
    "from numpy import std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanF0Hz</th>\n",
       "      <th>stdevF0Hz</th>\n",
       "      <th>HNR</th>\n",
       "      <th>localJitter</th>\n",
       "      <th>localabsoluteJitter</th>\n",
       "      <th>rapJitter</th>\n",
       "      <th>ppq5Jitter</th>\n",
       "      <th>localShimmer</th>\n",
       "      <th>localdbShimmer</th>\n",
       "      <th>apq3Shimmer</th>\n",
       "      <th>apq5Shimmer</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>180.433976</td>\n",
       "      <td>51.653057</td>\n",
       "      <td>13.292053</td>\n",
       "      <td>0.027039</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.012019</td>\n",
       "      <td>0.013197</td>\n",
       "      <td>0.113439</td>\n",
       "      <td>1.124025</td>\n",
       "      <td>0.046161</td>\n",
       "      <td>0.067371</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>190.751972</td>\n",
       "      <td>34.887596</td>\n",
       "      <td>11.243993</td>\n",
       "      <td>0.016118</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.006764</td>\n",
       "      <td>0.007168</td>\n",
       "      <td>0.079053</td>\n",
       "      <td>0.740666</td>\n",
       "      <td>0.029396</td>\n",
       "      <td>0.038308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>124.477366</td>\n",
       "      <td>26.621493</td>\n",
       "      <td>13.423983</td>\n",
       "      <td>0.026740</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.010862</td>\n",
       "      <td>0.011512</td>\n",
       "      <td>0.102565</td>\n",
       "      <td>0.974095</td>\n",
       "      <td>0.039042</td>\n",
       "      <td>0.058131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>182.557207</td>\n",
       "      <td>39.933612</td>\n",
       "      <td>12.235210</td>\n",
       "      <td>0.020701</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.008979</td>\n",
       "      <td>0.008983</td>\n",
       "      <td>0.080388</td>\n",
       "      <td>0.811653</td>\n",
       "      <td>0.025759</td>\n",
       "      <td>0.037847</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>195.969796</td>\n",
       "      <td>41.446983</td>\n",
       "      <td>14.669165</td>\n",
       "      <td>0.015063</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.005371</td>\n",
       "      <td>0.006017</td>\n",
       "      <td>0.082016</td>\n",
       "      <td>0.827343</td>\n",
       "      <td>0.029087</td>\n",
       "      <td>0.043951</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>168.012461</td>\n",
       "      <td>35.493510</td>\n",
       "      <td>13.020618</td>\n",
       "      <td>0.021790</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.009273</td>\n",
       "      <td>0.009862</td>\n",
       "      <td>0.078274</td>\n",
       "      <td>0.786047</td>\n",
       "      <td>0.024992</td>\n",
       "      <td>0.039414</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>203.130952</td>\n",
       "      <td>48.609299</td>\n",
       "      <td>12.333993</td>\n",
       "      <td>0.027164</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.012624</td>\n",
       "      <td>0.013001</td>\n",
       "      <td>0.102844</td>\n",
       "      <td>0.994058</td>\n",
       "      <td>0.039932</td>\n",
       "      <td>0.053414</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>197.503773</td>\n",
       "      <td>36.631657</td>\n",
       "      <td>15.683277</td>\n",
       "      <td>0.017656</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.007171</td>\n",
       "      <td>0.007674</td>\n",
       "      <td>0.078181</td>\n",
       "      <td>0.757354</td>\n",
       "      <td>0.029970</td>\n",
       "      <td>0.039306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>199.081279</td>\n",
       "      <td>41.081947</td>\n",
       "      <td>11.784297</td>\n",
       "      <td>0.024917</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.011396</td>\n",
       "      <td>0.011915</td>\n",
       "      <td>0.096619</td>\n",
       "      <td>0.963974</td>\n",
       "      <td>0.033895</td>\n",
       "      <td>0.049371</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>157.113264</td>\n",
       "      <td>46.419171</td>\n",
       "      <td>13.388906</td>\n",
       "      <td>0.034113</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.017499</td>\n",
       "      <td>0.016585</td>\n",
       "      <td>0.119624</td>\n",
       "      <td>1.104118</td>\n",
       "      <td>0.053728</td>\n",
       "      <td>0.058976</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>163.844699</td>\n",
       "      <td>54.076942</td>\n",
       "      <td>11.548012</td>\n",
       "      <td>0.018828</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.007439</td>\n",
       "      <td>0.009032</td>\n",
       "      <td>0.105805</td>\n",
       "      <td>0.993686</td>\n",
       "      <td>0.038722</td>\n",
       "      <td>0.060542</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>154.205413</td>\n",
       "      <td>42.577809</td>\n",
       "      <td>11.369774</td>\n",
       "      <td>0.029419</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.013191</td>\n",
       "      <td>0.012156</td>\n",
       "      <td>0.089834</td>\n",
       "      <td>0.912168</td>\n",
       "      <td>0.033115</td>\n",
       "      <td>0.046434</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>160.093999</td>\n",
       "      <td>31.936264</td>\n",
       "      <td>12.994633</td>\n",
       "      <td>0.018726</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.007586</td>\n",
       "      <td>0.008082</td>\n",
       "      <td>0.080560</td>\n",
       "      <td>0.774723</td>\n",
       "      <td>0.029102</td>\n",
       "      <td>0.040420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>173.417455</td>\n",
       "      <td>34.365179</td>\n",
       "      <td>14.193625</td>\n",
       "      <td>0.022659</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.009854</td>\n",
       "      <td>0.010656</td>\n",
       "      <td>0.090751</td>\n",
       "      <td>0.878991</td>\n",
       "      <td>0.031667</td>\n",
       "      <td>0.046121</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>179.048747</td>\n",
       "      <td>35.403221</td>\n",
       "      <td>16.224981</td>\n",
       "      <td>0.013899</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.005279</td>\n",
       "      <td>0.005674</td>\n",
       "      <td>0.072685</td>\n",
       "      <td>0.730909</td>\n",
       "      <td>0.027094</td>\n",
       "      <td>0.038795</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>197.330931</td>\n",
       "      <td>39.729669</td>\n",
       "      <td>15.950713</td>\n",
       "      <td>0.016124</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.005896</td>\n",
       "      <td>0.006771</td>\n",
       "      <td>0.085010</td>\n",
       "      <td>0.810418</td>\n",
       "      <td>0.029995</td>\n",
       "      <td>0.044046</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>183.050353</td>\n",
       "      <td>46.792915</td>\n",
       "      <td>13.081668</td>\n",
       "      <td>0.024480</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.010880</td>\n",
       "      <td>0.010480</td>\n",
       "      <td>0.079695</td>\n",
       "      <td>0.767308</td>\n",
       "      <td>0.030681</td>\n",
       "      <td>0.039645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>194.704118</td>\n",
       "      <td>54.785527</td>\n",
       "      <td>13.076819</td>\n",
       "      <td>0.021499</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.009724</td>\n",
       "      <td>0.009703</td>\n",
       "      <td>0.086963</td>\n",
       "      <td>0.876711</td>\n",
       "      <td>0.032313</td>\n",
       "      <td>0.044567</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>214.216909</td>\n",
       "      <td>38.864715</td>\n",
       "      <td>15.373564</td>\n",
       "      <td>0.016988</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.008453</td>\n",
       "      <td>0.008099</td>\n",
       "      <td>0.060868</td>\n",
       "      <td>0.629243</td>\n",
       "      <td>0.023691</td>\n",
       "      <td>0.028934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>182.554190</td>\n",
       "      <td>44.447825</td>\n",
       "      <td>15.092618</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.009226</td>\n",
       "      <td>0.009401</td>\n",
       "      <td>0.092794</td>\n",
       "      <td>0.876801</td>\n",
       "      <td>0.040549</td>\n",
       "      <td>0.051243</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>137.759284</td>\n",
       "      <td>24.790170</td>\n",
       "      <td>11.083001</td>\n",
       "      <td>0.028160</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.011123</td>\n",
       "      <td>0.013622</td>\n",
       "      <td>0.120958</td>\n",
       "      <td>1.129300</td>\n",
       "      <td>0.046355</td>\n",
       "      <td>0.066205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>123.414244</td>\n",
       "      <td>22.752103</td>\n",
       "      <td>12.358663</td>\n",
       "      <td>0.021337</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.008034</td>\n",
       "      <td>0.009556</td>\n",
       "      <td>0.105540</td>\n",
       "      <td>1.004045</td>\n",
       "      <td>0.040983</td>\n",
       "      <td>0.061719</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>116.991841</td>\n",
       "      <td>58.387577</td>\n",
       "      <td>10.195438</td>\n",
       "      <td>0.038871</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.016799</td>\n",
       "      <td>0.017930</td>\n",
       "      <td>0.127226</td>\n",
       "      <td>1.246093</td>\n",
       "      <td>0.048545</td>\n",
       "      <td>0.071562</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>122.961628</td>\n",
       "      <td>22.484201</td>\n",
       "      <td>12.783982</td>\n",
       "      <td>0.027902</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.012136</td>\n",
       "      <td>0.012880</td>\n",
       "      <td>0.096135</td>\n",
       "      <td>0.972089</td>\n",
       "      <td>0.035746</td>\n",
       "      <td>0.051311</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>139.689970</td>\n",
       "      <td>46.669739</td>\n",
       "      <td>12.332291</td>\n",
       "      <td>0.025015</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.010713</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.121463</td>\n",
       "      <td>1.164322</td>\n",
       "      <td>0.046843</td>\n",
       "      <td>0.076398</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>173.221371</td>\n",
       "      <td>81.862069</td>\n",
       "      <td>11.459649</td>\n",
       "      <td>0.031018</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.015509</td>\n",
       "      <td>0.014327</td>\n",
       "      <td>0.179428</td>\n",
       "      <td>1.531849</td>\n",
       "      <td>0.070886</td>\n",
       "      <td>0.103642</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>210.237178</td>\n",
       "      <td>39.254275</td>\n",
       "      <td>15.979671</td>\n",
       "      <td>0.017851</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.007177</td>\n",
       "      <td>0.008796</td>\n",
       "      <td>0.082826</td>\n",
       "      <td>0.851598</td>\n",
       "      <td>0.026117</td>\n",
       "      <td>0.041526</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>186.919188</td>\n",
       "      <td>43.036125</td>\n",
       "      <td>13.900163</td>\n",
       "      <td>0.021485</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.009976</td>\n",
       "      <td>0.011644</td>\n",
       "      <td>0.095878</td>\n",
       "      <td>1.032631</td>\n",
       "      <td>0.037534</td>\n",
       "      <td>0.055410</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>140.327577</td>\n",
       "      <td>48.573694</td>\n",
       "      <td>15.970827</td>\n",
       "      <td>0.030689</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.014995</td>\n",
       "      <td>0.014764</td>\n",
       "      <td>0.111399</td>\n",
       "      <td>1.092409</td>\n",
       "      <td>0.052731</td>\n",
       "      <td>0.065043</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>131.225704</td>\n",
       "      <td>23.870219</td>\n",
       "      <td>14.041177</td>\n",
       "      <td>0.024799</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.008344</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>0.104867</td>\n",
       "      <td>1.005431</td>\n",
       "      <td>0.036322</td>\n",
       "      <td>0.055991</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>127.417091</td>\n",
       "      <td>15.856715</td>\n",
       "      <td>14.583647</td>\n",
       "      <td>0.024052</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.009932</td>\n",
       "      <td>0.010440</td>\n",
       "      <td>0.101346</td>\n",
       "      <td>0.977365</td>\n",
       "      <td>0.038380</td>\n",
       "      <td>0.053780</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>99.176942</td>\n",
       "      <td>25.396425</td>\n",
       "      <td>13.423922</td>\n",
       "      <td>0.029025</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.013478</td>\n",
       "      <td>0.075952</td>\n",
       "      <td>0.787862</td>\n",
       "      <td>0.024354</td>\n",
       "      <td>0.038861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>133.525246</td>\n",
       "      <td>56.374227</td>\n",
       "      <td>14.355616</td>\n",
       "      <td>0.031816</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.014556</td>\n",
       "      <td>0.015936</td>\n",
       "      <td>0.096488</td>\n",
       "      <td>0.993070</td>\n",
       "      <td>0.038624</td>\n",
       "      <td>0.049436</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>213.746231</td>\n",
       "      <td>45.818006</td>\n",
       "      <td>14.262968</td>\n",
       "      <td>0.020147</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.008710</td>\n",
       "      <td>0.009108</td>\n",
       "      <td>0.071151</td>\n",
       "      <td>0.752922</td>\n",
       "      <td>0.023605</td>\n",
       "      <td>0.034078</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>166.779713</td>\n",
       "      <td>30.941409</td>\n",
       "      <td>11.148522</td>\n",
       "      <td>0.025417</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.013308</td>\n",
       "      <td>0.012758</td>\n",
       "      <td>0.107019</td>\n",
       "      <td>1.000508</td>\n",
       "      <td>0.049595</td>\n",
       "      <td>0.057682</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>185.734636</td>\n",
       "      <td>36.970632</td>\n",
       "      <td>16.854876</td>\n",
       "      <td>0.020856</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.009839</td>\n",
       "      <td>0.010539</td>\n",
       "      <td>0.098915</td>\n",
       "      <td>1.047622</td>\n",
       "      <td>0.039979</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>185.303514</td>\n",
       "      <td>52.677109</td>\n",
       "      <td>14.082311</td>\n",
       "      <td>0.021292</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.010419</td>\n",
       "      <td>0.009892</td>\n",
       "      <td>0.089151</td>\n",
       "      <td>0.877028</td>\n",
       "      <td>0.033184</td>\n",
       "      <td>0.042282</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      meanF0Hz  stdevF0Hz        HNR  localJitter  localabsoluteJitter  \\\n",
       "0   180.433976  51.653057  13.292053     0.027039             0.000151   \n",
       "1   190.751972  34.887596  11.243993     0.016118             0.000085   \n",
       "2   124.477366  26.621493  13.423983     0.026740             0.000216   \n",
       "3   182.557207  39.933612  12.235210     0.020701             0.000114   \n",
       "4   195.969796  41.446983  14.669165     0.015063             0.000077   \n",
       "5   168.012461  35.493510  13.020618     0.021790             0.000130   \n",
       "6   203.130952  48.609299  12.333993     0.027164             0.000134   \n",
       "7   197.503773  36.631657  15.683277     0.017656             0.000090   \n",
       "8   199.081279  41.081947  11.784297     0.024917             0.000125   \n",
       "9   157.113264  46.419171  13.388906     0.034113             0.000217   \n",
       "10  163.844699  54.076942  11.548012     0.018828             0.000115   \n",
       "11  154.205413  42.577809  11.369774     0.029419             0.000192   \n",
       "12  160.093999  31.936264  12.994633     0.018726             0.000117   \n",
       "13  173.417455  34.365179  14.193625     0.022659             0.000131   \n",
       "14  179.048747  35.403221  16.224981     0.013899             0.000078   \n",
       "15  197.330931  39.729669  15.950713     0.016124             0.000082   \n",
       "16  183.050353  46.792915  13.081668     0.024480             0.000134   \n",
       "17  194.704118  54.785527  13.076819     0.021499             0.000111   \n",
       "18  214.216909  38.864715  15.373564     0.016988             0.000079   \n",
       "19  182.554190  44.447825  15.092618     0.019678             0.000108   \n",
       "20  137.759284  24.790170  11.083001     0.028160             0.000205   \n",
       "21  123.414244  22.752103  12.358663     0.021337             0.000173   \n",
       "22  116.991841  58.387577  10.195438     0.038871             0.000332   \n",
       "23  122.961628  22.484201  12.783982     0.027902             0.000227   \n",
       "24  139.689970  46.669739  12.332291     0.025015             0.000179   \n",
       "25  173.221371  81.862069  11.459649     0.031018             0.000185   \n",
       "26  210.237178  39.254275  15.979671     0.017851             0.000085   \n",
       "27  186.919188  43.036125  13.900163     0.021485             0.000115   \n",
       "28  140.327577  48.573694  15.970827     0.030689             0.000219   \n",
       "29  131.225704  23.870219  14.041177     0.024799             0.000189   \n",
       "30  127.417091  15.856715  14.583647     0.024052             0.000189   \n",
       "31   99.176942  25.396425  13.423922     0.029025             0.000295   \n",
       "32  133.525246  56.374227  14.355616     0.031816             0.000241   \n",
       "33  213.746231  45.818006  14.262968     0.020147             0.000094   \n",
       "34  166.779713  30.941409  11.148522     0.025417             0.000153   \n",
       "35  185.734636  36.970632  16.854876     0.020856             0.000112   \n",
       "36  185.303514  52.677109  14.082311     0.021292             0.000115   \n",
       "\n",
       "    rapJitter  ppq5Jitter  localShimmer  localdbShimmer  apq3Shimmer  \\\n",
       "0    0.012019    0.013197      0.113439        1.124025     0.046161   \n",
       "1    0.006764    0.007168      0.079053        0.740666     0.029396   \n",
       "2    0.010862    0.011512      0.102565        0.974095     0.039042   \n",
       "3    0.008979    0.008983      0.080388        0.811653     0.025759   \n",
       "4    0.005371    0.006017      0.082016        0.827343     0.029087   \n",
       "5    0.009273    0.009862      0.078274        0.786047     0.024992   \n",
       "6    0.012624    0.013001      0.102844        0.994058     0.039932   \n",
       "7    0.007171    0.007674      0.078181        0.757354     0.029970   \n",
       "8    0.011396    0.011915      0.096619        0.963974     0.033895   \n",
       "9    0.017499    0.016585      0.119624        1.104118     0.053728   \n",
       "10   0.007439    0.009032      0.105805        0.993686     0.038722   \n",
       "11   0.013191    0.012156      0.089834        0.912168     0.033115   \n",
       "12   0.007586    0.008082      0.080560        0.774723     0.029102   \n",
       "13   0.009854    0.010656      0.090751        0.878991     0.031667   \n",
       "14   0.005279    0.005674      0.072685        0.730909     0.027094   \n",
       "15   0.005896    0.006771      0.085010        0.810418     0.029995   \n",
       "16   0.010880    0.010480      0.079695        0.767308     0.030681   \n",
       "17   0.009724    0.009703      0.086963        0.876711     0.032313   \n",
       "18   0.008453    0.008099      0.060868        0.629243     0.023691   \n",
       "19   0.009226    0.009401      0.092794        0.876801     0.040549   \n",
       "20   0.011123    0.013622      0.120958        1.129300     0.046355   \n",
       "21   0.008034    0.009556      0.105540        1.004045     0.040983   \n",
       "22   0.016799    0.017930      0.127226        1.246093     0.048545   \n",
       "23   0.012136    0.012880      0.096135        0.972089     0.035746   \n",
       "24   0.010713    0.013500      0.121463        1.164322     0.046843   \n",
       "25   0.015509    0.014327      0.179428        1.531849     0.070886   \n",
       "26   0.007177    0.008796      0.082826        0.851598     0.026117   \n",
       "27   0.009976    0.011644      0.095878        1.032631     0.037534   \n",
       "28   0.014995    0.014764      0.111399        1.092409     0.052731   \n",
       "29   0.008344    0.010311      0.104867        1.005431     0.036322   \n",
       "30   0.009932    0.010440      0.101346        0.977365     0.038380   \n",
       "31   0.009110    0.013478      0.075952        0.787862     0.024354   \n",
       "32   0.014556    0.015936      0.096488        0.993070     0.038624   \n",
       "33   0.008710    0.009108      0.071151        0.752922     0.023605   \n",
       "34   0.013308    0.012758      0.107019        1.000508     0.049595   \n",
       "35   0.009839    0.010539      0.098915        1.047622     0.039979   \n",
       "36   0.010419    0.009892      0.089151        0.877028     0.033184   \n",
       "\n",
       "    apq5Shimmer  label  \n",
       "0      0.067371      0  \n",
       "1      0.038308      0  \n",
       "2      0.058131      0  \n",
       "3      0.037847      0  \n",
       "4      0.043951      0  \n",
       "5      0.039414      0  \n",
       "6      0.053414      0  \n",
       "7      0.039306      0  \n",
       "8      0.049371      0  \n",
       "9      0.058976      0  \n",
       "10     0.060542      0  \n",
       "11     0.046434      0  \n",
       "12     0.040420      0  \n",
       "13     0.046121      0  \n",
       "14     0.038795      0  \n",
       "15     0.044046      0  \n",
       "16     0.039645      0  \n",
       "17     0.044567      0  \n",
       "18     0.028934      0  \n",
       "19     0.051243      0  \n",
       "20     0.066205      0  \n",
       "21     0.061719      1  \n",
       "22     0.071562      1  \n",
       "23     0.051311      1  \n",
       "24     0.076398      1  \n",
       "25     0.103642      1  \n",
       "26     0.041526      1  \n",
       "27     0.055410      1  \n",
       "28     0.065043      1  \n",
       "29     0.055991      1  \n",
       "30     0.053780      1  \n",
       "31     0.038861      1  \n",
       "32     0.049436      1  \n",
       "33     0.034078      1  \n",
       "34     0.057682      1  \n",
       "35     0.052948      1  \n",
       "36     0.042282      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./readtext.csv\")\n",
    "#df = shuffle(df)\n",
    "#df.reset_index(inplace=True, drop=True)\n",
    "df.drop('voiceID', inplace = True, axis = 1)\n",
    "df['label'].value_counts()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>185.303514</td>\n",
       "      <td>52.677109</td>\n",
       "      <td>14.082311</td>\n",
       "      <td>0.021292</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.010419</td>\n",
       "      <td>0.009892</td>\n",
       "      <td>0.089151</td>\n",
       "      <td>0.877028</td>\n",
       "      <td>0.033184</td>\n",
       "      <td>0.042282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>166.779713</td>\n",
       "      <td>30.941409</td>\n",
       "      <td>11.148522</td>\n",
       "      <td>0.025417</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.013308</td>\n",
       "      <td>0.012758</td>\n",
       "      <td>0.107019</td>\n",
       "      <td>1.000508</td>\n",
       "      <td>0.049595</td>\n",
       "      <td>0.057682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>131.225704</td>\n",
       "      <td>23.870219</td>\n",
       "      <td>14.041177</td>\n",
       "      <td>0.024799</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.008344</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>0.104867</td>\n",
       "      <td>1.005431</td>\n",
       "      <td>0.036322</td>\n",
       "      <td>0.055991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>213.746231</td>\n",
       "      <td>45.818006</td>\n",
       "      <td>14.262968</td>\n",
       "      <td>0.020147</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.008710</td>\n",
       "      <td>0.009108</td>\n",
       "      <td>0.071151</td>\n",
       "      <td>0.752922</td>\n",
       "      <td>0.023605</td>\n",
       "      <td>0.034078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>199.081279</td>\n",
       "      <td>41.081947</td>\n",
       "      <td>11.784297</td>\n",
       "      <td>0.024917</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.011396</td>\n",
       "      <td>0.011915</td>\n",
       "      <td>0.096619</td>\n",
       "      <td>0.963974</td>\n",
       "      <td>0.033895</td>\n",
       "      <td>0.049371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>173.417455</td>\n",
       "      <td>34.365179</td>\n",
       "      <td>14.193625</td>\n",
       "      <td>0.022659</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.009854</td>\n",
       "      <td>0.010656</td>\n",
       "      <td>0.090751</td>\n",
       "      <td>0.878991</td>\n",
       "      <td>0.031667</td>\n",
       "      <td>0.046121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>168.012461</td>\n",
       "      <td>35.493510</td>\n",
       "      <td>13.020618</td>\n",
       "      <td>0.021790</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.009273</td>\n",
       "      <td>0.009862</td>\n",
       "      <td>0.078274</td>\n",
       "      <td>0.786047</td>\n",
       "      <td>0.024992</td>\n",
       "      <td>0.039414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>194.704118</td>\n",
       "      <td>54.785527</td>\n",
       "      <td>13.076819</td>\n",
       "      <td>0.021499</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.009724</td>\n",
       "      <td>0.009703</td>\n",
       "      <td>0.086963</td>\n",
       "      <td>0.876711</td>\n",
       "      <td>0.032313</td>\n",
       "      <td>0.044567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>179.048747</td>\n",
       "      <td>35.403221</td>\n",
       "      <td>16.224981</td>\n",
       "      <td>0.013899</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.005279</td>\n",
       "      <td>0.005674</td>\n",
       "      <td>0.072685</td>\n",
       "      <td>0.730909</td>\n",
       "      <td>0.027094</td>\n",
       "      <td>0.038795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>197.503773</td>\n",
       "      <td>36.631657</td>\n",
       "      <td>15.683277</td>\n",
       "      <td>0.017656</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.007171</td>\n",
       "      <td>0.007674</td>\n",
       "      <td>0.078181</td>\n",
       "      <td>0.757354</td>\n",
       "      <td>0.029970</td>\n",
       "      <td>0.039306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>186.919188</td>\n",
       "      <td>43.036125</td>\n",
       "      <td>13.900163</td>\n",
       "      <td>0.021485</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.009976</td>\n",
       "      <td>0.011644</td>\n",
       "      <td>0.095878</td>\n",
       "      <td>1.032631</td>\n",
       "      <td>0.037534</td>\n",
       "      <td>0.055410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>190.751972</td>\n",
       "      <td>34.887596</td>\n",
       "      <td>11.243993</td>\n",
       "      <td>0.016118</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.006764</td>\n",
       "      <td>0.007168</td>\n",
       "      <td>0.079053</td>\n",
       "      <td>0.740666</td>\n",
       "      <td>0.029396</td>\n",
       "      <td>0.038308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>160.093999</td>\n",
       "      <td>31.936264</td>\n",
       "      <td>12.994633</td>\n",
       "      <td>0.018726</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.007586</td>\n",
       "      <td>0.008082</td>\n",
       "      <td>0.080560</td>\n",
       "      <td>0.774723</td>\n",
       "      <td>0.029102</td>\n",
       "      <td>0.040420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>210.237178</td>\n",
       "      <td>39.254275</td>\n",
       "      <td>15.979671</td>\n",
       "      <td>0.017851</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.007177</td>\n",
       "      <td>0.008796</td>\n",
       "      <td>0.082826</td>\n",
       "      <td>0.851598</td>\n",
       "      <td>0.026117</td>\n",
       "      <td>0.041526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>139.689970</td>\n",
       "      <td>46.669739</td>\n",
       "      <td>12.332291</td>\n",
       "      <td>0.025015</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.010713</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.121463</td>\n",
       "      <td>1.164322</td>\n",
       "      <td>0.046843</td>\n",
       "      <td>0.076398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>203.130952</td>\n",
       "      <td>48.609299</td>\n",
       "      <td>12.333993</td>\n",
       "      <td>0.027164</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.012624</td>\n",
       "      <td>0.013001</td>\n",
       "      <td>0.102844</td>\n",
       "      <td>0.994058</td>\n",
       "      <td>0.039932</td>\n",
       "      <td>0.053414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>122.961628</td>\n",
       "      <td>22.484201</td>\n",
       "      <td>12.783982</td>\n",
       "      <td>0.027902</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.012136</td>\n",
       "      <td>0.012880</td>\n",
       "      <td>0.096135</td>\n",
       "      <td>0.972089</td>\n",
       "      <td>0.035746</td>\n",
       "      <td>0.051311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>195.969796</td>\n",
       "      <td>41.446983</td>\n",
       "      <td>14.669165</td>\n",
       "      <td>0.015063</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.005371</td>\n",
       "      <td>0.006017</td>\n",
       "      <td>0.082016</td>\n",
       "      <td>0.827343</td>\n",
       "      <td>0.029087</td>\n",
       "      <td>0.043951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>214.216909</td>\n",
       "      <td>38.864715</td>\n",
       "      <td>15.373564</td>\n",
       "      <td>0.016988</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.008453</td>\n",
       "      <td>0.008099</td>\n",
       "      <td>0.060868</td>\n",
       "      <td>0.629243</td>\n",
       "      <td>0.023691</td>\n",
       "      <td>0.028934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>123.414244</td>\n",
       "      <td>22.752103</td>\n",
       "      <td>12.358663</td>\n",
       "      <td>0.021337</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.008034</td>\n",
       "      <td>0.009556</td>\n",
       "      <td>0.105540</td>\n",
       "      <td>1.004045</td>\n",
       "      <td>0.040983</td>\n",
       "      <td>0.061719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>182.554190</td>\n",
       "      <td>44.447825</td>\n",
       "      <td>15.092618</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.009226</td>\n",
       "      <td>0.009401</td>\n",
       "      <td>0.092794</td>\n",
       "      <td>0.876801</td>\n",
       "      <td>0.040549</td>\n",
       "      <td>0.051243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>157.113264</td>\n",
       "      <td>46.419171</td>\n",
       "      <td>13.388906</td>\n",
       "      <td>0.034113</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.017499</td>\n",
       "      <td>0.016585</td>\n",
       "      <td>0.119624</td>\n",
       "      <td>1.104118</td>\n",
       "      <td>0.053728</td>\n",
       "      <td>0.058976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>185.734636</td>\n",
       "      <td>36.970632</td>\n",
       "      <td>16.854876</td>\n",
       "      <td>0.020856</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.009839</td>\n",
       "      <td>0.010539</td>\n",
       "      <td>0.098915</td>\n",
       "      <td>1.047622</td>\n",
       "      <td>0.039979</td>\n",
       "      <td>0.052948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>182.557207</td>\n",
       "      <td>39.933612</td>\n",
       "      <td>12.235210</td>\n",
       "      <td>0.020701</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.008979</td>\n",
       "      <td>0.008983</td>\n",
       "      <td>0.080388</td>\n",
       "      <td>0.811653</td>\n",
       "      <td>0.025759</td>\n",
       "      <td>0.037847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>180.433976</td>\n",
       "      <td>51.653057</td>\n",
       "      <td>13.292053</td>\n",
       "      <td>0.027039</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.012019</td>\n",
       "      <td>0.013197</td>\n",
       "      <td>0.113439</td>\n",
       "      <td>1.124025</td>\n",
       "      <td>0.046161</td>\n",
       "      <td>0.067371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1          2         3         4         5         6  \\\n",
       "0   185.303514  52.677109  14.082311  0.021292  0.000115  0.010419  0.009892   \n",
       "1   166.779713  30.941409  11.148522  0.025417  0.000153  0.013308  0.012758   \n",
       "2   131.225704  23.870219  14.041177  0.024799  0.000189  0.008344  0.010311   \n",
       "3   213.746231  45.818006  14.262968  0.020147  0.000094  0.008710  0.009108   \n",
       "4   199.081279  41.081947  11.784297  0.024917  0.000125  0.011396  0.011915   \n",
       "5   173.417455  34.365179  14.193625  0.022659  0.000131  0.009854  0.010656   \n",
       "6   168.012461  35.493510  13.020618  0.021790  0.000130  0.009273  0.009862   \n",
       "7   194.704118  54.785527  13.076819  0.021499  0.000111  0.009724  0.009703   \n",
       "8   179.048747  35.403221  16.224981  0.013899  0.000078  0.005279  0.005674   \n",
       "9   197.503773  36.631657  15.683277  0.017656  0.000090  0.007171  0.007674   \n",
       "10  186.919188  43.036125  13.900163  0.021485  0.000115  0.009976  0.011644   \n",
       "11  190.751972  34.887596  11.243993  0.016118  0.000085  0.006764  0.007168   \n",
       "12  160.093999  31.936264  12.994633  0.018726  0.000117  0.007586  0.008082   \n",
       "13  210.237178  39.254275  15.979671  0.017851  0.000085  0.007177  0.008796   \n",
       "14  139.689970  46.669739  12.332291  0.025015  0.000179  0.010713  0.013500   \n",
       "15  203.130952  48.609299  12.333993  0.027164  0.000134  0.012624  0.013001   \n",
       "16  122.961628  22.484201  12.783982  0.027902  0.000227  0.012136  0.012880   \n",
       "17  195.969796  41.446983  14.669165  0.015063  0.000077  0.005371  0.006017   \n",
       "18  214.216909  38.864715  15.373564  0.016988  0.000079  0.008453  0.008099   \n",
       "19  123.414244  22.752103  12.358663  0.021337  0.000173  0.008034  0.009556   \n",
       "20  182.554190  44.447825  15.092618  0.019678  0.000108  0.009226  0.009401   \n",
       "21  157.113264  46.419171  13.388906  0.034113  0.000217  0.017499  0.016585   \n",
       "22  185.734636  36.970632  16.854876  0.020856  0.000112  0.009839  0.010539   \n",
       "23  182.557207  39.933612  12.235210  0.020701  0.000114  0.008979  0.008983   \n",
       "24  180.433976  51.653057  13.292053  0.027039  0.000151  0.012019  0.013197   \n",
       "\n",
       "           7         8         9        10  \n",
       "0   0.089151  0.877028  0.033184  0.042282  \n",
       "1   0.107019  1.000508  0.049595  0.057682  \n",
       "2   0.104867  1.005431  0.036322  0.055991  \n",
       "3   0.071151  0.752922  0.023605  0.034078  \n",
       "4   0.096619  0.963974  0.033895  0.049371  \n",
       "5   0.090751  0.878991  0.031667  0.046121  \n",
       "6   0.078274  0.786047  0.024992  0.039414  \n",
       "7   0.086963  0.876711  0.032313  0.044567  \n",
       "8   0.072685  0.730909  0.027094  0.038795  \n",
       "9   0.078181  0.757354  0.029970  0.039306  \n",
       "10  0.095878  1.032631  0.037534  0.055410  \n",
       "11  0.079053  0.740666  0.029396  0.038308  \n",
       "12  0.080560  0.774723  0.029102  0.040420  \n",
       "13  0.082826  0.851598  0.026117  0.041526  \n",
       "14  0.121463  1.164322  0.046843  0.076398  \n",
       "15  0.102844  0.994058  0.039932  0.053414  \n",
       "16  0.096135  0.972089  0.035746  0.051311  \n",
       "17  0.082016  0.827343  0.029087  0.043951  \n",
       "18  0.060868  0.629243  0.023691  0.028934  \n",
       "19  0.105540  1.004045  0.040983  0.061719  \n",
       "20  0.092794  0.876801  0.040549  0.051243  \n",
       "21  0.119624  1.104118  0.053728  0.058976  \n",
       "22  0.098915  1.047622  0.039979  0.052948  \n",
       "23  0.080388  0.811653  0.025759  0.037847  \n",
       "24  0.113439  1.124025  0.046161  0.067371  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#separate dependent and independent variable\n",
    "X = df.iloc[:, :-1]\n",
    "df_X = df.iloc[:, :-1].values\n",
    "df_Y = df.iloc[:,-1].values\n",
    "\n",
    "# Split the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_Y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "pd.DataFrame(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.683159</td>\n",
       "      <td>0.934727</td>\n",
       "      <td>0.514127</td>\n",
       "      <td>0.365714</td>\n",
       "      <td>0.252388</td>\n",
       "      <td>0.420615</td>\n",
       "      <td>0.386582</td>\n",
       "      <td>0.466749</td>\n",
       "      <td>0.463082</td>\n",
       "      <td>0.318015</td>\n",
       "      <td>0.281224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.480170</td>\n",
       "      <td>0.261822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.569791</td>\n",
       "      <td>0.502888</td>\n",
       "      <td>0.657009</td>\n",
       "      <td>0.649233</td>\n",
       "      <td>0.761632</td>\n",
       "      <td>0.693850</td>\n",
       "      <td>0.862800</td>\n",
       "      <td>0.605668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.090560</td>\n",
       "      <td>0.042909</td>\n",
       "      <td>0.506918</td>\n",
       "      <td>0.539225</td>\n",
       "      <td>0.746808</td>\n",
       "      <td>0.250842</td>\n",
       "      <td>0.425005</td>\n",
       "      <td>0.726118</td>\n",
       "      <td>0.703052</td>\n",
       "      <td>0.422196</td>\n",
       "      <td>0.570045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.994842</td>\n",
       "      <td>0.722379</td>\n",
       "      <td>0.545786</td>\n",
       "      <td>0.309113</td>\n",
       "      <td>0.114155</td>\n",
       "      <td>0.280805</td>\n",
       "      <td>0.314770</td>\n",
       "      <td>0.169704</td>\n",
       "      <td>0.231142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.834140</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.111415</td>\n",
       "      <td>0.545052</td>\n",
       "      <td>0.320417</td>\n",
       "      <td>0.500617</td>\n",
       "      <td>0.571964</td>\n",
       "      <td>0.589996</td>\n",
       "      <td>0.625574</td>\n",
       "      <td>0.341612</td>\n",
       "      <td>0.430574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.552909</td>\n",
       "      <td>0.367817</td>\n",
       "      <td>0.533634</td>\n",
       "      <td>0.433380</td>\n",
       "      <td>0.359524</td>\n",
       "      <td>0.374398</td>\n",
       "      <td>0.456565</td>\n",
       "      <td>0.493161</td>\n",
       "      <td>0.466750</td>\n",
       "      <td>0.267652</td>\n",
       "      <td>0.362105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.493679</td>\n",
       "      <td>0.402748</td>\n",
       "      <td>0.328072</td>\n",
       "      <td>0.390382</td>\n",
       "      <td>0.350274</td>\n",
       "      <td>0.326849</td>\n",
       "      <td>0.383806</td>\n",
       "      <td>0.287253</td>\n",
       "      <td>0.293049</td>\n",
       "      <td>0.046075</td>\n",
       "      <td>0.220798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.786174</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.337921</td>\n",
       "      <td>0.375990</td>\n",
       "      <td>0.222888</td>\n",
       "      <td>0.363734</td>\n",
       "      <td>0.369304</td>\n",
       "      <td>0.430656</td>\n",
       "      <td>0.462488</td>\n",
       "      <td>0.289103</td>\n",
       "      <td>0.329359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.614618</td>\n",
       "      <td>0.399953</td>\n",
       "      <td>0.889615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.195013</td>\n",
       "      <td>0.190002</td>\n",
       "      <td>0.115829</td>\n",
       "      <td>0.207765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.816853</td>\n",
       "      <td>0.437984</td>\n",
       "      <td>0.794685</td>\n",
       "      <td>0.185842</td>\n",
       "      <td>0.083057</td>\n",
       "      <td>0.154837</td>\n",
       "      <td>0.183334</td>\n",
       "      <td>0.285719</td>\n",
       "      <td>0.239425</td>\n",
       "      <td>0.211324</td>\n",
       "      <td>0.218521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.700864</td>\n",
       "      <td>0.636256</td>\n",
       "      <td>0.482207</td>\n",
       "      <td>0.375300</td>\n",
       "      <td>0.252123</td>\n",
       "      <td>0.384398</td>\n",
       "      <td>0.547164</td>\n",
       "      <td>0.577768</td>\n",
       "      <td>0.753885</td>\n",
       "      <td>0.462431</td>\n",
       "      <td>0.557817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.742865</td>\n",
       "      <td>0.383990</td>\n",
       "      <td>0.016731</td>\n",
       "      <td>0.109800</td>\n",
       "      <td>0.049823</td>\n",
       "      <td>0.121526</td>\n",
       "      <td>0.136899</td>\n",
       "      <td>0.300104</td>\n",
       "      <td>0.208236</td>\n",
       "      <td>0.192255</td>\n",
       "      <td>0.197484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.406907</td>\n",
       "      <td>0.292622</td>\n",
       "      <td>0.323518</td>\n",
       "      <td>0.238807</td>\n",
       "      <td>0.267768</td>\n",
       "      <td>0.188812</td>\n",
       "      <td>0.220659</td>\n",
       "      <td>0.324978</td>\n",
       "      <td>0.271886</td>\n",
       "      <td>0.182494</td>\n",
       "      <td>0.241995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.956389</td>\n",
       "      <td>0.519176</td>\n",
       "      <td>0.846626</td>\n",
       "      <td>0.195491</td>\n",
       "      <td>0.053206</td>\n",
       "      <td>0.155377</td>\n",
       "      <td>0.286094</td>\n",
       "      <td>0.362372</td>\n",
       "      <td>0.415555</td>\n",
       "      <td>0.083407</td>\n",
       "      <td>0.265298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.183314</td>\n",
       "      <td>0.748748</td>\n",
       "      <td>0.207447</td>\n",
       "      <td>0.549912</td>\n",
       "      <td>0.678122</td>\n",
       "      <td>0.444735</td>\n",
       "      <td>0.717190</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.771460</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.878517</td>\n",
       "      <td>0.808793</td>\n",
       "      <td>0.207746</td>\n",
       "      <td>0.656238</td>\n",
       "      <td>0.375828</td>\n",
       "      <td>0.601039</td>\n",
       "      <td>0.671499</td>\n",
       "      <td>0.692733</td>\n",
       "      <td>0.681796</td>\n",
       "      <td>0.542009</td>\n",
       "      <td>0.515748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.286603</td>\n",
       "      <td>0.692708</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.561147</td>\n",
       "      <td>0.660458</td>\n",
       "      <td>0.582011</td>\n",
       "      <td>0.640740</td>\n",
       "      <td>0.403060</td>\n",
       "      <td>0.471447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.800043</td>\n",
       "      <td>0.587059</td>\n",
       "      <td>0.616969</td>\n",
       "      <td>0.057579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007527</td>\n",
       "      <td>0.031460</td>\n",
       "      <td>0.349004</td>\n",
       "      <td>0.370225</td>\n",
       "      <td>0.181998</td>\n",
       "      <td>0.316385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.507116</td>\n",
       "      <td>0.740410</td>\n",
       "      <td>0.152838</td>\n",
       "      <td>0.014238</td>\n",
       "      <td>0.259766</td>\n",
       "      <td>0.222270</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.004960</td>\n",
       "      <td>0.008294</td>\n",
       "      <td>0.212069</td>\n",
       "      <td>0.367974</td>\n",
       "      <td>0.640116</td>\n",
       "      <td>0.225463</td>\n",
       "      <td>0.355771</td>\n",
       "      <td>0.737220</td>\n",
       "      <td>0.700462</td>\n",
       "      <td>0.576919</td>\n",
       "      <td>0.690740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.653031</td>\n",
       "      <td>0.679960</td>\n",
       "      <td>0.691176</td>\n",
       "      <td>0.285881</td>\n",
       "      <td>0.203509</td>\n",
       "      <td>0.322988</td>\n",
       "      <td>0.341569</td>\n",
       "      <td>0.526876</td>\n",
       "      <td>0.462657</td>\n",
       "      <td>0.562512</td>\n",
       "      <td>0.470020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.374243</td>\n",
       "      <td>0.740990</td>\n",
       "      <td>0.392612</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.930363</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969657</td>\n",
       "      <td>0.887486</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.632931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.687884</td>\n",
       "      <td>0.448478</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.344184</td>\n",
       "      <td>0.233918</td>\n",
       "      <td>0.373195</td>\n",
       "      <td>0.445853</td>\n",
       "      <td>0.627894</td>\n",
       "      <td>0.781902</td>\n",
       "      <td>0.543576</td>\n",
       "      <td>0.505942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.653064</td>\n",
       "      <td>0.540207</td>\n",
       "      <td>0.190435</td>\n",
       "      <td>0.336495</td>\n",
       "      <td>0.243318</td>\n",
       "      <td>0.302831</td>\n",
       "      <td>0.303238</td>\n",
       "      <td>0.322142</td>\n",
       "      <td>0.340903</td>\n",
       "      <td>0.071511</td>\n",
       "      <td>0.187788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.629798</td>\n",
       "      <td>0.903023</td>\n",
       "      <td>0.375639</td>\n",
       "      <td>0.650029</td>\n",
       "      <td>0.490687</td>\n",
       "      <td>0.551607</td>\n",
       "      <td>0.689425</td>\n",
       "      <td>0.867586</td>\n",
       "      <td>0.924690</td>\n",
       "      <td>0.748823</td>\n",
       "      <td>0.809812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0   0.683159  0.934727  0.514127  0.365714  0.252388  0.420615  0.386582   \n",
       "1   0.480170  0.261822  0.000000  0.569791  0.502888  0.657009  0.649233   \n",
       "2   0.090560  0.042909  0.506918  0.539225  0.746808  0.250842  0.425005   \n",
       "3   0.994842  0.722379  0.545786  0.309113  0.114155  0.280805  0.314770   \n",
       "4   0.834140  0.575758  0.111415  0.545052  0.320417  0.500617  0.571964   \n",
       "5   0.552909  0.367817  0.533634  0.433380  0.359524  0.374398  0.456565   \n",
       "6   0.493679  0.402748  0.328072  0.390382  0.350274  0.326849  0.383806   \n",
       "7   0.786174  1.000000  0.337921  0.375990  0.222888  0.363734  0.369304   \n",
       "8   0.614618  0.399953  0.889615  0.000000  0.004697  0.000000  0.000000   \n",
       "9   0.816853  0.437984  0.794685  0.185842  0.083057  0.154837  0.183334   \n",
       "10  0.700864  0.636256  0.482207  0.375300  0.252123  0.384398  0.547164   \n",
       "11  0.742865  0.383990  0.016731  0.109800  0.049823  0.121526  0.136899   \n",
       "12  0.406907  0.292622  0.323518  0.238807  0.267768  0.188812  0.220659   \n",
       "13  0.956389  0.519176  0.846626  0.195491  0.053206  0.155377  0.286094   \n",
       "14  0.183314  0.748748  0.207447  0.549912  0.678122  0.444735  0.717190   \n",
       "15  0.878517  0.808793  0.207746  0.656238  0.375828  0.601039  0.671499   \n",
       "16  0.000000  0.000000  0.286603  0.692708  1.000000  0.561147  0.660458   \n",
       "17  0.800043  0.587059  0.616969  0.057579  0.000000  0.007527  0.031460   \n",
       "18  1.000000  0.507116  0.740410  0.152838  0.014238  0.259766  0.222270   \n",
       "19  0.004960  0.008294  0.212069  0.367974  0.640116  0.225463  0.355771   \n",
       "20  0.653031  0.679960  0.691176  0.285881  0.203509  0.322988  0.341569   \n",
       "21  0.374243  0.740990  0.392612  1.000000  0.930363  1.000000  1.000000   \n",
       "22  0.687884  0.448478  1.000000  0.344184  0.233918  0.373195  0.445853   \n",
       "23  0.653064  0.540207  0.190435  0.336495  0.243318  0.302831  0.303238   \n",
       "24  0.629798  0.903023  0.375639  0.650029  0.490687  0.551607  0.689425   \n",
       "\n",
       "           7         8         9        10  \n",
       "0   0.466749  0.463082  0.318015  0.281224  \n",
       "1   0.761632  0.693850  0.862800  0.605668  \n",
       "2   0.726118  0.703052  0.422196  0.570045  \n",
       "3   0.169704  0.231142  0.000000  0.108383  \n",
       "4   0.589996  0.625574  0.341612  0.430574  \n",
       "5   0.493161  0.466750  0.267652  0.362105  \n",
       "6   0.287253  0.293049  0.046075  0.220798  \n",
       "7   0.430656  0.462488  0.289103  0.329359  \n",
       "8   0.195013  0.190002  0.115829  0.207765  \n",
       "9   0.285719  0.239425  0.211324  0.218521  \n",
       "10  0.577768  0.753885  0.462431  0.557817  \n",
       "11  0.300104  0.208236  0.192255  0.197484  \n",
       "12  0.324978  0.271886  0.182494  0.241995  \n",
       "13  0.362372  0.415555  0.083407  0.265298  \n",
       "14  1.000000  1.000000  0.771460  1.000000  \n",
       "15  0.692733  0.681796  0.542009  0.515748  \n",
       "16  0.582011  0.640740  0.403060  0.471447  \n",
       "17  0.349004  0.370225  0.181998  0.316385  \n",
       "18  0.000000  0.000000  0.002874  0.000000  \n",
       "19  0.737220  0.700462  0.576919  0.690740  \n",
       "20  0.526876  0.462657  0.562512  0.470020  \n",
       "21  0.969657  0.887486  1.000000  0.632931  \n",
       "22  0.627894  0.781902  0.543576  0.505942  \n",
       "23  0.322142  0.340903  0.071511  0.187788  \n",
       "24  0.867586  0.924690  0.748823  0.809812  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale\n",
    "#sc = StandardScaler()\n",
    "sc = MinMaxScaler()\n",
    "#sc = RobustScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *****************KNN Experiments******************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model\n",
    "### without tuning the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.66666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67         6\n",
      "           1       0.67      0.67      0.67         6\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.67      0.67      0.67        12\n",
      "weighted avg       0.67      0.67      0.67        12\n",
      "\n",
      "0.6666666666666667\n",
      "[1 1 0 0 0 1 0 0 1 0 1 1]\n",
      "[[4 2]\n",
      " [2 4]]\n"
     ]
    }
   ],
   "source": [
    "###### KNNN ###########\n",
    "# Fit classifier to the Training set\n",
    "#KNN\n",
    "model_knn = KNeighborsClassifier(n_neighbors = 10)\n",
    "model_knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred_knn = model_knn.predict(X_test)\n",
    "\n",
    "conf_matrix_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "\n",
    "accuracy_knn = ((conf_matrix_knn[0,0] + conf_matrix_knn[1,1])/(conf_matrix_knn[0,0] +conf_matrix_knn[0,1]+conf_matrix_knn[1,0]+conf_matrix_knn[1,1]))*100\n",
    "\n",
    "\n",
    "print(accuracy_knn)\n",
    "\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "#Checking performance our model with ROC Score.\n",
    "print(roc_auc_score(y_test, y_pred_knn))\n",
    "\n",
    "print(y_pred_knn)\n",
    "\n",
    "print(conf_matrix_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best leaf_size: 1\n",
      "Best p: 1\n",
      "Best n_neighbors: 9\n",
      "Best Score: 0.76\n",
      "Best Hyperparameters: {'leaf_size': 1, 'n_neighbors': 9, 'p': 1}\n",
      "{'leaf_size': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49], 'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], 'p': [1, 2]}\n",
      "83.33333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         6\n",
      "           1       0.75      1.00      0.86         6\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.88      0.83      0.83        12\n",
      "weighted avg       0.88      0.83      0.83        12\n",
      "\n",
      "0.8333333333333334\n",
      "[1 1 0 0 1 1 0 0 1 1 1 1]\n",
      "[1 0 0 0 1 1 0 0 0 1 1 1]\n",
      "[[4 2]\n",
      " [0 6]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "########Hyperparameter tuning for KNN####################\n",
    "#List Hyperparameters that we want to tune.\n",
    "leaf_size = list(range(1,50))\n",
    "n_neighbors = list(range(1,20)) #neighbours must be < number of samples (22)\n",
    "p=[1,2]\n",
    "#Convert to dictionary\n",
    "hyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)\n",
    "#Create new KNN object\n",
    "knn_2 = KNeighborsClassifier()\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "#Use GridSearch\n",
    "clf = GridSearchCV(knn_2, hyperparameters, cv=10)\n",
    "\n",
    "#clf = RandomizedSearchCV(knn_2, hyperparameters, n_iter=500, cv=8, scoring=\"recall\")\n",
    "#Fit the model\n",
    "best_model = clf.fit(X_train, y_train)\n",
    "#Print The value of best Hyperparameters\n",
    "print('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])\n",
    "print('Best p:', best_model.best_estimator_.get_params()['p'])\n",
    "print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])\n",
    "print('Best Score: %s' % best_model.best_score_)\n",
    "print('Best Hyperparameters: %s' % best_model.best_params_)\n",
    "print(hyperparameters)\n",
    "y_pred_knn_2 = best_model.predict(X_test)\n",
    "\n",
    "conf_matrix_knn_2 = confusion_matrix(y_test, y_pred_knn_2)\n",
    "\n",
    "accuracy_knn_2 = ((conf_matrix_knn_2[0,0] + conf_matrix_knn_2[1,1])/(conf_matrix_knn_2[0,0] +conf_matrix_knn_2[0,1]+conf_matrix_knn_2[1,0]+conf_matrix_knn_2[1,1]))*100\n",
    "\n",
    "\n",
    "print(accuracy_knn_2)\n",
    "\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred_knn_2))\n",
    "#Checking performance our model with ROC Score.\n",
    "print(roc_auc_score(y_test, y_pred_knn_2))\n",
    "\n",
    "print(y_pred_knn_2)\n",
    "print(y_test)\n",
    "\n",
    "print(conf_matrix_knn_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model\n",
    "### using the optimal parameters gotten above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.33333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         6\n",
      "           1       0.75      1.00      0.86         6\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.88      0.83      0.83        12\n",
      "weighted avg       0.88      0.83      0.83        12\n",
      "\n",
      "0.8333333333333334\n",
      "[1 1 0 0 1 1 0 0 1 1 1 1]\n",
      "[1 0 0 0 1 1 0 0 0 1 1 1]\n",
      "[[4 2]\n",
      " [0 6]]\n"
     ]
    }
   ],
   "source": [
    "model_knn = KNeighborsClassifier(n_neighbors = 9, p = 1, leaf_size = 1)\n",
    "model_knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred_knn = model_knn.predict(X_test)\n",
    "\n",
    "conf_matrix_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "\n",
    "accuracy_knn = ((conf_matrix_knn[0,0] + conf_matrix_knn[1,1])/(conf_matrix_knn[0,0] +conf_matrix_knn[0,1]+conf_matrix_knn[1,0]+conf_matrix_knn[1,1]))*100\n",
    "\n",
    "\n",
    "print(accuracy_knn)\n",
    "\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "#Checking performance our model with ROC Score.\n",
    "print(roc_auc_score(y_test, y_pred_knn))\n",
    "\n",
    "print(y_pred_knn)\n",
    "print(y_test)\n",
    "print(conf_matrix_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation with Leave one out method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.649 (0.477)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0]\n",
      "Confusion Matrix for KNN using k-fold (leave one out)\n",
      "[[18  3]\n",
      " [10  6]]\n",
      "64.86486486486487\n"
     ]
    }
   ],
   "source": [
    "df_X = sc.fit_transform(df_X)\n",
    "k_fold = KFold(n_splits=37)\n",
    "#KNN\n",
    "model_knn_kfold = KNeighborsClassifier(n_neighbors = 9, p =1, leaf_size = 1)\n",
    "y_pred_kfold_knn = cross_val_predict(model_knn_kfold, df_X, df_Y, cv=k_fold)\n",
    "\n",
    "scores = cross_val_score(model_knn_kfold, df_X, df_Y, scoring='accuracy', cv=k_fold, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "\n",
    "print(df_Y)\n",
    "print(y_pred_kfold_knn)\n",
    "conf_matrix_knn_kfold = confusion_matrix(df_Y, y_pred_kfold_knn)\n",
    "print(\"Confusion Matrix for KNN using k-fold (leave one out)\")\n",
    "print(conf_matrix_knn_kfold)\n",
    "\n",
    "\n",
    "accuracy_knn_2 = ((conf_matrix_knn_kfold[0,0] + conf_matrix_knn_kfold[1,1])/(conf_matrix_knn_kfold[0,0] +conf_matrix_knn_kfold[0,1]+conf_matrix_knn_kfold[1,0]+conf_matrix_knn_kfold[1,1]))*100\n",
    "\n",
    "\n",
    "print(accuracy_knn_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Fold Evaluation using optimal paramaters. (k =3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divided into 4 parts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loops</th>\n",
       "      <th>fold 1</th>\n",
       "      <th>fold 2</th>\n",
       "      <th>fold 3</th>\n",
       "      <th>fold 4</th>\n",
       "      <th>mean accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70.0</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>61.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>60.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>62.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>70.0</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>59.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>70.0</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>61.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>68.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>60.0</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>65.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>60.0</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>51.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>60.0</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>62.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>65.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>50.0</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>48.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>50.0</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>56.944444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loops  fold 1     fold 2     fold 3     fold 4  mean accuracy\n",
       "0       1    70.0  55.555556  44.444444  77.777778      61.944444\n",
       "1       2    60.0  66.666667  33.333333  88.888889      62.222222\n",
       "2       3    70.0  55.555556  55.555556  55.555556      59.166667\n",
       "3       4    70.0  55.555556  44.444444  77.777778      61.944444\n",
       "4       5    50.0  77.777778  88.888889  55.555556      68.055556\n",
       "5       6    60.0  55.555556  66.666667  77.777778      65.000000\n",
       "6       7    60.0  22.222222  66.666667  55.555556      51.111111\n",
       "7       8    60.0  77.777778  55.555556  55.555556      62.222222\n",
       "8       9    60.0  55.555556  77.777778  66.666667      65.000000\n",
       "9      10    50.0  55.555556  33.333333  55.555556      48.611111\n",
       "10     11    50.0  77.777778  22.222222  77.777778      56.944444"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_kfold = shuffle(df)\n",
    "#df_kfold.reset_index(inplace=True, drop=True)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "df_kfold = df\n",
    "df_Xnew = df_kfold.iloc[:, :-1].values\n",
    "df_Ynew = df_kfold.iloc[:,-1].values\n",
    "\n",
    "\n",
    "X_kfold = pd.DataFrame(df_Xnew)\n",
    "y_kfold = pd.DataFrame(df_Ynew)\n",
    "#print(X_kfold)\n",
    "#print(y_kfold)\n",
    "\n",
    "parts = 4\n",
    "kfold = KFold(parts, True, None) \n",
    "\n",
    "# splits into 5 groups \n",
    "print(\"Divided into %s parts.\" %parts)\n",
    "\n",
    "k_list = []\n",
    "\n",
    "for i in range (1,12):\n",
    "    row = []\n",
    "    row.append(i)\n",
    "    total = 0\n",
    "    #print(\"Loop\", i)\n",
    "    for train, test in kfold.split(X_kfold,y_kfold):\n",
    "        #print('\\ntrain: %s, test: %s' % (train, test))\n",
    "        Xtrain_kfold = X_kfold.iloc[train, :]\n",
    "        Ytrain_kfold = y_kfold.iloc[train, :]\n",
    "        Xtest_kfold = X_kfold.iloc[test, :]\n",
    "        Ytest_kfold = y_kfold.iloc[test, :]\n",
    "        #print(Xtest_kfold)\n",
    "        #print(Ytest_kfold)\n",
    "\n",
    "        Xtrain_kfold = sc.fit_transform(Xtrain_kfold)\n",
    "        Xtest_kfold = sc.transform(Xtest_kfold)\n",
    "\n",
    "        #modelling\n",
    "        model_knn_new = KNeighborsClassifier(n_neighbors = 9, p =1, leaf_size = 1)\n",
    "        model_knn_new.fit(Xtrain_kfold, Ytrain_kfold)\n",
    "        y_pred_knn_new = model_knn_new.predict(Xtest_kfold)\n",
    "\n",
    "        conf_matrix_knn_kfold = confusion_matrix(Ytest_kfold, y_pred_knn_new)\n",
    "\n",
    "        accuracy_knn_kfold = ((conf_matrix_knn_kfold[0,0] + conf_matrix_knn_kfold[1,1])/(conf_matrix_knn_kfold[0,0] +conf_matrix_knn_kfold[0,1]+conf_matrix_knn_kfold[1,0]+conf_matrix_knn_kfold[1,1]))*100\n",
    "\n",
    "        #print(\"Confusion Matrix:\\n \", conf_matrix_knn_kfold)\n",
    "        #print(\"Accuracy \", accuracy_knn_kfold)\n",
    "\n",
    "        row.append(accuracy_knn_kfold)\n",
    "        total += accuracy_knn_kfold\n",
    "    average = row.append(total/parts)\n",
    "        \n",
    "    #print(row)\n",
    "    k_list.append(row)\n",
    "    \n",
    "k_list = pd.DataFrame(k_list, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean accuracy'])\n",
    "k_list\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#print(df.sample(n=7))\n",
    "#print(df)\n",
    "\n",
    "#x = df.take(np.random.permutation(len(df))[:4])\n",
    "#x= df.sample(n=7)\n",
    "#print(x)\n",
    "#print(df.drop(x))\n",
    "\n",
    "#drop_indices = np.random.choice(df.index, 4, replace=False)\n",
    "#df_subset = df.drop(drop_indices)\n",
    "#print(drop_indices)\n",
    "#print(df_subset)\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# *****************Decision Tree Experiments***************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model\n",
    "### without tuning the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.66666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67         6\n",
      "           1       0.67      0.67      0.67         6\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.67      0.67      0.67        12\n",
      "weighted avg       0.67      0.67      0.67        12\n",
      "\n",
      "0.6666666666666667\n",
      "[1 1 0 0 1 0 0 0 1 1 1 0]\n",
      "[[4 2]\n",
      " [2 4]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(334.8, 684.9359999999999, 'X[1] <= 0.277\\ngini = 0.48\\nsamples = 25\\nvalue = [15, 10]'),\n",
       " Text(167.4, 532.728, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
       " Text(502.20000000000005, 532.728, 'X[6] <= 0.254\\ngini = 0.408\\nsamples = 21\\nvalue = [15, 6]'),\n",
       " Text(334.8, 380.52, 'gini = 0.0\\nsamples = 6\\nvalue = [6, 0]'),\n",
       " Text(669.6, 380.52, 'X[2] <= 0.437\\ngini = 0.48\\nsamples = 15\\nvalue = [9, 6]'),\n",
       " Text(334.8, 228.312, 'X[8] <= 0.962\\ngini = 0.219\\nsamples = 8\\nvalue = [7, 1]'),\n",
       " Text(167.4, 76.10399999999993, 'gini = 0.0\\nsamples = 7\\nvalue = [7, 0]'),\n",
       " Text(502.20000000000005, 76.10399999999993, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(1004.4000000000001, 228.312, 'X[0] <= 0.668\\ngini = 0.408\\nsamples = 7\\nvalue = [2, 5]'),\n",
       " Text(837.0, 76.10399999999993, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(1171.8, 76.10399999999993, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 5]')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x1008 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###### KNNN ###########\n",
    "# Fit classifier to the Training set\n",
    "#Decision Tree\n",
    "import matplotlib.pyplot as plt\n",
    "model_dt = tree.DecisionTreeClassifier()\n",
    "model_dt = model_dt.fit(X_train, y_train)\n",
    "\n",
    "y_pred_knn = model_dt.predict(X_test)\n",
    "\n",
    "conf_matrix_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "\n",
    "accuracy_knn = ((conf_matrix_knn[0,0] + conf_matrix_knn[1,1])/(conf_matrix_knn[0,0] +conf_matrix_knn[0,1]+conf_matrix_knn[1,0]+conf_matrix_knn[1,1]))*100\n",
    "\n",
    "\n",
    "print(accuracy_knn)\n",
    "\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "#Checking performance our model with ROC Score.\n",
    "print(roc_auc_score(y_test, y_pred_knn))\n",
    "\n",
    "print(y_pred_knn)\n",
    "\n",
    "print(conf_matrix_knn)\n",
    "\n",
    "plt.figure(figsize=(24,14))\n",
    "tree.plot_tree(model_dt, filled=True, fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning for Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.6\n",
      "Best Hyperparameters: {'criterion': 'gini', 'max_depth': 1, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "{'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9], 'min_samples_leaf': [1, 2, 3, 4], 'criterion': ['gini', 'entropy']}\n",
      "75.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73         6\n",
      "           1       0.71      0.83      0.77         6\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.76      0.75      0.75        12\n",
      "weighted avg       0.76      0.75      0.75        12\n",
      "\n",
      "0.7500000000000002\n",
      "[1 1 0 0 1 1 0 0 1 0 1 1]\n",
      "[1 0 0 0 1 1 0 0 0 1 1 1]\n",
      "[[4 2]\n",
      " [1 5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "########Hyperparameter tuning for KNN####################\n",
    "#List Hyperparameters that we want to tune.\n",
    "#n_components = list(range(1,X.shape[1]+1,1))\n",
    "max_depth = list(range(1,10))\n",
    "min_samples_split = list(range(2,10)) #neighbours must be < number of samples (22)\n",
    "min_samples_leaf = list(range(1,5))\n",
    "criterion=['gini','entropy']\n",
    "#Convert to dictionary\n",
    "hyperparameters = dict(max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, criterion = criterion)\n",
    "#Create new KNN object\n",
    "dt_2 = tree.DecisionTreeClassifier()\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=4, n_repeats=3, random_state=1)\n",
    "\n",
    "#Use GridSearch\n",
    "clf = GridSearchCV(dt_2, hyperparameters, refit=True)\n",
    "\n",
    "#clf = RandomizedSearchCV(knn_2, hyperparameters, n_iter=500, cv=8, scoring=\"recall\")\n",
    "#Fit the model\n",
    "best_model = clf.fit(X_train, y_train)\n",
    "#Print The value of best Hyperparameters\n",
    "#print('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])\n",
    "#print('Best p:', best_model.best_estimator_.get_params()['p'])\n",
    "#print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])\n",
    "print('Best Score: %s' % best_model.best_score_)\n",
    "print('Best Hyperparameters: %s' % best_model.best_params_)\n",
    "print(hyperparameters)\n",
    "y_pred_knn_2 = best_model.predict(X_test)\n",
    "\n",
    "conf_matrix_knn_2 = confusion_matrix(y_test, y_pred_knn_2)\n",
    "\n",
    "accuracy_knn_2 = ((conf_matrix_knn_2[0,0] + conf_matrix_knn_2[1,1])/(conf_matrix_knn_2[0,0] +conf_matrix_knn_2[0,1]+conf_matrix_knn_2[1,0]+conf_matrix_knn_2[1,1]))*100\n",
    "\n",
    "\n",
    "print(accuracy_knn_2)\n",
    "\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred_knn_2))\n",
    "#Checking performance our model with ROC Score.\n",
    "print(roc_auc_score(y_test, y_pred_knn_2))\n",
    "\n",
    "print(y_pred_knn_2)\n",
    "print(y_test)\n",
    "\n",
    "print(conf_matrix_knn_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model (Decision Tree)\n",
    "### using the optimal parameters gotten above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 2]\n",
      " [1 5]]\n",
      "75.0\n"
     ]
    }
   ],
   "source": [
    "#model_dt = tree.DecisionTreeClassifier(max_depth = 6, criterion='entropy',min_samples_leaf=2, min_samples_split=2 )\n",
    "model_dt = tree.DecisionTreeClassifier(max_depth = 1, criterion='gini',min_samples_leaf=1, min_samples_split=2 )\n",
    "model_dt = model_dt.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dt_2 = best_model.predict(X_test)\n",
    "\n",
    "conf_matrix_dt_2 = confusion_matrix(y_test, y_pred_dt_2)\n",
    "\n",
    "accuracy_dt_2 = ((conf_matrix_dt_2[0,0] + conf_matrix_dt_2[1,1])/(conf_matrix_dt_2[0,0] +conf_matrix_dt_2[0,1]+conf_matrix_dt_2[1,0]+conf_matrix_dt_2[1,1]))*100\n",
    "\n",
    "print(conf_matrix_dt_2)\n",
    "print(accuracy_dt_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation with Leave one out method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.568 (0.495)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0]\n",
      "Confusion Matrix for Dt using k-fold (leave one out)\n",
      "[[17  4]\n",
      " [11  5]]\n",
      "59.45945945945946\n"
     ]
    }
   ],
   "source": [
    "df_X = sc.fit_transform(df_X)\n",
    "k_fold = KFold(n_splits=37)\n",
    "#KNN\n",
    "#model_knn_kfold = tree.DecisionTreeClassifier(max_depth = 6, criterion='entropy',min_samples_leaf=2, min_samples_split=2 )\n",
    "model_dt = tree.DecisionTreeClassifier(max_depth = 1, criterion='gini',min_samples_leaf=1, min_samples_split=2 )\n",
    "y_pred_kfold_knn = cross_val_predict(model_dt, df_X, df_Y, cv=k_fold)\n",
    "scores = cross_val_score(model_dt, df_X, df_Y, scoring='accuracy', cv=k_fold, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "\n",
    "print(df_Y)\n",
    "print(y_pred_kfold_knn)\n",
    "conf_matrix_knn_kfold = confusion_matrix(df_Y, y_pred_kfold_knn)\n",
    "print(\"Confusion Matrix for Dt using k-fold (leave one out)\")\n",
    "print(conf_matrix_knn_kfold)\n",
    "\n",
    "\n",
    "accuracy_knn_2 = ((conf_matrix_knn_kfold[0,0] + conf_matrix_knn_kfold[1,1])/(conf_matrix_knn_kfold[0,0] +conf_matrix_knn_kfold[0,1]+conf_matrix_knn_kfold[1,0]+conf_matrix_knn_kfold[1,1]))*100\n",
    "\n",
    "\n",
    "print(accuracy_knn_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Fold Evaluation using optimal paramaters. (k =4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divided into 4 parts.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loops</th>\n",
       "      <th>fold 1</th>\n",
       "      <th>fold 2</th>\n",
       "      <th>fold 3</th>\n",
       "      <th>fold 4</th>\n",
       "      <th>mean accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>67.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>60.0</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>62.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>48.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>56.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>60.0</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>51.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>60.0</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>53.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>56.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>70.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>61.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>60.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>59.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>60.0</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>53.888889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loops  fold 1     fold 2     fold 3     fold 4  mean accuracy\n",
       "0       1    20.0  66.666667  66.666667  66.666667      55.000000\n",
       "1       2    80.0  77.777778  55.555556  55.555556      67.222222\n",
       "2       3    60.0  55.555556  66.666667  66.666667      62.222222\n",
       "3       4    50.0  55.555556  33.333333  55.555556      48.611111\n",
       "4       5    60.0  77.777778  33.333333  55.555556      56.666667\n",
       "5       6    60.0  55.555556  44.444444  44.444444      51.111111\n",
       "6       7    60.0  33.333333  55.555556  66.666667      53.888889\n",
       "7       8    50.0  66.666667  44.444444  66.666667      56.944444\n",
       "8       9    70.0  66.666667  77.777778  33.333333      61.944444\n",
       "9      10    60.0  66.666667  55.555556  55.555556      59.444444\n",
       "10     11    60.0  33.333333  44.444444  77.777778      53.888889"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_kfold = shuffle(df)\n",
    "#df_kfold.reset_index(inplace=True, drop=True)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "df_kfold = df\n",
    "df_Xnew = df_kfold.iloc[:, :-1].values\n",
    "df_Ynew = df_kfold.iloc[:,-1].values\n",
    "\n",
    "\n",
    "X_kfold = pd.DataFrame(df_Xnew)\n",
    "y_kfold = pd.DataFrame(df_Ynew)\n",
    "#print(X_kfold)\n",
    "#print(y_kfold)\n",
    "\n",
    "parts = 4\n",
    "kfold = KFold(parts, True, None) \n",
    "\n",
    "# splits into 5 groups \n",
    "print(\"Divided into %s parts.\" %parts)\n",
    "\n",
    "k_list = []\n",
    "\n",
    "for i in range (1,12):\n",
    "    row = []\n",
    "    row.append(i)\n",
    "    total = 0\n",
    "    #print(\"Loop\", i)\n",
    "    for train, test in kfold.split(X_kfold,y_kfold):\n",
    "        #print('\\ntrain: %s, test: %s' % (train, test))\n",
    "        Xtrain_kfold = X_kfold.iloc[train, :]\n",
    "        Ytrain_kfold = y_kfold.iloc[train, :]\n",
    "        Xtest_kfold = X_kfold.iloc[test, :]\n",
    "        Ytest_kfold = y_kfold.iloc[test, :]\n",
    "        #print(Xtest_kfold)\n",
    "        #print(Ytest_kfold)\n",
    "\n",
    "        Xtrain_kfold = sc.fit_transform(Xtrain_kfold)\n",
    "        Xtest_kfold = sc.transform(Xtest_kfold)\n",
    "\n",
    "        #modelling\n",
    "        #model_knn_new = tree.DecisionTreeClassifier(max_depth = 6, criterion='entropy',min_samples_leaf=2, min_samples_split=2 )\n",
    "        model_dt_new = tree.DecisionTreeClassifier(max_depth = 1, criterion='gini',min_samples_leaf=1, min_samples_split=2 )\n",
    "        model_dt_new.fit(Xtrain_kfold, Ytrain_kfold)\n",
    "        y_pred_dt_new = model_dt_new.predict(Xtest_kfold)\n",
    "\n",
    "        conf_matrix_dt_kfold = confusion_matrix(Ytest_kfold, y_pred_dt_new)\n",
    "\n",
    "        accuracy_dt_kfold = ((conf_matrix_dt_kfold[0,0] + conf_matrix_dt_kfold[1,1])/(conf_matrix_dt_kfold[0,0] +conf_matrix_dt_kfold[0,1]+conf_matrix_dt_kfold[1,0]+conf_matrix_dt_kfold[1,1]))*100\n",
    "\n",
    "        #print(\"Confusion Matrix:\\n \", conf_matrix_knn_kfold)\n",
    "        #print(\"Accuracy \", accuracy_knn_kfold)\n",
    "\n",
    "        row.append(accuracy_dt_kfold)\n",
    "        total += accuracy_dt_kfold\n",
    "    average = row.append(total/parts)\n",
    "        \n",
    "    #print(row)\n",
    "    k_list.append(row)\n",
    "    \n",
    "k_list = pd.DataFrame(k_list, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean accuracy'])\n",
    "k_list\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#print(df.sample(n=7))\n",
    "#print(df)\n",
    "\n",
    "#x = df.take(np.random.permutation(len(df))[:4])\n",
    "#x= df.sample(n=7)\n",
    "#print(x)\n",
    "#print(df.drop(x))\n",
    "\n",
    "#drop_indices = np.random.choice(df.index, 4, replace=False)\n",
    "#df_subset = df.drop(drop_indices)\n",
    "#print(drop_indices)\n",
    "#print(df_subset)\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# *****************SVM Experiments***************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model\n",
    "### without tuning the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.67      0.57         6\n",
      "           1       0.50      0.33      0.40         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.50      0.50      0.49        12\n",
      "weighted avg       0.50      0.50      0.49        12\n",
      "\n",
      "0.5\n",
      "[0 1 0 0 1 0 0 0 1 0 1 0]\n",
      "[[4 2]\n",
      " [4 2]]\n"
     ]
    }
   ],
   "source": [
    "###### KNNN ###########\n",
    "# Fit classifier to the Training set\n",
    "#Decision Tree\n",
    "import matplotlib.pyplot as plt\n",
    "model_svm = svm.SVC()\n",
    "model_svm = model_dt.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = model_dt.predict(X_test)\n",
    "\n",
    "conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "\n",
    "accuracy_svm = ((conf_matrix_svm[0,0] + conf_matrix_svm[1,1])/(conf_matrix_svm[0,0] +conf_matrix_svm[0,1]+conf_matrix_svm[1,0]+conf_matrix_svm[1,1]))*100\n",
    "\n",
    "\n",
    "print(accuracy_svm)\n",
    "\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "#Checking performance our model with ROC Score.\n",
    "print(roc_auc_score(y_test, y_pred_svm))\n",
    "\n",
    "print(y_pred_svm)\n",
    "\n",
    "print(conf_matrix_svm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.68\n",
      "Best Hyperparameters: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "{'C': [0.1, 1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'kernel': ['rbf']}\n",
      "66.66666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67         6\n",
      "           1       0.67      0.67      0.67         6\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.67      0.67      0.67        12\n",
      "weighted avg       0.67      0.67      0.67        12\n",
      "\n",
      "0.6666666666666667\n",
      "[1 1 0 0 1 1 0 0 1 0 1 0]\n",
      "[1 0 0 0 1 1 0 0 0 1 1 1]\n",
      "[[4 2]\n",
      " [2 4]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "########Hyperparameter tuning for SVM####################\n",
    "#List Hyperparameters that we want to tune.\n",
    "#n_components = list(range(1,X.shape[1]+1,1))\n",
    "C = [0.1, 1, 10, 100, 1000]\n",
    "gamma = [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "kernel = ['rbf']\n",
    "\n",
    "#Convert to dictionary\n",
    "hyperparameters = dict(C=C, gamma=gamma, kernel=kernel)\n",
    "#Create new KNN object\n",
    "svm2 = svm.SVC()\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "#Use GridSearch\n",
    "clf = GridSearchCV(svm2, hyperparameters, refit=True)\n",
    "\n",
    "#clf = RandomizedSearchCV(knn_2, hyperparameters, n_iter=500, cv=8, scoring=\"recall\")\n",
    "#Fit the model\n",
    "best_model = clf.fit(X_train, y_train)\n",
    "#Print The value of best Hyperparameters\n",
    "#print('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])\n",
    "#print('Best p:', best_model.best_estimator_.get_params()['p'])\n",
    "#print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])\n",
    "print('Best Score: %s' % best_model.best_score_)\n",
    "print('Best Hyperparameters: %s' % best_model.best_params_)\n",
    "print(hyperparameters)\n",
    "y_pred_knn_2 = best_model.predict(X_test)\n",
    "\n",
    "conf_matrix_knn_2 = confusion_matrix(y_test, y_pred_knn_2)\n",
    "\n",
    "accuracy_knn_2 = ((conf_matrix_knn_2[0,0] + conf_matrix_knn_2[1,1])/(conf_matrix_knn_2[0,0] +conf_matrix_knn_2[0,1]+conf_matrix_knn_2[1,0]+conf_matrix_knn_2[1,1]))*100\n",
    "\n",
    "\n",
    "print(accuracy_knn_2)\n",
    "\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred_knn_2))\n",
    "#Checking performance our model with ROC Score.\n",
    "print(roc_auc_score(y_test, y_pred_knn_2))\n",
    "\n",
    "print(y_pred_knn_2)\n",
    "print(y_test)\n",
    "\n",
    "print(conf_matrix_knn_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model (SVM)\n",
    "### using the optimal parameters gotten above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 2]\n",
      " [2 4]]\n",
      "66.66666666666666\n"
     ]
    }
   ],
   "source": [
    "model_svm = svm.SVC(C = 10, gamma=0.1,kernel='rbf')\n",
    "model_svm = model_svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm_2 = best_model.predict(X_test)\n",
    "\n",
    "conf_matrix_svm_2 = confusion_matrix(y_test, y_pred_svm_2)\n",
    "\n",
    "accuracy_svm_2 = ((conf_matrix_svm_2[0,0] + conf_matrix_svm_2[1,1])/(conf_matrix_svm_2[0,0] +conf_matrix_svm_2[0,1]+conf_matrix_svm_2[1,0]+conf_matrix_svm_2[1,1]))*100\n",
    "\n",
    "print(conf_matrix_svm_2)\n",
    "print(accuracy_svm_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation (SVM) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation with Leave one out method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.757 (0.429)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0]\n",
      "Confusion Matrix for Dt using k-fold (leave one out)\n",
      "[[17  4]\n",
      " [ 5 11]]\n",
      "75.67567567567568\n"
     ]
    }
   ],
   "source": [
    "df_X = sc.fit_transform(df_X)\n",
    "k_fold = KFold(n_splits=37)\n",
    "#KNN\n",
    "#model_knn_kfold = tree.DecisionTreeClassifier(max_depth = 6, criterion='entropy',min_samples_leaf=2, min_samples_split=2 )\n",
    "model_svm = svm.SVC(C = 10, gamma=0.1,kernel='rbf')\n",
    "y_pred_kfold_svm = cross_val_predict(model_svm, df_X, df_Y, cv=k_fold)\n",
    "scores = cross_val_score(model_svm, df_X, df_Y, scoring='accuracy', cv=k_fold, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "\n",
    "print(df_Y)\n",
    "print(y_pred_kfold_knn)\n",
    "conf_matrix_svm_kfold = confusion_matrix(df_Y, y_pred_kfold_svm)\n",
    "print(\"Confusion Matrix for Dt using k-fold (leave one out)\")\n",
    "print(conf_matrix_svm_kfold)\n",
    "\n",
    "\n",
    "accuracy_svm_2 = ((conf_matrix_svm_kfold[0,0] + conf_matrix_svm_kfold[1,1])/(conf_matrix_svm_kfold[0,0] +conf_matrix_svm_kfold[0,1]+conf_matrix_svm_kfold[1,0]+conf_matrix_svm_kfold[1,1]))*100\n",
    "\n",
    "\n",
    "print(accuracy_svm_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Fold Evaluation using optimal paramaters. (k =4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divided into 4 parts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aeesha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loops</th>\n",
       "      <th>fold 1</th>\n",
       "      <th>fold 2</th>\n",
       "      <th>fold 3</th>\n",
       "      <th>fold 4</th>\n",
       "      <th>mean accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>67.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>72.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>70.0</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>70.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>73.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>80.0</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>75.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>80.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>72.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>60.0</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>67.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>80.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>75.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>70.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>64.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>70.0</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>59.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loops  fold 1     fold 2     fold 3     fold 4  mean accuracy\n",
       "0       1    80.0  33.333333  66.666667  88.888889      67.222222\n",
       "1       2    80.0  66.666667  66.666667  77.777778      72.777778\n",
       "2       3    70.0  77.777778  44.444444  88.888889      70.277778\n",
       "3       4    80.0  77.777778  77.777778  44.444444      70.000000\n",
       "4       5    60.0  77.777778  66.666667  88.888889      73.333333\n",
       "5       6    80.0  55.555556  77.777778  88.888889      75.555556\n",
       "6       7    80.0  66.666667  77.777778  66.666667      72.777778\n",
       "7       8    60.0  77.777778  88.888889  44.444444      67.777778\n",
       "8       9    80.0  66.666667  77.777778  77.777778      75.555556\n",
       "9      10    70.0  66.666667  66.666667  55.555556      64.722222\n",
       "10     11    70.0  77.777778  55.555556  33.333333      59.166667"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_kfold = shuffle(df)\n",
    "#df_kfold.reset_index(inplace=True, drop=True)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "df_kfold = df\n",
    "df_Xnew = df_kfold.iloc[:, :-1].values\n",
    "df_Ynew = df_kfold.iloc[:,-1].values\n",
    "\n",
    "\n",
    "X_kfold = pd.DataFrame(df_Xnew)\n",
    "y_kfold = pd.DataFrame(df_Ynew)\n",
    "#print(X_kfold)\n",
    "#print(y_kfold)\n",
    "\n",
    "parts = 4\n",
    "kfold = KFold(parts, True, None) \n",
    "\n",
    "# splits into 5 groups \n",
    "print(\"Divided into %s parts.\" %parts)\n",
    "\n",
    "k_list = []\n",
    "\n",
    "for i in range (1,12):\n",
    "    row = []\n",
    "    row.append(i)\n",
    "    total = 0\n",
    "    #print(\"Loop\", i)\n",
    "    for train, test in kfold.split(X_kfold,y_kfold):\n",
    "        #print('\\ntrain: %s, test: %s' % (train, test))\n",
    "        Xtrain_kfold = X_kfold.iloc[train, :]\n",
    "        Ytrain_kfold = y_kfold.iloc[train, :]\n",
    "        Xtest_kfold = X_kfold.iloc[test, :]\n",
    "        Ytest_kfold = y_kfold.iloc[test, :]\n",
    "        #print(Xtest_kfold)\n",
    "        #print(Ytest_kfold)\n",
    "\n",
    "        Xtrain_kfold = sc.fit_transform(Xtrain_kfold)\n",
    "        Xtest_kfold = sc.transform(Xtest_kfold)\n",
    "\n",
    "        #modelling\n",
    "        #model_knn_new = tree.DecisionTreeClassifier(max_depth = 6, criterion='entropy',min_samples_leaf=2, min_samples_split=2 )\n",
    "        model_svm_new = svm.SVC(C = 10, gamma=0.1,kernel='rbf')\n",
    "        model_svm_new.fit(Xtrain_kfold, Ytrain_kfold)\n",
    "        y_pred_svm_new = model_svm_new.predict(Xtest_kfold)\n",
    "\n",
    "        conf_matrix_svm_kfold = confusion_matrix(Ytest_kfold, y_pred_svm_new)\n",
    "\n",
    "        accuracy_svm_kfold = ((conf_matrix_svm_kfold[0,0] + conf_matrix_svm_kfold[1,1])/(conf_matrix_svm_kfold[0,0] +conf_matrix_svm_kfold[0,1]+conf_matrix_svm_kfold[1,0]+conf_matrix_svm_kfold[1,1]))*100\n",
    "\n",
    "        #print(\"Confusion Matrix:\\n \", conf_matrix_knn_kfold)\n",
    "        #print(\"Accuracy \", accuracy_knn_kfold)\n",
    "\n",
    "        row.append(accuracy_svm_kfold)\n",
    "        total += accuracy_svm_kfold\n",
    "    average = row.append(total/parts)\n",
    "    #print(row)\n",
    "    k_list.append(row)\n",
    "    \n",
    "k_list = pd.DataFrame(k_list, columns=['Loops','fold 1','fold 2','fold 3','fold 4', 'mean accuracy'])\n",
    "k_list\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#print(df.sample(n=7))\n",
    "#print(df)\n",
    "\n",
    "#x = df.take(np.random.permutation(len(df))[:4])\n",
    "#x= df.sample(n=7)\n",
    "#print(x)\n",
    "#print(df.drop(x))\n",
    "\n",
    "#drop_indices = np.random.choice(df.index, 4, replace=False)\n",
    "#df_subset = df.drop(drop_indices)\n",
    "#print(drop_indices)\n",
    "#print(df_subset)\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
